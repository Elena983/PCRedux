<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>PCRedux Package - An Overview • PCRedux</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="PCRedux Package - An Overview">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">PCRedux</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">0.2.6.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/PCRedux.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/PCRedux_visdat_pcrfit.html">PCRedux Package - Visualization Data Structure</a>
    </li>
    <li>
      <a href="../articles/SI1.html">Algorithms for Automatized Detection of Hook Effect-bearing Amplification Curves</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>PCRedux Package - An Overview</h1>
                        <h4 class="author">Stefan Rödiger</h4>
            
            <h4 class="date">2018-09-11</h4>
      
      
      <div class="hidden name"><code>PCRedux.Rmd</code></div>

    </div>

    
    

<div id="development-implementation-and-installation" class="section level2">
<h2 class="hasAnchor">
<a href="#development-implementation-and-installation" class="anchor"></a>Development, Implementation and Installation </h2>
<p> is an open source software package (<a href="https://opensource.org/licenses/MIT">MIT license</a>) for the statistical computing language . Data with sigmoid curves are common in bioanalytical methods. A widely used bioanalytical method for the detecition and quantification of DNA is the quantitative real-time PCR (qPCR). qPCRs are applied in human diagnostics, life sciences and forensics <span class="citation">(Martins et al. 2015, <span class="citation">Sauer, Reinke, and Courts (2016)</span>)</span>. qPCR amplification curves are an example for sigmoid shaped curves  contains function for the calculation of predictors from amplification curves and classified data sets for machine learning applications.</p>
<p>All technical and experimental aspects should be performed under principles that follow good practices of reproducible research. Numerous authors addressed the matter for experimental design and data report. Examples are the <em>Minimum Information for Publication of Quantitative PCR Experiments</em> guidelines (MIQE) and the <em>Real-time PCR Data Markup Language</em> (RDML). MIQE is a recommended standard of the minimum information for publication of quantitative real-time PCR experiments guidelines and RDML is a data exchange format <span class="citation">(S. Bustin 2017, <span class="citation">Rödiger et al. (2015)</span>, <span class="citation">Rödiger et al. (2017)</span>)</span>.</p>
<p>The development of scientific software is a complex process. In particular, if a developer team works in different time zones with no face-to-face meetings. End users need releases with stable software that delivers reproducible results. Developers need well documented software to modify the software to their needs.</p>
<p>Under the umbrella  and , several principles were proposed to deliver high quality software, which meet the needs of end users and developers. This includes version control, collaborative editing, unit testing and continuous integration <span class="citation">(Lanubile et al. 2010, <span class="citation">Myers et al. (2004)</span>, <span class="citation">Rödiger et al. (2015)</span>)</span>. The following paragraphs describe methods applied for the  package.</p>
<div id="version-control-and-continuous-integration" class="section level3">
<h3 class="hasAnchor">
<a href="#version-control-and-continuous-integration" class="anchor"></a>Version Control and Continuous Integration </h3>
<p>The development of the  package started 2017 with the submission of a functional, yet immature source code, to GitHub (GitHub, Inc.). GitHub is a web-based version control repository hosting service. Both distributed version control and source code management are based on Git. <span class="citation">(Lanubile et al. 2010)</span>. Additional functionality of GitHub includes the administration of access management, bug tracking, moderation of predictor requests, task management, some metrics for the software development, and wikis. The source code of  is available at:</p>
<blockquote>

</blockquote>
<p>In continuous integration development team members (incl. coders, artists, translators) can commit and integrate their contributions several times a day. An automated build and test system verifies each integration and gives the development team members a timely feedback about the effect of their commit. In contrast to deferred integration leads this to a reduced number of integration problems and less workload because most errors are solved shortly after they were integrated <span class="citation">(Myers et al. 2004)</span>.</p>
<p>TravisCI was chosen as continues integration service for . The TravisCI server communicates with the GitHub version control system and manages the  package building process. Continuous interaction is available for the  releases ,  and . The history of the build tests are available at:</p>
<blockquote>

</blockquote>
</div>
<div id="naming-convention-and-literate-programming" class="section level3">
<h3 class="hasAnchor">
<a href="#naming-convention-and-literate-programming" class="anchor"></a>Naming Convention and Literate Programming </h3>
<p> is an  (<span class="math inline">\(\geq\)</span> v. 3.3.3) package, written as  object system.  has characteristics of object orientated programming but eases the development due to the use of the naming conventions <span class="citation">(Brito 2008)</span>. In most places functions and parameter names are written as underscore separated (underscore<span class="math inline">\(\_\)</span>sep), which is a widely used style in  packages <span class="citation">(Bååth 2012)</span>. This convention had to be violated in coding sections where functionality from other packages was used.</p>
<p>By convention, it was specified that functions from the  package shall be reported in the form <code>functionname()</code> (e.g., <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code>) and functions from other packages in the form <code>functionname()</code> [] (e.g., <code><a href="http://www.rdocumentation.org/packages/qpcR/topics/efficiency">efficiency(pcrfit())</a></code> []).</p>
<p>Literate programming, as proposed by <span class="citation">Knuth (1984)</span>, is a concept where the logic of the source code and documentation is integrated in a single file. Markup conventions (e. g., ‘#’) tell in literate programming how to typeset the documentation. This produces outputs in a typesetting language such as the lightweight markup language <strong>Markdown</strong>, or the document preparation system .</p>
<p>The ,  and  packages were used to write the documentation in-line with code for the  package.</p>
</div>
<div id="installation-of-the-package" class="section level3">
<h3 class="hasAnchor">
<a href="#installation-of-the-package" class="anchor"></a>Installation of the  Package </h3>
<p>The development version of  can be installed using the  package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Install devtools, if not already installed.</span>
<span class="kw">install.packages</span>(<span class="st">"devtools"</span>)

<span class="co"># Install PCRedux</span>
devtools<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/devtools/topics/install_github">install_github</a></span>(<span class="st">"devSJR/PCRedux"</span>)</code></pre></div>
<p> is available as stable version from the omprehensive  rchive etwork (CRAN) at . Package published at CRAN undergo intensive checking procedures. In addition, CRAN tests whether the package can be built for common operating systems and whether all version dependencies are solved. To install  first install  (<span class="math inline">\(\geq\)</span> v. 3.3.3). Then start  and type in the prompt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Select your local mirror</span>
<span class="kw">install.packages</span>(<span class="st">"PCRedux"</span>)</code></pre></div>
<p>The  package should just install. If this failed make sure that write access is permitted to the destination directory and that all package dependencies are met.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The following command points to the help for download and install of packages</span>
<span class="co"># from CRAN-like repositories or from local files.</span>
?<span class="kw">install.packages</span>()</code></pre></div>
<p>If this fails try to follow the instructions given by <span class="citation">De Vries and Meys (2012)</span>.</p>
<blockquote>
<p>R CMD check</p>
</blockquote>
<p>Results from CRAN check can be found at</p>
<blockquote>
<p>.</p>
</blockquote>
</div>
<div id="unit-testing-of-the-package" class="section level3">
<h3 class="hasAnchor">
<a href="#unit-testing-of-the-package" class="anchor"></a>Unit Testing of the  Package </h3>
<p>Modules testing, better known as unit testing, is an approach to simplify the refactoring of source code during software development. Unit Testing is not a guarantee for error-free software. The goal is to minimize errors and regressions. It is also intended to ensure that the numerical results from the calculations are reproducible and of high quality. An unintended behavior of the software should be detected at the latest during the package building process <span class="citation">(Myers et al. 2004)</span>.</p>
<p><em>Checkpoints</em> are used to check whether the software performs calculations and data transformations correctly for all builds. For this, numerous (logical) queries have to be defined by the developer in advance. They are refereed to . It should be ensured that as many errors as possible are covered. A logical query can be, for example, whether the calculation has a numeric or Boolean value as output. If the data type is incorrect during output, this is a sufficient termination criterion. Or it can be checked whether the length of the result vector is correct after the calculation. There are different approaches for unit tests in . This also includes testing of units from the packages , ,  and . (<span class="citation">Wickham (2011)</span>).</p>
<p>The package  was used in  because it could be well implemented and its maintenance is relatively simple. The logic is that an  defines how the result, class or error in the corresponding unit (e. g., function) should behave. Unit tests can be found in the <code>/test/testthat</code> subdirectory of the  package. They are run automatically during the creation of the package. The following example for the <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code> function (for details see ) uses the <code>test_that()</code> [] function with the  that:</p>
<ul>
<li>an object of the class <em>fdata</em> is created (see <span class="citation">Febrero-Bande and Oviedo de la Fuente (2012)</span> for details of the class <em>fdata</em>),</li>
<li>the parameter <code>rangeval</code> has a length of two,</li>
<li>is the second value of parameter <code>rangeval</code> 49 (last cycle number) and *whether the object structure of the <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code> function does not change if the parameter <code>preprocess=TRUE</code> is set.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Expectations used for the unit testing of the qPCR2fdata() function.</span>
<span class="kw">library</span>(PCRedux)

<span class="kw">context</span>(<span class="st">"qPCR2fdata"</span>)

<span class="kw">test_that</span>(<span class="st">"qPCR2fdata gives the correct dimensions and properties"</span>, {
    <span class="kw">library</span>(qpcR)
    res_fdata &lt;-<span class="st"> </span><span class="kw"><a href="../reference/qPCR2fdata.html">qPCR2fdata</a></span>(testdat)
    res_fdata_preprocess &lt;-<span class="st"> </span><span class="kw"><a href="../reference/qPCR2fdata.html">qPCR2fdata</a></span>(testdat, <span class="dt">preprocess =</span> <span class="ot">TRUE</span>)
    
    <span class="kw">expect_that</span>(res_fdata, <span class="kw">is_a</span>(<span class="st">"fdata"</span>))
    <span class="kw">expect_that</span>(<span class="kw">length</span>(res_fdata<span class="op">$</span>rangeval) <span class="op">==</span><span class="st"> </span><span class="dv">2</span> <span class="op">&amp;&amp;</span>
<span class="st">    </span>res_fdata<span class="op">$</span>rangeval[<span class="dv">2</span>] <span class="op">==</span><span class="st"> </span><span class="dv">49</span>, <span class="kw">is_true</span>())
    
    <span class="kw">expect_that</span>(res_fdata_preprocess, <span class="kw">is_a</span>(<span class="st">"fdata"</span>))
    <span class="kw">expect_that</span>(<span class="kw">length</span>(res_fdata_preprocess<span class="op">$</span>rangeval) <span class="op">==</span><span class="st"> </span><span class="dv">2</span> <span class="op">&amp;&amp;</span>
<span class="st">    </span>res_fdata_preprocess<span class="op">$</span>rangeval[<span class="dv">2</span>] <span class="op">==</span><span class="st"> </span><span class="dv">49</span>, <span class="kw">is_true</span>())
})</code></pre></div>
<p>Further unit tests were implemented for all functions of the  package. The coverage by  package can be calculated by the <code>package_coverage()</code> [] function <span class="citation">(Hester 2018)</span> or visual analyzed via web-interface at:</p>
<blockquote>
<p>.</p>
</blockquote>

</div>
</div>
<div id="analysis-of-sigmoid-shaped-curves-for-data-mining-and-machine-learning-applications" class="section level2">
<h2 class="hasAnchor">
<a href="#analysis-of-sigmoid-shaped-curves-for-data-mining-and-machine-learning-applications" class="anchor"></a>Analysis of Sigmoid Shaped Curves for Data Mining and Machine Learning Applications</h2>
<p>The following sections describe the  regarding the analysis, numerical description and predictor calculation from a sigmoid curve. A predictor herein refers to a quantifiable <em>informative</em> property of a sigmoid curve. The predictors, sometimes referred to as descriptors, () can be used for applications such as data mining, machine learning and automatic classification (e. g., negative or positive amplification). The determination of quantification points such as the Cq value is a typical task during the analysis of qPCR experiments. This is briefly described in dedicated sections (ff.).</p>
<p>Characteristics of amplification curves that can be used for the statistical and analytical description are discussed () more in detail. The examples described focus on the concepts for <strong>binary (dichotomous) classification</strong> <span class="citation">(Kruppa et al. 2014)</span> as negative or positive. The mere binary classification into classes positive or negative is not necessarily the aim of the  package. Instead, it is aimed to provide a tool set for automatic <strong>multicategory (polychotomus) classification</strong> of amplification curves by any class conceivable. Such classification could be used for the quality of an amplification curve as negative, ambiguous and positive (A &amp; B). A definition for binary (dichotomous) classification and multicategory (polychotomus) classification is presented in <span class="citation">Kruppa et al. (2014)</span>.</p>
<div class="figure">
<img src="PCRedux_files/figure-html/htPCR_nap-1.png" alt="Examples of negative, ambiguous and positive amplification curves. A) A negative (black), ambiguous (red) and positive (green) amplification curve were selected from the `htPCR` data set. The negative amplification curve is non-sigmoid and has a positive trend. The ambiguous amplification curve is similar to a sigmoidic amplification curve, but shows a positive slope in ground phase (cycle 1 $\rightarrow$ 5). The positive amplification curve (green) is sigmoid. It starts with a flat baseline (cycle 5 $\rightarrow$ 25). This is followed by the exponential phase (cycle 5 $\rightarrow$ 25) and ends in a flat plateau phase (cycle 26 $\rightarrow$ 35). B) Amplification curves of the `vermeulen1` data set were divided into groups with \textit{negative}, \textit{ambiguous} and \textit{positive} classification. Negative amplification curves have a low signal level. Interesting is the spontaneous increase (probably due to a sensor calibration) in cycles 1 to 2 followed by a linear signal decrease. In principle, the ambiguous amplification curves have a sigmoid curve shape. However, the plateau phase is fairly broad. One of the ambiguous amplification curves begins to rise sharply at Cycle 45. The positive amplification curves have a characteristic sigmoid curve shape." width="700"><p class="caption">
Examples of negative, ambiguous and positive amplification curves. A) A negative (black), ambiguous (red) and positive (green) amplification curve were selected from the <code>htPCR</code> data set. The negative amplification curve is non-sigmoid and has a positive trend. The ambiguous amplification curve is similar to a sigmoidic amplification curve, but shows a positive slope in ground phase (cycle 1 <span class="math inline">\(\rightarrow\)</span> 5). The positive amplification curve (green) is sigmoid. It starts with a flat baseline (cycle 5 <span class="math inline">\(\rightarrow\)</span> 25). This is followed by the exponential phase (cycle 5 <span class="math inline">\(\rightarrow\)</span> 25) and ends in a flat plateau phase (cycle 26 <span class="math inline">\(\rightarrow\)</span> 35). B) Amplification curves of the <code>vermeulen1</code> data set were divided into groups with ,  and  classification. Negative amplification curves have a low signal level. Interesting is the spontaneous increase (probably due to a sensor calibration) in cycles 1 to 2 followed by a linear signal decrease. In principle, the ambiguous amplification curves have a sigmoid curve shape. However, the plateau phase is fairly broad. One of the ambiguous amplification curves begins to rise sharply at Cycle 45. The positive amplification curves have a characteristic sigmoid curve shape.
</p>
</div>
<div id="concepts-of-machine-learning" class="section level3">
<h3 class="hasAnchor">
<a href="#concepts-of-machine-learning" class="anchor"></a>Concepts of Machine Learning</h3>
<p>Data mining and machine learning can be used for descriptive and predictive tasks during the analysis of complex data sets. Data mining uses specific methods from statistical interference, software engineering and domain knowledge to get a better understanding of the data and to extract <em>hidden knowledge</em> from the pre-processed data <span class="citation">(Kruppa et al. 2014, <span class="citation">Herrera et al. (2016)</span>)</span>. All this implies that a human being interacts with the data at the different stages of the whole process as part of the workflow in data mining. Elements of the data mining process are the pre-processing of the data, the description of the data, the exploration of the data and the search for connections and causes.</p>
<p>The availability of classified amplification curve data sets and technologies for the classification of amplification curves is of high importance to train and validate models. This is dealt with in  and , respectively.</p>
<p>For machine learning, the type of learning task is the first thing that needs to be defined. The learning task can be a classification, clustering or regression problem. Next, suitable algorithms can be selected depending on the task. In the case of classification problems it is attempted to predict a <em>discrete valued</em> output. The labels (<span class="math inline">\(y\)</span>) are usually categorical and represent a finite number of classes (e.g. “negative”, “positive” -&gt; binary classification). With regression tasks, it is attempted to predict a <em>continuously valued</em> output. Clustering is primarily about forming groups (clusters) based on their similarities. Examples are presented in the following and following chapters.</p>
<p>In contrast, machine learning uses instructions and data in software modules to create models that can be used to make predictions on novel data. In machine learning, the human being is much less necessary in the entire process. Processes (algorithms) are used to create models with tunable parameters. These models automatically adapt their performance to the information (predictors) from the data. Well-known examples of machine learning technologies are Decision Trees (DT), Boosting, Random Forests (RF), Support Vector Machines (SVM), generalized linear models (GLM), logistic regression (LR) and deep neural networks (DNN) <span class="citation">(Lee 2010)</span>. The three following concepts of machine learning are frequently described in the literature:</p>
<p><em>Supervised learning</em>: These algorithms (e. g., SVM, DT, RF) learn from a training data set of labeled and annotated data (e. g., “positive” and “negative”). Classified training data can be created by one or more individuals. It is used for building a generalized model of all data. These algorithms use error or reward signals to evaluate the quality of a solution found <span class="citation">(Bischl et al. 2010, <span class="citation">Greene et al. (2014)</span>, <span class="citation">Igual and Seguí (2017)</span>)</span>. Binomial logistic regression (also referred to as logit regression or logit model) is used to gain knowledge about a binary relationship, by fitting a regression model <span class="math inline">\(y = f(x)\)</span>. <span class="math inline">\(y\)</span> is a categorical variable with two states (negative <span class="math inline">\(\rightarrow 0\)</span>, positive <span class="math inline">\(\rightarrow 1\)</span>). Typically, this model is used for predicting <span class="math inline">\(y\)</span> with a mixture of <span class="math inline">\(n\)</span> continuous and categorical predictors (features) <span class="math inline">\(x_{i1}, \ldots, x_{k1}, (i = 1, \ldots, n)\)</span>.</p>
<p>The logit model is a robust and versatile classification method to explain a dependent binary variable. Their codomain of real numbers is limited to [0,1]. Probabilities can therefore be utilized. The logistical distribution function <span class="math inline">\(F(\eta)\)</span>, also known as the response function, is strictly monotone increasing and limited to this range.</p>
<p><span class="math inline">\(\eta_{i}\)</span> establishes the link between the probability of the occurrence and the independent variables. For this reason, <span class="math inline">\(\eta_{i}\)</span> is referred to as a link function. The distribution function of the normal distribution is an alternative to the logistical distribution function. By using the normal distribution, the Probit model is obtained. However, since this is more difficult to interpret, it is less widely used in practice. Since probabilities are used, it is possible to make a prediction about the probability of occurrence of an event.</p>
<p>When analyzing amplification curves, diagnosis can be made whether a reaction was unsuccessful (0) or successful (1). For the prediction independent metric variables (predictors) are used. The metric variables have interpretable distances with a defined order. Their codomain is [-<span class="math inline">\(\infty\)</span>,<span class="math inline">\(\infty\)</span>]. The logistic distribution function on the independent variables determines the probability for <span class="math inline">\(Y_{i} = 0\)</span> or <span class="math inline">\(Y_{i} = 1\)</span>. A logistic regression model can be formulated as follows:</p>
<p><span class="math inline">\(F(\eta)=\frac{1}{1+exp(-\eta)}\)</span></p>
<p>The logistic regression analysis is based on the maximum-likelihood estimation (MLE). In contrast to linear regression, the probability for <span class="math inline">\(Y=1\)</span> is not modeled from explanatory variables. Rather, the logarithmic chance (logit) is used for the occurrence of <span class="math inline">\(Y=1\)</span>. The term <em>chance</em> refers to the ratio of the probability of occurrence of an event (e. g., amplification curve is positive) and the counter-probability (e. g., amplification curve is negative) of an event.</p>
<p><em>Unsupervised learning</em>: Algorithms, such as k-means clustering, kernel density estimation, LDA or PCA learn from training data sets of unlabeled or non-annotated data to find hidden structures according to geometric or statistical criteria <span class="citation">(Bischl et al. 2010, <span class="citation">Greene et al. (2014)</span>, <span class="citation">Igual and Seguí (2017)</span>)</span>.</p>
<p><em>Reinforcement Learning</em>: The algorithms learn by reinforcement from <em>criticism</em>. The criticisms inform the algorithm about the quality of the solution found but nothing about how to improve. These algorithms search by iterations the improved solution in the entire solution space <span class="citation">(Bischl et al. 2010, <span class="citation">Igual and Seguí (2017)</span>)</span>.</p>

</div>
<div id="why-is-there-is-need-for-the-software" class="section level3">
<h3 class="hasAnchor">
<a href="#why-is-there-is-need-for-the-software" class="anchor"></a>Why is there is need for the  software?</h3>
<p>The binary classification of an amplification curve is feasible using bioanalytical methods such as melting curve analysis <span class="citation">(Rödiger, Böhm, and Schimke 2013)</span> or electrophoretic separation <span class="citation">(Westermeier 2004)</span>. However, this is not always possible or desirable.</p>
<ul>
<li>Melting curve analysis is used in some qPCRs as a post-processing step to identify samples, which contain the specific target sequence (<em>positive</em>) based on a specific melting temperature. However, some detection probe systems like hydrolysis probes do not permit such classification. Moreover, nucleic acids with similar biochemical properties but different sequences may have the same melting temperature.</li>
<li>An electrophoretic separation (classification of target DNA sequences by size and quantity) often requires too much effort for experiments with high sample throughput.</li>
<li>There are mathematical qPCR analysis algorithms such as  <span class="citation">(J M Ruijter et al. 2009)</span> that require information on whether an amplification curve is negative or positive for subsequent calculation.</li>
<li>Raw data of amplification curves can be fitted with sigmoid functions. Sigmoid functions are non-linear, real-valued, have an S-shaped curvature () and be differentiated (e. g., first derivative maximum, with one local minimum and one local maximum). With the model obtained, predictions can be made. For example, the position of the second derivative maximum can be calculated from this (). In the context of amplification curves, the second derivative maximum is commonly used to describe the relationship between the cycle number and the PCR product formation (). All softwares assume that the amplification resemble a sigmoid curve shape (ideal positive amplification reaction), or a flat low line (ideal negative amplification reaction). For example, <span class="citation">Ritz and Spiess (2008)</span> published the   package that contains functions to fit several multi-parameter models. This includes the five-parameter Richardson function <span class="citation">(Richards 1959)</span> (). The  package <span class="citation">(Ritz and Spiess 2008)</span> contains an amplification curve test via the <code><a href="http://www.rdocumentation.org/packages/qpcR/topics/modlist">modlist()</a></code> function. The parameter <code>check="uni2"</code> offers an analytical approach, as part of a method for the kinetic outlier detection. It tries to checks for a sigmoid structure of the amplification curve. Then <code><a href="http://www.rdocumentation.org/packages/qpcR/topics/modlist">modlist()</a></code> tests for the location of the first derivative maximum and the second derivative maximum. However, multi-parameter functions fit “successful” in most cases including noise and give false positive results. This will be shown in later sections. This is exemplary shown in later sections in combination with the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/amptester">amptester()</a></code> [] function <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015)</span>. This function uses static thresholds and frequentist inference to identify amplification curves that exceed the threshold (<span class="math inline">\(\mapsto\)</span> classified as positive). However, the analysis can also lead to false-positive classifications as exemplified in the example below and in . Therefore, additional classification concepts would be beneficial.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the qpcR package for the model fit.</span>
<span class="kw">library</span>(qpcR)
<span class="kw">library</span>(chipPCR)

<span class="co"># Select one positive and one negative amplification curve from the PCRedux </span>
<span class="co"># package.</span>

amp_data &lt;-<span class="st"> </span>PCRedux<span class="op">::</span>RAS002[, <span class="kw">c</span>(<span class="st">"cyc"</span>, <span class="st">"A01_gDNA.._unkn_B.Globin"</span>, 
                                <span class="st">"B07_gDNA.._unkn_HPRT1"</span>)]

<span class="kw">colnames</span>(amp_data) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">"cyc"</span>, <span class="st">"positive"</span>, <span class="st">"negative"</span>)

<span class="co"># Arrange graphs in an matrix and set the plot parameters. An plot the positive</span>
<span class="co"># and negative amplification curve.</span>
hight &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">3100</span>, <span class="dv">4100</span>)

<span class="kw">plot</span>(<span class="ot">NA</span>, <span class="ot">NA</span>, <span class="dt">xlim =</span> <span class="kw">range</span>(amp_data[, <span class="st">"cyc"</span>]), 
        <span class="dt">ylim =</span> <span class="kw">range</span>(amp_data[, <span class="kw">c</span>(<span class="st">"positive"</span>, <span class="st">"negative"</span>)]),
        <span class="dt">xlab =</span> <span class="st">"Cycles"</span>, <span class="dt">ylab =</span> <span class="st">"RFU"</span>, <span class="dt">main =</span> <span class="st">""</span>)

<span class="co"># Apply the amptester() function from the chipPCR package to the amplification </span>
<span class="co"># curve data and write the results to the main of the plots.</span>

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span><span class="dv">3</span>) {
    res.ampt &lt;-<span class="st">  </span><span class="kw">suppressMessages</span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/chipPCR/topics/amptester">amptester</a></span>(amp_data[, i]))
    
    <span class="co"># Make a logical connection by two tests (shap.noisy, lrt.test and</span>
    <span class="co"># tht.dec) of amptester to decide if an amplification reaction is</span>
    <span class="co"># positive or negative.</span>
    decision &lt;-<span class="st"> </span><span class="kw">ifelse</span>(<span class="op">!</span>res.ampt<span class="op">@</span>decisions[<span class="dv">1</span>] <span class="op">&amp;&amp;</span>
<span class="st">    </span>res.ampt<span class="op">@</span>decisions[<span class="dv">2</span>] <span class="op">&amp;&amp;</span>
<span class="st">    </span>res.ampt<span class="op">@</span>decisions[<span class="dv">4</span>],
    <span class="st">"positive"</span>, <span class="st">"negative"</span>
    )
    <span class="co"># The amplification curves were fitted (l7 model) with pcrfit() function. </span>
    <span class="co"># The Cq was determined with the efficiency() function.</span>
    
    fit &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/qpcR/topics/pcrfit">pcrfit</a></span>(<span class="dt">data =</span> amp_data, <span class="dt">cyc =</span> <span class="dv">1</span>, <span class="dt">fluo =</span> i, <span class="dt">model =</span> l7)
    res &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/qpcR/topics/efficiency">efficiency</a></span>(fit, <span class="dt">plot =</span> <span class="ot">FALSE</span>)
    <span class="kw">lines</span>(<span class="kw">predict</span>(fit), <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">xlab =</span> <span class="st">"Cycles"</span>, <span class="dt">ylab =</span> <span class="st">"RFU"</span>, 
          <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">col =</span> i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)
    <span class="kw">abline</span>(<span class="dt">h =</span> res[[<span class="st">"fluo"</span>]], <span class="dt">col =</span> <span class="st">"grey"</span>)
    <span class="kw">points</span>(res[[<span class="st">"cpD2"</span>]], res[[<span class="st">"fluo"</span>]], <span class="dt">pch =</span> <span class="dv">19</span>)

    <span class="kw">legend</span>(<span class="dv">1</span>, hight[i<span class="op">-</span><span class="dv">1</span>], <span class="kw">paste0</span>(<span class="kw">colnames</span>(amp_data)[i], 
                                 <span class="st">"  curve -&gt;  Decision: "</span>, 
                                 decision, <span class="st">"    Cq: "</span>, res[[<span class="st">"cpD2"</span>]]), 
           <span class="dt">bty =</span> <span class="st">"n"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="st">"red"</span>
          )
}</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/curve_fit_fail-1.png" alt="Incorrect model adjustment for amplification curves. A positive (black) and a negative amplification curve (red) were randomly selected from the `RAS002` data set. The positive amplification curve has a baseline signal of about 2500 RFU and has a definite sigmoidal shape. The negative amplification curve has a baseline signal of approx. 4200 RFU, but only moderately positive slope (no sigmoidal shape). A logistic function with seven parameters (`l7`) has been fitted to both amplification curves. A Cq value of 25.95 was determined for the positive amplification curve. The negative amplification curve had a Cq value of 9.41. However, it can be seen that the latter model fitting is not appropriate for calculating a trustworthy Cq value. An automatic calculation without user control would give a false-positive result." width="576"><p class="caption">
Incorrect model adjustment for amplification curves. A positive (black) and a negative amplification curve (red) were randomly selected from the <code>RAS002</code> data set. The positive amplification curve has a baseline signal of about 2500 RFU and has a definite sigmoidal shape. The negative amplification curve has a baseline signal of approx. 4200 RFU, but only moderately positive slope (no sigmoidal shape). A logistic function with seven parameters (<code>l7</code>) has been fitted to both amplification curves. A Cq value of 25.95 was determined for the positive amplification curve. The negative amplification curve had a Cq value of 9.41. However, it can be seen that the latter model fitting is not appropriate for calculating a trustworthy Cq value. An automatic calculation without user control would give a false-positive result.
</p>
</div>
<ul>
<li>The analysis and classification of sigmoid data (e. g., quantitative PCR) it is a manageable task if the data volume is low, or dedicated analysis software is available. An example for a low number of amplification curves is shown in A. All 65 curves exhibit a sigmoid curve shape. It is trivial to classify them as positive by hand. In contrast, the vast number of amplification curves in B is barely manageable with a reasonable effort by simple visual inspection. These data originate from a high-throughput experiment that encompasses in total 8858 amplification curves of which only 200 are shown. A manual analysis of the data is time-consuming and prone to errors. Even for an experienced user it is difficult to classify the amplification curves unambiguously and reproducible as will be later shown in .</li>
<li>qPCRs are performed in thermo-cyclers, which are equipped with a real-time monitoring technology. There are numerous commercial manufactures, which produce thermo-cyclers (). An example for a thermo-cycler that originated in scientific project is the VideoScan technology <span class="citation">(Rödiger et al. 2013)</span>. Most of the thermo-cyclers have a thermal block with wells at certain positions. Reaction vessels containing the PCR mix are inserted into the wells. There are also thermo-cyclers that use capillary tubes that are heated and cooled by air (e. g., Roche Light Cycler 1.0). The thermo-cycler raises and lowers the temperature in the reaction vessels in discrete, pre-programmed steps so that the PCR can take place. Instruments with a real-time monitoring functionality have sensors to measure changes of the fluorescence intensity in the reaction vessel. All thermo-cycler systems use software to processes the amplification curves. Plots of the fluorescence observations versus cycle number obtained from two different qPCR systems is shown in A and B. The thermo-cyclers produce different amplification curve shapes even with the same sample material and PCR mastermix because of their technical design, sensors, and software. These factors need to be taken into account during the development of analysis algorithms.</li>
</ul>
<div class="figure">
<img src="PCRedux_files/figure-html/figure_sigmoid_curve_models-1.png" alt="A) Model function of a one-parameter sigmoid function. B) Model function of a sigmoid function with an intercept $n$ = 0.2 RFU (shift in base-line). C) Model function of a sigmoid function with an intercept ($n$ \textasciitilde 0.2 RFU) and a square portion $m * x^{2}, m = -0.0005, n = 0.2 RFU$ (hook-effect-like). D) Model function of a sigmoid function with an intercept ($n$) and a square portion of $m * x^{2}$ and additional noise $\epsilon$ (normal distributed, $\mu = 0.01, \sigma = 0.05$)." width="700"><p class="caption">
</p>
<ol style="list-style-type: upper-alpha"><li>Model function of a one-parameter sigmoid function. B) Model function of a sigmoid function with an intercept <span class="math inline">\(n\)</span> = 0.2 RFU (shift in base-line). C) Model function of a sigmoid function with an intercept (<span class="math inline">\(n\)</span> 0.2 RFU) and a square portion <span class="math inline">\(m * x^{2}, m = -0.0005, n = 0.2 RFU\)</span> (hook-effect-like). D) Model function of a sigmoid function with an intercept (<span class="math inline">\(n\)</span>) and a square portion of <span class="math inline">\(m * x^{2}\)</span> and additional noise <span class="math inline">\(\epsilon\)</span> (normal distributed, <span class="math inline">\(\mu = 0.01, \sigma = 0.05\)</span>).

</li></ol>
</div>

<div class="figure">
<img src="PCRedux_files/figure-html/figure_sigmoid_curve-1.png" alt="Amplification curve data from an iQ5 (Bio-Rad) thermo-cycler and a high throughput experiment in the Biomark HD (Fluidigm). A) The `C127EGHP` data set with 64 amplification curves was produced in conventional thermo-cycler with a 8 x 12 PCR grid. B) The `htPCR` data set, which contains 8858 amplification curves, was produced in a 95 x 96 PCR grid. Only 200 amplification curves are shown. In contrast to `A)` have all amplification curves in `B)` an off-set (intercept) between 0.09 and 0.40 RFU." width="700"><p class="caption">
Amplification curve data from an iQ5 (Bio-Rad) thermo-cycler and a high throughput experiment in the Biomark HD (Fluidigm). A) The <code>C127EGHP</code> data set with 64 amplification curves was produced in conventional thermo-cycler with a 8 x 12 PCR grid. B) The <code>htPCR</code> data set, which contains 8858 amplification curves, was produced in a 95 x 96 PCR grid. Only 200 amplification curves are shown. In contrast to <code>A)</code> have all amplification curves in <code>B)</code> an off-set (intercept) between 0.09 and 0.40 RFU.
</p>
</div>
</div>
<div id="software-for-the-analysis-of-amplification-curve-data" class="section level3">
<h3 class="hasAnchor">
<a href="#software-for-the-analysis-of-amplification-curve-data" class="anchor"></a>Software for the Analysis of Amplification Curve Data </h3>
<p>There are several open source and closed source software tools for the analysis of qPCR data <span class="citation">(Pabinger et al. 2014)</span>. The software packages deal for example with</p>
<ul>
<li>missing values and non-detects <span class="citation">(McCall et al. 2014)</span>,</li>
<li>noise and artifact removal <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015, <span class="citation">Rödiger et al. (2015)</span>, <span class="citation">Spiess et al. (2015)</span>, <span class="citation">Spiess et al. (2016)</span>)</span>,</li>
<li>inter run calibration <span class="citation">(Jan M. Ruijter et al. 2015)</span>,</li>
<li>normalization <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015, <span class="citation">Jan M. Ruijter et al. (2013)</span>, <span class="citation">Feuer et al. (2015)</span>, <span class="citation">Matz, Wright, and Scott (2013)</span>)</span>,</li>
<li>quantification cycle estimation <span class="citation">(Ritz and Spiess 2008, <span class="citation">Jan M. Ruijter et al. (2013)</span>)</span>,</li>
<li>amplification efficiency estimation <span class="citation">(Ritz and Spiess 2008, <span class="citation">Jan M. Ruijter et al. (2013)</span>)</span>,</li>
<li>data exchange <span class="citation">(Lefever et al. 2009, <span class="citation">Perkins et al. (2012)</span>, <span class="citation">Rödiger et al. (2017)</span>)</span>,</li>
<li>relative gene expression analysis <span class="citation">(Dvinge and Bertone 2009, <span class="citation">Pabinger et al. (2009)</span>, <span class="citation">Neve et al. (2014)</span>)</span> and</li>
<li>data analysis pipelines <span class="citation">(Pabinger et al. 2009, <span class="citation">Ronde et al. (2017)</span>, <span class="citation">Mallona, Weiss, and Egea-Cortines (2011)</span>, <span class="citation">Mallona et al. (2017)</span>)</span>.</li>
</ul>
<p>However, a bottleneck of qPCR data analysis is the lack of predictors and software to build classifiers for amplification curves. A classifier herein refers to a vector of predictors that can be used to distinguish the amplification curves by their shape only. A predictor, also referred to as <em>feature</em>, is an entity that characterizes an object. A few potential predictors for amplification curves are described in the literature. These include:</p>
<ul>
<li>the starting point (<em>takeoff</em>) of the amplification curve,</li>
<li>the Cq value and amplification efficiency, and</li>
<li>the signal level (e.g., slope and intercept of the ground phase).</li>
</ul>
<p>These alone are presumably not enough to describe amplification curves sufficiently. The number of predictors should be large enough to describe the object accurately and small enough not to interfere with the learning process with redundant or information. There are no references of algorithms in the scientific literature for the calculation of additional predictors from amplification curves. This makes studies on machine learning and modeling difficult.</p>
</div>
<div id="principles-of-amplification-curve-data-analysis-and-predictor-calculation" class="section level3">
<h3 class="hasAnchor">
<a href="#principles-of-amplification-curve-data-analysis-and-predictor-calculation" class="anchor"></a>Principles of Amplification Curve Data Analysis and Predictor Calculation</h3>
<p>The shape of a positive amplification curve has in most cases a sigmoid shape. Many factors, such as the sample quality, qPCR chemistry, and technical problems (e. g., sensor errors) contribute to various curve shapes <span class="citation">(Jan M. Ruijter et al. 2014)</span>. The curvature of the amplification curve can be used as a quality measure. For example, fragmentation, inhibitors and sample material handling errors during the extraction can be identified. The kinetic of fluoresce emission is proportional to the quantity of the synthesized DNA. Typical amplification curves have three phases.</p>
<ol style="list-style-type: decimal">
<li>
<strong>Ground phase</strong>: This phase occurs during the first cycles of the PCR. The fluorescence emission is in most cases flat. During the ground phase, only a weak and flat fluorescence signal is generated. Noise but no product formation is detected by the sensor system. The PCR product signal is an insignificantly small component of the total signal. This is often referred to as base-line or background signal. Apparently, there is only a phase shift or no signal at all. This is primarily due to the limited sensitivity of the instrument. Even in a perfect PCR reaction (double amplification per cycle), qPCR instruments cannot detect the fluorescence signal from the amplification. Fragmentation, inhibitors and sample handling errors would result in a prolonged ground phase. Nevertheless, this may indicate some typical properties of the qPCR system or probe system. In many instruments, this phase is used to determine the base-line level for the calculation of the Cycle threshold (Ct). The Ct value is considered statistically relevant increase outside the noise range. A signal that is far enough above this threshold is considered coming from the amplicon. In some qPCR systems a flat amplification signal is expected in this phase. Slight deviations from this trend are presumably due to changes (e. g., disintegration of probes) in the fluorophores. Background correction algorithms are often used here to ensure that flat amplification curves without slope are generated. However, this can result in errors and inevitably leads to a loss of information via the waveform of the raw data <span class="citation">(Nolan, Hands, and Bustin 2006)</span>. The slope, level and variance of this phase can serve as predictors.</li>
<li>
<strong>Exponential phase</strong>: This phase follows the ground phase and is also called <em>log phase</em>. This phase is characterized by a strong increase of the emitted fluorescence. In this phase, the DNA amount doubles in each cycle under ideal conditions. The amount of the synthesized fluorescent labeled PCR product is high enough to be detected by the sensor system. This phase is used for the calculation of the quantification point (Cq) and for the calculation of the curve specific amplification efficiency. The most important measurement from qPCRs is the cycle of quantification (Cq), which signifies at which PCR cycle the fluorescence exceeds a <code>threshold value</code>. There is an ongoing debate as to what a significant and robust threshold value is. An overview and performance comparison of Cq methods is given in <span class="citation">Jan M. Ruijter et al. (2013)</span>. There are several mathematical methods to calculate the Cq.
<ul>
<li>The ‘classical’ threshold value (cycle threshold, Ct) is the intersect between a manually defined straight horizontal line with the quasi-linear phase in the exponential amplification phase (A &amp; B). This simple to implement method requires that amplification curves are properly base-lined prior to the analysis. The Ct method makes the assumption that the amplification efficiency (~ slope in the log-linear phase) is equal across all amplification curves compared <span class="citation">(Jan M. Ruijter et al. 2013)</span>. Evidently, this is not always case as exemplified in C. The Ct method is widely used presumably due to the familiarity of users with this approach (e.g., chemical analysis procedures). However, this method is statistically unreliable <span class="citation">(Jan M. Ruijter et al. 2013, <span class="citation">Spiess et al. (2015)</span>, <span class="citation">Spiess et al. (2016)</span>)</span>. Moreover, the Ct method gives no stable in predictions if different users are given the same data set to be analyzed. <em>Therefore, this method is not used within the  package</em>.</li>
<li>Another Cq method uses the maximum of second derivative (SDM) <span class="citation">(Rödiger et al. 2015)</span> (C). In all cases the Cq value can be used to calculate the concentration of target sequence in a sample (low Cq high target concentration). In contrast, negative or ambiguous amplification curves loosely resemble noise. This noise may appear linear or exhibit an curvature similar to a specific amplification curve (). This however, may result in faulty interpretation of the amplification curves. Fragmentation, inhibitors and sample handling errors would decrease the slop of the amplification curve <span class="citation">(Spiess, Feig, and Ritz 2008, <span class="citation">Ritz and Spiess (2008)</span>)</span>. The slope and variation can be considered as predictors. Since the Cq depends on the initial template amount, and the amplification efficiency there is no immediate use of the Cq as predictor.</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>
<strong>Plateau phase</strong>: This phase follows the exponential phase. The cause for this lies in the exploitation of the limited resources (incl. primers, nucleotides, enzyme activity) in the reaction vessel. This limits the amplification reaction, so that the theoretical maximum amplification efficiency (doubling per cycle) no longer prevails. This turning point and the progressive limitation of resources finally leads to a plateau. In the plateau phase, there is sometime a signal decrease called <em>hook effect</em> ( and <span class="citation">(Barratt and Mackay 2002, <span class="citation">Isaac (2009)</span>)</span>). The slope (<em>hook effect</em>), level and variation can be considered as predictors.</li>
</ol>
</li>
</ol>
<p>If the amplification curve has only a slight positive slope and no perceptible exponential phase, it can be assumed that the amplification reaction did not occur (B). Causes may include poor specificity of the PCR primers (non-specific PCR products), degraded sample material, degraded probes or detector failures. If a lot of input DNA is present in a sample, the amplification curve starts to increase in early PCR cycles (1 - 12 cycles). Some PCR devices have software that corrects this data without checking it. This results in an amplification curve with a negative trend.</p>
<p>The discussed phases are considered as regions of interest (ROI). As an example, the  is in the head area, while the  is in the tail area. The  is located between these two ROIs.</p>
<div class="figure">
<img src="PCRedux_files/figure-html/amplification_curve_ROI-1.png" alt="Phases of application curves as Region of Interest (ROI). For amplification curves, the fluorescence signal (RFU, relative fluorescence units) of the reporter dye is plotted against the cycle number. Positive amplification curves have the three ROIs: ground phase, exponential phase and plateau phase. These ROIs can be used to determine predictors such as the takedown point (`tdp`) or the standard deviation within the ground phase (`sd\_bg`). The exponential range (red dots) is used to determine the Cq values and amplification efficiency (not shown). A linear regression model (red) can be used to calculate the slope in this region. B) PCRs without amplification reaction usually show a flat (non-sigmoides) signal. C) The exponential phase of PCR reactions can vary greatly depending on the DNA starting quantity and other factors. Amplification curves that appear in later cycles often have a lower slope in the exponential phase." width="768"><p class="caption">
Phases of application curves as Region of Interest (ROI). For amplification curves, the fluorescence signal (RFU, relative fluorescence units) of the reporter dye is plotted against the cycle number. Positive amplification curves have the three ROIs: ground phase, exponential phase and plateau phase. These ROIs can be used to determine predictors such as the takedown point (<code>tdp</code>) or the standard deviation within the ground phase (<code>sd\_bg</code>). The exponential range (red dots) is used to determine the Cq values and amplification efficiency (not shown). A linear regression model (red) can be used to calculate the slope in this region. B) PCRs without amplification reaction usually show a flat (non-sigmoides) signal. C) The exponential phase of PCR reactions can vary greatly depending on the DNA starting quantity and other factors. Amplification curves that appear in later cycles often have a lower slope in the exponential phase.
</p>
</div>
<p>The amplification curve shape, the amplification efficiency and the Cq value are important measures to judge the outcome of a qPCR reaction. In all phases of PCR the curves should be smooth. Possible artifacts in the curves may be due to unstable light sources from the instrument or problems during sample preparation, such as the presence of bubbles in the reaction vessel, incorrectly assigned dye detectors, errors during the calibration of dyes for the instrument, errors during the preparation of the PCR master mix, sample degradation, lack of a sample in the PCR, too much sample material in the PCR mix or a low detection probe concentration <span class="citation">(J M Ruijter et al. 2009, <span class="citation">Jan M. Ruijter et al. (2014)</span>, <span class="citation">Spiess et al. (2015)</span>)</span>. Smoothing and filtering cause alterations to the raw data that affects the Cq value and the amplification efficiency.</p>
<p>Most commercial qPCR systems do not display the raw data of the amplification curves on the screen. Instead, raw data are often processed by the instrument software to remove fluorophore-specific effects and noise in all ROI’s. Commonly employed pre-processing step of qPCR is smoothing and filtering to remove noise. Noise in amplification curves can have different causes <span class="citation">(Spiess et al. 2015)</span>.</p>
<p>The ordinate often does not display the measured fluorescence, but rather the change in fluorescence per cycle (<span class="math inline">\(\varDelta RFU = RFU_{cycle + 1} - RFU_{cycle}\)</span>). Some qPCR systems have a periodicity in the amplification curve data. Periodicity exposes the risk of introducing artificially shifts in the Cq values <span class="citation">(Spiess et al. 2016)</span>.</p>
<p>In particular the cycle threshold method (Ct method) () is affected by these factors <span class="citation">(Spiess et al. 2015, <span class="citation">Spiess et al. (2016)</span>)</span>. Therefore, it is advisable to clarify beforehand, which processing steps the amplification curves have been subjected to. Failure to do so may result in misinterpretations and incorrect amplification curve fitting models <span class="citation">(Nolan, Hands, and Bustin 2006, <span class="citation">Rödiger et al. (2015)</span>, <span class="citation">Rödiger, Burdukiewicz, and Schierack (2015)</span>, <span class="citation">Spiess et al. (2015)</span>)</span>.</p>
<div class="figure">
<img src="PCRedux_files/figure-html/figure_quntifcation_points-1.png" alt="Frequently used methods for the analysis of quantification points. A) The amplification curve is intersected by a grey horizontal line. This is the background signal (3$\sigma$) determined from the \textit{68-95-99.7 rule} from the fluorescence emission of cycles 1 to 10. The black horizontal line is the user-defined threshold (Ct value) in the exponential phase. Based on this, the cycle at which the amplification curve differs significantly from the background is calculated. B) The amplification curve can also be analyzed by fitting a multi-parametric model (black line, five parameters). The red line is the first derivative of the amplification curve with a maximum of 17.59 cycles. The first derivative maximum (`cpD1`) is used as a quantification point (Cq value) in some qPCR systems. The green line shows the second derivative of the amplification curve, with a maximum at 15.68 cycles a minimum at 19.5 cycles. The maximum of the second derivative (`cpD2`) is used as Cq value in many systems. The blue line shows the amplification efficiency estimated from the trajectory of the exponential region. The `Eff` value of 1.795 means that the amplification efficiency is approximately 89\%. `cpDdiff` is the difference between the first and second derivative maximum ($cpDdiff = cpD1 - cpD2$)." width="768"><p class="caption">
Frequently used methods for the analysis of quantification points. A) The amplification curve is intersected by a grey horizontal line. This is the background signal (3<span class="math inline">\(\sigma\)</span>) determined from the  from the fluorescence emission of cycles 1 to 10. The black horizontal line is the user-defined threshold (Ct value) in the exponential phase. Based on this, the cycle at which the amplification curve differs significantly from the background is calculated. B) The amplification curve can also be analyzed by fitting a multi-parametric model (black line, five parameters). The red line is the first derivative of the amplification curve with a maximum of 17.59 cycles. The first derivative maximum (<code>cpD1</code>) is used as a quantification point (Cq value) in some qPCR systems. The green line shows the second derivative of the amplification curve, with a maximum at 15.68 cycles a minimum at 19.5 cycles. The maximum of the second derivative (<code>cpD2</code>) is used as Cq value in many systems. The blue line shows the amplification efficiency estimated from the trajectory of the exponential region. The <code>Eff</code> value of 1.795 means that the amplification efficiency is approximately 89%. <code>cpDdiff</code> is the difference between the first and second derivative maximum (<span class="math inline">\(cpDdiff = cpD1 - cpD2\)</span>).
</p>
</div>

</div>
</div>
<div id="technologies-for-amplification-curve-classification-and-classified-amplification-curves" class="section level2">
<h2 class="hasAnchor">
<a href="#technologies-for-amplification-curve-classification-and-classified-amplification-curves" class="anchor"></a>Technologies for Amplification Curve Classification and Classified Amplification Curves</h2>
<p>Many machine learning concepts exist. One method is supervised machine learning, where the goal is to derive a property from user-defined (classified) training data. Categories such as negative, ambiguous or positive are assigned depending on the form of the amplification curve. An extensive literature research showed that there are no openly accessible classified amplification curve data sets. Open Data is meant in the sense that data are freely available, free of charge, free to use and that data can be republished, without restrictions from copyright, patents or other mechanisms of control <span class="citation">(Kitchin 2014)</span>.</p>
<p>Therefore, a large number of records with amplification curves and their classification (negative, ambiguous, positive) were added to the  package.</p>
<p>For the amplification curves in , a dichotomous classification was performed (roughly sigmoid or negative amplification reaction with a flat curve shape). Consequently, this does not rule out</p>
<ul>
<li>if a specific amplification product has been synthesized,</li>
<li>if a contamination has been amplified or</li>
<li>if only primer-dimers have been amplified.</li>
</ul>
<p>To answer this question, other methods such as agarosegel electrophoresis need to be used.</p>
<div id="manual-amplification-curve-classification" class="section level3">
<h3 class="hasAnchor">
<a href="#manual-amplification-curve-classification" class="anchor"></a>Manual Amplification Curve Classification</h3>
<p>For machine learning and method validation it was important to classify the amplification curves individually. In <span class="citation">Rödiger, Burdukiewicz, and Schierack (2015)</span> the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/humanrater">humanrater()</a></code> [] function was described. This function was developed to help the user during the classification of amplification curves and melting curves. The user has to define classes, which get assigned to an amplification curve after expert has entered the class in input mask.</p>
<blockquote>
<p>By convention, class labels were specified as e. g., negative (“n”), ambiguous (“a”), positive (“y”) in the  package.</p>
</blockquote>
<p>All amplification curve data sets listed in  were classified in interactive, semi-blinded sessions. <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/humanrater">humanrater()</a></code> [] was set to randomly select individual amplification curves. All data sets were manually classified at least three times. The <code>htPCR</code> data set (B) was in total classified eight times (see ). Most of the amplification curves are neither unequivocal classifiable as positive or negative.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Suppress messages and load the packages for reading the data of the classified</span>
<span class="co"># amplification curves.</span>
<span class="kw">library</span>(PCRedux)

<span class="co"># Load the decision_res_htPCR.csv data set from a csv file.</span>
filename &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">"decision_res_htPCR.csv"</span>, <span class="dt">package =</span> <span class="st">"PCRedux"</span>)
decision_res_htPCR &lt;-<span class="st"> </span>data.table<span class="op">::</span><span class="kw">fread</span>(filename, <span class="dt">data.table =</span> <span class="ot">FALSE</span>)

<span class="co"># Create graphic device for the plot(s)</span>
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">4</span>))
<span class="cf">for</span> (i <span class="cf">in</span> 2L<span class="op">:</span><span class="dv">9</span>) {
    data_tmp &lt;-<span class="st"> </span><span class="kw">table</span>(<span class="kw">as.factor</span>(decision_res_htPCR[, i]))
    
    <span class="kw">barplot</span>(data_tmp, <span class="dt">col =</span> <span class="kw">adjustcolor</span>(<span class="st">"grey"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.5</span>),
            <span class="dt">xlab =</span> <span class="st">"Class"</span>, <span class="dt">ylab =</span> <span class="st">"Counts"</span>, <span class="dt">border =</span> <span class="st">"white"</span>)
    <span class="kw">text</span>(<span class="kw">c</span>(<span class="fl">0.7</span>, <span class="fl">1.9</span>, <span class="fl">3.1</span>), <span class="kw">rep</span>(<span class="kw">quantile</span>(data_tmp, <span class="fl">0.25</span>), <span class="dv">3</span>), 
         data_tmp, <span class="dt">srt =</span> <span class="dv">90</span>)
    <span class="kw">mtext</span>(LETTERS[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>], <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)
}</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/figure_curve_classification-1.png" alt="Variations of the classification of amplification curves. A prerequisite for the development of machine-learning models is the availability of manually classified amplification curves. Amplification curves (n = 8858) from the `htPCR` data set have been classified by one user eight times at different points over time (classes: ambiguous (a), positive (y) or negative (n)). During this process, the amplification curves were presented in random order. The example shows that different (subjective) class mappings may occur for the same data set. While only a few amplification curves were classified as negative in the first three classification cycles (A-C), their proportion increased almost tenfold in later classification cycles (D-H)." width="700"><p class="caption">
Variations of the classification of amplification curves. A prerequisite for the development of machine-learning models is the availability of manually classified amplification curves. Amplification curves (n = 8858) from the <code>htPCR</code> data set have been classified by one user eight times at different points over time (classes: ambiguous (a), positive (y) or negative (n)). During this process, the amplification curves were presented in random order. The example shows that different (subjective) class mappings may occur for the same data set. While only a few amplification curves were classified as negative in the first three classification cycles (A-C), their proportion increased almost tenfold in later classification cycles (D-H).
</p>
</div>
<p>This approach is well suited and has been applied to classify a variety of amplification curves during the development of the  package. From experience this is time-consuming and tiring for large data sets, especially when the amplification curves are similar in shape. A high similarity between amplification curves exists, for example, in replicates and negative controls.</p>
</div>
<div id="treem---a-function-for-shape-based-group-wise-classification-of-amplification-curves" class="section level3">
<h3 class="hasAnchor">
<a href="#treem---a-function-for-shape-based-group-wise-classification-of-amplification-curves" class="anchor"></a><code><a href="../reference/tReem.html">tReem()</a></code> - A Function for Shape-based Group-wise Classification of Amplification Curves</h3>
<p>The similarity of amplification curves can be used to form groups of similar shapes. The amplification curves in the groups can then be classified in a bulk. In this way, a higher throughput can be achieved. This concept has not been described for the analysis of qPCR data in the literature.</p>
<p>The <code><a href="../reference/tReem.html">tReem()</a></code> function was developed to perform a <em>shape-based group classification</em>. To use the <code><a href="../reference/tReem.html">tReem()</a></code> function, the first column must contain the qPCR cycles and all subsequent columns must contain the amplification curves. Two measures of similarity are used within the <code><a href="../reference/tReem.html">tReem()</a></code> function.</p>
<ul>
<li><p>In the first measure (default), the Pearson <em>correlation coefficient</em>s (<em>r</em>) are determined in pairs for all combinations of the amplification curves. The correlation coefficient is a statistical measure to describe the strength of the correlation between two or more variables. The correlation coefficient <em>r</em> is regarded as distance between the amplification curves. <em>r</em> is a dimensionless value and only takes values between -1 and 1. If <em>r = -1</em>, there is a maximum reciprocal relationship. If <em>r = 0</em> there is no correlation between the two variables. If <em>r = 1</em>, there is a maximum rectified correlation.</p></li>
<li><p>In the second measure, the <em>Hausdorff distance</em> is used to determine the similarity between amplification curves. The Hausdorff distance is “the maximum of the distances from a point in any of the sets to the nearest point in the other set” <span class="citation">(Rote 1991, <span class="citation">Herrera et al. (2016)</span>)</span>. The amplification curves are converted within the <code><a href="../reference/tReem.html">tReem()</a></code> function using the <code>qPCR2data()</code> function.</p></li>
</ul>
<p>Both methods process the distances in the same steps. This involves the calculation of the distance matrix using the Euclidean distances of all distance measures to determine the distance between the lines of the data matrix.</p>
<p>This is used to perform a hierarchical cluster analysis. In the last step, the cluster is divided into groups based on a user-defined <em>k</em> value. For example, two groups are created for <em>k = 2</em>. If the amplification curves shapes are highly diverse, a larger <em>k</em> should be used. After a chain of processing steps presents the <code><a href="../reference/tReem.html">tReem()</a></code> function a series of plots with grouped of amplification curves. The corresponding classes can then be assigned to the groups of amplification curves by the user using an input mask.</p>
<p>Grouping the amplification curves with the Pearson correlation coefficient as a distance measure is usually faster than the Hausdorff distance. The Hausdorff distance is an approximation of a shape metrics to define similarity measures between shapes. <span class="citation">(Charpiat, Faugeras, and Keriven 2003)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Classify amplification curve data by correlation coefficients (r)</span>
data &lt;-<span class="st"> </span>qpcR<span class="op">::</span>testdat

classification_result &lt;-<span class="st"> </span><span class="kw"><a href="../reference/tReem.html">tReem</a></span>(data[, <span class="dv">1</span><span class="op">:</span><span class="dv">15</span>], <span class="dt">k =</span> <span class="dv">3</span>)
classification_result</code></pre></div>
</div>
<div id="decision_modus---a-function-to-get-a-decision-modus-from-a-vector-of-classes" class="section level3">
<h3 class="hasAnchor">
<a href="#decision_modus---a-function-to-get-a-decision-modus-from-a-vector-of-classes" class="anchor"></a><code><a href="../reference/decision_modus.html">decision_modus()</a></code> - A Function to Get a Decision (Modus) from a Vector of Classes </h3>
<p>For the systematic statistical analysis of classification data sets, the <code><a href="../reference/decision_modus.html">decision_modus()</a></code> function has been developed. This allows the most common decision (mode) to be determined. The mode is useful to consolidate large collections of different decisions into a single (most frequent) decision.</p>
<blockquote>
<p>Observed:<em>a</em>, <em>a</em>, <em>a</em>, <em>a</em>, <em>a</em>, <em>n</em>, <em>n</em>, <em>n</em> <span class="math inline">\(\rightarrow\)</span> frequencies 5 x <em>a</em>, 3 x <em>n</em> <span class="math inline">\(\rightarrow\)</span> mode: <em>a</em>. Since the class names are known, they only have to be interpreted by the user (e. g., “a”,<em>n</em>,“y” -&gt; “ambivalent”,“negative”,“positive”).</p>
</blockquote>
<p>A manual classification was performed out for the <code>htPCR</code> data set (for an example plot B) with the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/humanrater">humanrater()</a></code> function. The classification of each amplification curve was performed eight times at different time points since many of the amplification curves did not resemble optimal curvatures (e.g., ). It is likely that the amplification curve (P06.W47, ) is considered as ambiguous or even positive (positive <span class="math inline">\(\leftrightarrow\)</span> ambivalent) by the users.</p>
<p> shows from a total of 8858 amplification curves the first 25 lines classified as negative (<em>conformity=TRUE</em>) and the first 25 lines classified as positive. Since in total, the curves were classified eight times (<code>test.result.1</code> <span class="math inline">\(\ldots\)</span> <code>test.result.8</code>) a whole of 70864 amplification curves was analysed. In this classification experiment the amplification curves have been classified differently in 94.5% of the cases (e. g., line 1 “P01. W01”).</p>

<p>The <code><a href="../reference/decision_modus.html">decision_modus()</a></code> function was applied to the record <code>decision_res_htPCR.csv</code> with all classification rounds (columns 2 to 9) and the mode was determined for each amplitude curve .</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Use decision_modus() to go through each row of all classification done by</span>
<span class="co"># a human.</span>

<span class="co"># Determine the number of observations where all classifications were </span>
<span class="co"># the same (conformity == TRUE).</span>
conformity &lt;-<span class="st"> </span>decision_res_htPCR[[<span class="st">"conformity"</span>]]

<span class="co"># List all classifications.</span>
dec &lt;-<span class="st"> </span><span class="kw">lapply</span>(1L<span class="op">:</span><span class="kw">nrow</span>(decision_res_htPCR), <span class="cf">function</span>(i) {
    <span class="kw"><a href="../reference/decision_modus.html">decision_modus</a></span>(decision_res_htPCR[i, <span class="dv">2</span><span class="op">:</span><span class="dv">9</span>])[<span class="dv">1</span>]
}) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()

<span class="co"># Show statistic of the decisions</span>
<span class="kw">summary</span>(dec)</code></pre></div>
<pre><code>##    a    n    y 
## 1266 4264 3328</code></pre>
<div class="figure">
<img src="PCRedux_files/figure-html/htPCR_nap_frequency-1.png" alt="Frequency of amplification curve classes and conformity in the `htPCR` data set. The `htPCR` data set was classified by hand eight times. Due to the unusual amplification curve shape and input errors during classification, many amplification curves were classified differently. A) Frequency of negative (black), ambiguous (red) and positive (green) amplification curves in the `htPCR` data set. The combined number of ambiguous and negative amplification curves appears to be higher, than the number of positive amplification curves. B) The number of observations where all classification cycles made the same decision (conformity == TRUE) accounts for only 5\% of the total number of observations. TRUE, all classes of the amplification curve matched. FALSE, at least one in eight observations had a different class." width="700"><p class="caption">
Frequency of amplification curve classes and conformity in the <code>htPCR</code> data set. The <code>htPCR</code> data set was classified by hand eight times. Due to the unusual amplification curve shape and input errors during classification, many amplification curves were classified differently. A) Frequency of negative (black), ambiguous (red) and positive (green) amplification curves in the <code>htPCR</code> data set. The combined number of ambiguous and negative amplification curves appears to be higher, than the number of positive amplification curves. B) The number of observations where all classification cycles made the same decision (conformity == TRUE) accounts for only 5% of the total number of observations. TRUE, all classes of the amplification curve matched. FALSE, at least one in eight observations had a different class.
</p>
</div>
<p>Another usage mode of <code><a href="../reference/decision_modus.html">decision_modus()</a></code> is to set the parameter as <code>max_freq=FALSE</code>. This option specifies the number of all classifications.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PCRedux)
<span class="co"># Decisions for observation P01.W06</span>
res_dec_P01.W06 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/decision_modus.html">decision_modus</a></span>(decision_res_htPCR[
<span class="kw">which</span>(decision_res_htPCR[[<span class="st">"htPCR"</span>]] <span class="op">==</span><span class="st"> "P01.W06"</span>),
                                  2L<span class="op">:</span><span class="dv">9</span>
], <span class="dt">max_freq =</span> <span class="ot">FALSE</span>)
<span class="kw">print</span>(res_dec_P01.W06)</code></pre></div>
<pre><code>##   variable freq
## 1        a    3
## 2        n    5</code></pre>
<p>The amplification curve <code>P01. W06</code> was classified as a=3 times and as n=5 times. Therefore, the decision would turn into a <code>negative</code> decision.</p>
</div>
<div id="classified-amplification-curve-datasets" class="section level3">
<h3 class="hasAnchor">
<a href="#classified-amplification-curve-datasets" class="anchor"></a>Classified Amplification Curve Datasets</h3>
<p>Amplification curves from different sources (e.g., detection chemistries, thermo-cyclers) were manually classified with the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/humanrater">humanrater()</a></code> function () or with the <code><a href="../reference/tReem.html">tReem()</a></code> function (). Raw amplification curve data were exported as comma separated values or in the Real-time PCR Data Markup Language (RDML) format via the  package. RDML is human readable data exchange format for qPCR experiments. A detailed description can be found in <span class="citation">Rödiger et al. (2017)</span>. The following code section describes the import of an RDML file from the  package. The RDML file contains amplification curve data of a duplex qPCR (HPV 16 &amp; HPV 18) performed in the CFX96 (Bio-Rad).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(RDML)
<span class="co"># Load the RDML package and use its functions to import the amplification curve</span>
<span class="co">#  data</span>
<span class="kw">library</span>(RDML)
filename &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">"RAS002.rdml"</span>, <span class="dt">package =</span> <span class="st">"PCRedux"</span>)
raw_data &lt;-<span class="st"> </span>RDML<span class="op">$</span><span class="kw"><a href="http://www.rdocumentation.org/packages/RDML/topics/new-method">new</a></span>(<span class="dt">filename =</span> filename)</code></pre></div>
<p>The following example shows the export of the <code>RAS002.rdml</code> file from the RDML format to the csv format.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Export the RDML data from the PCRedux package as the objects RAS002 and RAS003.</span>
<span class="kw">library</span>(RDML)
<span class="kw">library</span>(PCRedux)
<span class="kw">library</span>(data.table)

RAS002 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(RDML<span class="op">$</span><span class="kw"><a href="http://www.rdocumentation.org/packages/RDML/topics/new-method">new</a></span>(<span class="kw">paste0</span>(
    <span class="kw">path.package</span>(<span class="st">"PCRedux"</span>), <span class="st">"/"</span>, <span class="st">"RAS002.rdml"</span>))<span class="op">$</span><span class="kw"><a href="http://www.rdocumentation.org/packages/RDML/topics/GetFData-function">GetFData</a></span>()
    )

<span class="co"># The obbject RAS002 can be stored in the working directory as CSV file with</span>
<span class="co"># the name RAS002_amp.csv.</span>
<span class="kw">write.csv</span>(RAS002, <span class="st">"RAS002_amp.csv"</span>, <span class="dt">row.names =</span> <span class="ot">FALSE</span>)</code></pre></div>
<table class="table">
<thead><tr class="header">
<th>RDML data file</th>
<th>Device</th>
<th>Target gene</th>
<th>Detection chemistry</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>RAS002.rdml</td>
<td>CFX96</td>
<td>HPV16, HPV18, HPRT1</td>
<td>Taqman</td>
</tr>
<tr class="even">
<td>RAS003.rdml</td>
<td>CFX96</td>
<td>HPV16, HPV18, HPRT1</td>
<td>Taqman</td>
</tr>
<tr class="odd">
<td>hookreg.rdml</td>
<td>Bio-Rad</td>
<td>various</td>
<td>Taqman, DNA binding dyes</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="data-analysis-functions-of-the-package" class="section level2">
<h2 class="hasAnchor">
<a href="#data-analysis-functions-of-the-package" class="anchor"></a>Data Analysis Functions of the  Package </h2>
<p>The  package contains functions for analyzing amplification curves. In the following, these are distinguished into helper functions () and analysis functions ().</p>
<div id="helper-functions-of-the-package" class="section level3">
<h3 class="hasAnchor">
<a href="#helper-functions-of-the-package" class="anchor"></a>Helper Functions of the  Package </h3>
<div id="performer---performance-analysis-for-binary-classification" class="section level4">
<h4 class="hasAnchor">
<a href="#performer---performance-analysis-for-binary-classification" class="anchor"></a><code><a href="../reference/performeR.html">performeR()</a></code> - Performance Analysis for Binary Classification </h4>
<p>Statistical modeling and machine learning is powerful but expose a risk to the user by introducing an unexpected bias. This may lead to an overestimation of the performance. The assessment of the performance by the sensitivity and specificity is fundamental to characterize a classifier or screening test <span class="citation">(G. James et al. 2013)</span>. Sensitivity is the percentage of true decisions that are identified and specificity is the percentage of negative decision that are correctly identified (). An example for the application of the <code><a href="../reference/performeR.html">performeR()</a></code> function is shown in .</p>

</div>
<div id="qpcr2fdata---a-helper-function-to-convert-amplification-curve-data-to-the-fdata-format" class="section level4">
<h4 class="hasAnchor">
<a href="#qpcr2fdata---a-helper-function-to-convert-amplification-curve-data-to-the-fdata-format" class="anchor"></a><code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code> - A Helper Function to Convert Amplification Curve Data to the <code>fdata</code> Format </h4>
<p><code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code> is a helper function to convert amplification curve data to the functional <code>fdata</code> class <span class="citation">(Febrero-Bande and Oviedo de la Fuente 2012)</span>. The <code>fdata</code> format is used for functional data analysis to determine the similarity measures between amplification curves shapes by the Hausdorff distance. Similarity herein refers to the difference in spatial location of two  (e. g., amplification curves). Objects with a close distance are presumably more similar. For single objects (e. g., points) one can use a vector distance, such as the Euclidean distance <span class="citation">(Herrera et al. 2016)</span>.</p>
<p>The <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code> function takes a <code>data.frame</code> containing the amplification cycles (first column) and the fluorescence amplitudes (subsequent columns) as input.</p>
<p>Noise and missing values may affect the analysis adversely. Therefore, an instance of the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/CPP">CPP()</a></code> [] function <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015)</span> was integrated in <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code>. If  in <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code>, then all curves are smoothed (Savitzky-Golay smoother), missing values are imputated and outliers in the ground phase get removed as described in <span class="citation">Rödiger, Burdukiewicz, and Schierack (2015)</span>.</p>
<p>The following example illustrates a hierarchical cluster analysis the <code>testdat</code> data set. The amplification curves of the <code>testdat</code> data set remained as raw data or were pre-processed (smoothed). Subsequent, the amplification curves were converted by the <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code>. The converted data were subjected to a cluster analysis (Hausdorff distance). This method uses the elements of a proximity matrix to generate a dendrogram. The dendrogram can can be used to further analyze the clusters. There are methods to determine the number of clusters automatically  <span class="citation">(Cook and Swayne 2007)</span>. However, for simplicity the number of clusters was determined visually.</p>
<p>The distance based on the Hausdorff metric was already done the next steps involved the <code>cutree()</code> [] function to split the dendrogram into smaller junks. <em>A priori</em> was defined that two classes ( &amp; ) are expected. Therefore, the  parameter was set to =2 in the <code>cutree()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate the Hausdorff distance of the amplification curves</span>
<span class="co"># cluster the curves.</span>
<span class="co"># Load additional packages for data and pipes.</span>
<span class="kw">library</span>(fda.usc)

data &lt;-<span class="st"> </span>qpcR<span class="op">::</span>testdat

<span class="co"># Convert the qPCR data set to the fdata format</span>
<span class="co"># Use unprocessed data from the testdat data set</span>
res_fdata &lt;-<span class="st"> </span><span class="kw"><a href="../reference/qPCR2fdata.html">qPCR2fdata</a></span>(data)

<span class="co"># Extract column names and create rainbow color to label the data</span>
columnames &lt;-<span class="st"> </span>data[<span class="op">-</span><span class="dv">1</span>] -&gt;.; <span class="kw">colnames</span>(.)</code></pre></div>
<pre><code>##  [1] "F1.1" "F1.2" "F1.3" "F1.4" "F2.1" "F2.2" "F2.3" "F2.4" "F3.1" "F3.2"
## [11] "F3.3" "F3.4" "F4.1" "F4.2" "F4.3" "F4.4" "F5.1" "F5.2" "F5.3" "F5.4"
## [21] "F6.1" "F6.2" "F6.3" "F6.4"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">colors &lt;-<span class="st"> </span><span class="kw">rainbow</span>(<span class="kw">length</span>(columnames), <span class="dt">alpha =</span> <span class="fl">0.5</span>)

<span class="co"># Calculate the Hausdorff distance (fda.usc) package and plot the distances</span>
<span class="co"># as clustered data.</span>

res_fdata_hclust &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/fda.usc/topics/metric.hausdorff">metric.hausdorff</a></span>(res_fdata)
res_hclust &lt;-<span class="st"> </span><span class="kw">hclust</span>(<span class="kw">as.dist</span>(res_fdata_hclust))</code></pre></div>
<p>The distance based on the Hausdorff metric was already done the next steps involved the <code>cutree()</code> [] function to split the dendrogram into smaller junks. <em>A priori</em> was defined that two classes ( &amp; ) are expected. Therefore, the  parameter was set to =2 in the <code>cutree()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Cluster of the unprocessed amplification curves</span>
res_cutree &lt;-<span class="st"> </span><span class="kw">cutree</span>(res_hclust, <span class="dt">k =</span> <span class="dv">2</span>)
res_cutree &lt;-<span class="st"> </span><span class="kw">factor</span>(res_cutree)
<span class="kw">levels</span>(res_cutree) &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">y =</span> <span class="st">"1"</span>, <span class="dt">n =</span> <span class="st">"2"</span>)</code></pre></div>
<p>The dendrogram shows that</p>
<ul>
<li>the observations are correctly assigned to a cluster of positive or negative amplification curves and that</li>
<li>the shift of the Cq (late increase of the fluorescence) is reflected in the positive cluster ().</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Plot the converted qPCR data</span>
<span class="co"># Create graphic device for the plot(s)</span>
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))

<span class="kw">plot</span>(res_fdata, <span class="dt">xlab =</span> <span class="st">"Cycles"</span>, <span class="dt">ylab =</span> <span class="st">"RFU"</span>, <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">type =</span> <span class="st">"l"</span>,
        <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> colors
)
<span class="kw">legend</span>(
    <span class="st">"topleft"</span>, <span class="kw">paste0</span>(<span class="kw">as.character</span>(columnames), <span class="st">": "</span>, res_cutree),
       <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">col =</span> colors, <span class="dt">bty =</span> <span class="st">"n"</span>, <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">cex =</span> <span class="fl">0.7</span>
)
<span class="kw">mtext</span>(<span class="st">"A"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)

<span class="kw">plot</span>(res_hclust, <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">xlab =</span> <span class="st">""</span>, <span class="dt">sub=</span><span class="st">""</span>)
<span class="kw">text</span>(<span class="kw">c</span>(<span class="fl">5.5</span>,<span class="dv">18</span>), <span class="kw">rep</span>(<span class="fl">6.5</span>,<span class="dv">2</span>), <span class="kw">c</span>(<span class="st">"negative"</span>, <span class="st">"positive"</span>), 
     <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">"black"</span>, <span class="st">"green"</span>), <span class="dt">cex =</span> <span class="fl">0.9</span>, <span class="dt">srt =</span> <span class="dv">90</span>)
<span class="kw">mtext</span>(<span class="st">"B"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/qPCR2fdata-1.png" alt="Shape-based grouping of amplification curves. A) The grouping of the amplification curves of the `testdat` data set (A) was based on the Hausdorff distance. B) The amplification curves were converted with the ``qPCR2fdata()`` function and the Hausdorff distance of the curves to each other was determined by a cluster analysis. There were no errors in distinguishing between negative (n) and positive (y) amplification curves." width="768"><p class="caption">
Shape-based grouping of amplification curves. A) The grouping of the amplification curves of the <code>testdat</code> data set (A) was based on the Hausdorff distance. B) The amplification curves were converted with the <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code> function and the Hausdorff distance of the curves to each other was determined by a cluster analysis. There were no errors in distinguishing between negative (n) and positive (y) amplification curves.
</p>
</div>
<p>This workflow can be used to cluster amplification curve data according to their shape into groups of amplification curves with similar shape. Classification tasks can be preformed in batches of amplification curves. The calculation of the distances is a computing expensive step dependent on the number of amplification curves.</p>
<p>The following example illustrates the usage for the <code>HCU32_aggR.csv</code> data set from the VideoScan platform with 32 heating and cooling units (equivalent of 32 PCR vessels). In this experiment the bacterial gene <em>aggR</em> from <em>E. coli</em> was amplified in 32 replicate qPCR reactions. Details of the experiment are described in the manual of the  package. The ambition was to test if the 32 amplification curves of the qPCR reaction are identical. As before, the data were processed with the <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code> function and compared by the Hausdorff distance. Ideally, the amplification curves form only few clusters.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate slope and intercept on positive amplification curve data from the</span>
<span class="co"># VideoScan 32 cavity real-time PCR device.</span>
<span class="co"># Use the fda.usc package for functional data analysis</span>
<span class="kw">library</span>(data.table)
<span class="kw">library</span>(fda.usc)

<span class="co"># Load the qPCR data from the HCU32_aggR.csv data set</span>
<span class="co"># Convert the qPCR data set to the fdata format</span>

filename &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">"HCU32_aggR.csv"</span>, <span class="dt">package =</span> <span class="st">"PCRedux"</span>)
data_32HCU &lt;-<span class="st"> </span>data.table<span class="op">::</span><span class="kw">fread</span>(filename, <span class="dt">data.table =</span> <span class="ot">FALSE</span>)

res_fdata &lt;-<span class="st"> </span><span class="kw"><a href="../reference/qPCR2fdata.html">qPCR2fdata</a></span>(data_32HCU)
<span class="co"># Extract column names and create rainbow color to label the data</span>
columnames &lt;-<span class="st"> </span>data_32HCU[<span class="op">-</span><span class="dv">1</span>] -&gt;.; <span class="kw">colnames</span>(.)</code></pre></div>
<pre><code>##  [1] "A1" "B1" "C1" "D1" "E1" "F1" "G1" "H1" "A2" "B2" "C2" "D2" "E2" "F2"
## [15] "G2" "H2" "A3" "B3" "C3" "D3" "E3" "F3" "G3" "H3" "A4" "B4" "C4" "D4"
## [29] "E4" "F4" "G4" "H4"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">colors &lt;-<span class="st"> </span><span class="kw">rainbow</span>(<span class="kw">length</span>(columnames), <span class="dt">alpha =</span> <span class="fl">0.55</span>)</code></pre></div>
<p>In advance the Cq values were calculated by the following code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the qpcR package to calculate the Cq values by the second derivative</span>
<span class="co"># maximum method.</span>
<span class="kw">library</span>(qpcR)

res_Cq &lt;-<span class="st"> </span><span class="kw">sapply</span>(2L<span class="op">:</span><span class="kw">ncol</span>(data_32HCU), <span class="cf">function</span>(i) {
    <span class="kw"><a href="http://www.rdocumentation.org/packages/qpcR/topics/efficiency">efficiency</a></span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/qpcR/topics/pcrfit">pcrfit</a></span>(data_32HCU, <span class="dt">cyc =</span> <span class="dv">1</span>, <span class="dt">fluo =</span> i, <span class="dt">model =</span> l6))
})

<span class="kw">data.frame</span>(
    <span class="dt">obs =</span> <span class="kw">colnames</span>(data_32HCU)[<span class="op">-</span><span class="dv">1</span>],
           <span class="dt">Cq =</span> <span class="kw">unlist</span>(res_Cq[<span class="st">"cpD2"</span>, ]), <span class="dt">eff =</span> <span class="kw">unlist</span>(res_Cq[<span class="st">"eff"</span>, ])
)

<span class="co">#        Results</span>
<span class="co">#</span>
<span class="co"># obs    Cq      eff</span>
<span class="co"># 1      A1 14.89 1.092963</span>
<span class="co"># 2      B1 15.68 1.110480</span>
<span class="co"># 3      C1 15.63 1.111474</span>
<span class="co"># ...</span>
<span class="co"># 30     F4 15.71 1.109634</span>
<span class="co"># 31     G4 15.70 1.110373</span>
<span class="co"># 32     H4 15.73 1.117827</span></code></pre></div>
<p>Next, the amplification curves (A), the differences between base-line region and plateau region (B), the correlation between the Cq value and amplification efficiency (C) and the clusters based on the Hausdorff distance were taken into account.</p>
<p>Some amplification curves (A) had stronger noise and all curves have a negative non-linear trend and a shift in the ground phase. The comparison of the ground phase and the plateau phase showed a difference between the 32 amplification curves. The observations <code>E1</code>, <code>F1</code> and <code>H1</code> were most close in the ground phase and plateau phase. The comparison of Cq values and amplification efficiency showed that most amplification curves are similar. However, there are also amplification curves that show a greater deviation from the median of all Cq values (C). The cluster analysis confirmed the shape similarity (D).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Use the fda.usc package for functional data analysis</span>
<span class="kw">library</span>(fda.usc)

<span class="co"># To save computing time, the Cq values and amplification efficiencies were </span>
<span class="co"># calculated beforehand and transferred as a hard copy here.</span>

calculated_Cqs &lt;-<span class="st"> </span><span class="kw">c</span>(
    <span class="fl">14.89</span>, <span class="fl">15.68</span>, <span class="fl">15.63</span>, <span class="fl">15.5</span>, <span class="fl">15.54</span>, <span class="fl">15.37</span>, <span class="fl">15.78</span>, <span class="fl">15.24</span>, <span class="fl">15.94</span>,
    <span class="fl">15.88</span>, <span class="fl">15.91</span>, <span class="fl">15.77</span>, <span class="fl">15.78</span>, <span class="fl">15.74</span>, <span class="fl">15.84</span>, <span class="fl">15.78</span>, <span class="fl">15.64</span>, <span class="fl">15.61</span>,
    <span class="fl">15.66</span>, <span class="fl">15.63</span>, <span class="fl">15.77</span>, <span class="fl">15.71</span>, <span class="fl">15.7</span>, <span class="fl">15.79</span>, <span class="fl">15.8</span>, <span class="fl">15.72</span>, <span class="fl">15.7</span>, <span class="fl">15.82</span>,
    <span class="fl">15.62</span>, <span class="fl">15.71</span>, <span class="fl">15.7</span>, <span class="fl">15.73</span>
)

calculated_effs &lt;-<span class="st"> </span><span class="kw">c</span>(
    <span class="fl">1.09296326515231</span>, <span class="fl">1.11047987547324</span>, <span class="fl">1.11147389307153</span>, <span class="fl">1.10308929700635</span>,
    <span class="fl">1.10012176315852</span>, <span class="fl">1.09136717687619</span>, <span class="fl">1.11871308210321</span>, <span class="fl">1.08006168654712</span>,
    <span class="fl">1.09500422011318</span>, <span class="fl">1.1078777171126</span>, <span class="fl">1.11269436700649</span>, <span class="fl">1.10628580163733</span>,
    <span class="fl">1.1082009954558</span>, <span class="fl">1.11069683827291</span>, <span class="fl">1.11074914659374</span>, <span class="fl">1.10722949813473</span>,
    <span class="fl">1.10754282514113</span>, <span class="fl">1.10098387264025</span>, <span class="fl">1.1107026749644</span>, <span class="fl">1.11599641663658</span>,
    <span class="fl">1.11388510347017</span>, <span class="fl">1.11398547396991</span>, <span class="fl">1.09410798249025</span>, <span class="fl">1.12422338092929</span>,
    <span class="fl">1.11977386646464</span>, <span class="fl">1.11212436173214</span>, <span class="fl">1.12145338871426</span>, <span class="fl">1.12180879952503</span>,
    <span class="fl">1.1080276005651</span>, <span class="fl">1.10963449004393</span>, <span class="fl">1.11037302758388</span>, <span class="fl">1.11782689816295</span>
)

<span class="co"># Plot the converted qPCR data</span>
<span class="co"># Create graphic device for the plot(s)</span>

<span class="kw">layout</span>(<span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>), <span class="dv">2</span>, <span class="dv">3</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>))

res_fdata -&gt;.; 

<span class="kw">plot</span>(., <span class="dt">xlab =</span> <span class="st">"Cycles"</span>, <span class="dt">ylab =</span> <span class="st">"RFU"</span>, <span class="dt">main =</span> <span class="st">"HCU32_aggR"</span>, <span class="dt">type =</span> <span class="st">"l"</span>,
         <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> colors)

<span class="kw">legend</span>(<span class="st">"topleft"</span>, <span class="kw">as.character</span>(columnames), <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">col =</span> colors, 
       <span class="dt">bty =</span> <span class="st">"n"</span>, <span class="dt">ncol =</span> <span class="dv">4</span>)
<span class="kw">mtext</span>(<span class="st">"A"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)

<span class="co"># Plot the background and plateau phase.</span>

<span class="kw">boxplot</span>(
    data_32HCU[, <span class="op">-</span><span class="dv">1</span>] <span class="op">-</span><span class="st"> </span><span class="kw">apply</span>(data_32HCU[, <span class="op">-</span><span class="dv">1</span>], <span class="dv">2</span>, min),
        <span class="dt">col =</span> colors, <span class="dt">las =</span> <span class="dv">2</span>, <span class="dt">main =</span> <span class="st">"Signal to noise ratio"</span>,
        <span class="dt">xlab =</span> <span class="st">"Sample"</span>, <span class="dt">ylab =</span> <span class="st">"RFU"</span>
)
<span class="kw">mtext</span>(<span class="st">"B"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)

<span class="co"># Plot the Cqs and the amplification efficiencies.</span>
<span class="co"># Determine the median of the Cq values and label all Cqs, which a less 0.1 Cqs</span>
<span class="co"># of the median or more then 0.1 Cqs of the median Cq.</span>

<span class="kw">plot</span>(
    calculated_Cqs, calculated_effs, <span class="dt">xlab =</span> <span class="st">"Cq (SDM)"</span>,
     <span class="dt">ylab =</span> <span class="st">"eff"</span>, <span class="dt">main =</span> <span class="st">"Cq vs. Amplification Efficiency"</span>,
     <span class="dt">type =</span> <span class="st">"p"</span>, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> colors
)

median_Cq &lt;-<span class="st"> </span><span class="kw">median</span>(calculated_Cqs)
<span class="kw">abline</span>(<span class="dt">v =</span> median_Cq)

<span class="kw">text</span>(median_Cq <span class="op">+</span><span class="st"> </span><span class="fl">0.01</span>, <span class="fl">1.085</span>, <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">tilde</span>(x))))
labeled &lt;-<span class="st"> </span><span class="kw">c</span>(
    <span class="kw">which</span>(calculated_Cqs <span class="op">&lt;</span><span class="st"> </span>median_Cq <span class="op">-</span><span class="st"> </span><span class="fl">0.1</span>),
             <span class="kw">which</span>(calculated_Cqs <span class="op">&gt;</span><span class="st"> </span>median_Cq <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span>)
)

<span class="kw">text</span>(
    calculated_Cqs[labeled], calculated_effs[labeled],
     <span class="kw">as.character</span>(columnames)[labeled]
)
<span class="kw">mtext</span>(<span class="st">"C"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)

<span class="co"># Calculate the Hausdorff distance using the fda.usc package and cluster the</span>
<span class="co"># the distances.</span>

res_fdata_hclust &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/fda.usc/topics/metric.hausdorff">metric.hausdorff</a></span>(res_fdata)
cluster &lt;-<span class="st"> </span><span class="kw">hclust</span>(<span class="kw">as.dist</span>(res_fdata_hclust))

<span class="co"># plot the distances as clustered data and label the leafs with the Cq values</span>
<span class="co"># and colored dots.</span>

<span class="kw">plot</span>(cluster, <span class="dt">main =</span> <span class="st">"Clusters of the amplification</span><span class="ch">\n</span>
<span class="st">curves as calculated by the Hausdorff distance"</span>, <span class="dt">xlab =</span> <span class="st">""</span>, <span class="dt">sub=</span><span class="st">""</span>)
<span class="kw">mtext</span>(<span class="st">"D"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/HCU32-1.png" alt="Clustering and variation analysis of amplification curves. The amplification curves of the 32HCU were processed with the ``qPCR2fdata()`` function and then processed by cluster analysis (Hausdorff distance). A) Amplification curves were plotted from the raw data. B) Overall, signal-to-noise ratios of the amplification curves between all cavities were similar. C) The Cq values and amplification efficiency (eff) were calculated using the ``efficiency(pcrfit())`` [\texttt{qpcR}] function. The median Cq is shown as a vertical line. Cqs greater or less than 0,1 of Cq $  ilde{x}$ are marked with observation labels. D) The cluster analysis showed no specific pattern with respect to the amplification curve signals. It appears that the observations D1, E1, F1, F3, G3 and H1 differ most from the other amplification curves." width="1056"><p class="caption">
Clustering and variation analysis of amplification curves. The amplification curves of the 32HCU were processed with the <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code> function and then processed by cluster analysis (Hausdorff distance). A) Amplification curves were plotted from the raw data. B) Overall, signal-to-noise ratios of the amplification curves between all cavities were similar. C) The Cq values and amplification efficiency (eff) were calculated using the <code><a href="http://www.rdocumentation.org/packages/qpcR/topics/efficiency">efficiency(pcrfit())</a></code> [] function. The median Cq is shown as a vertical line. Cqs greater or less than 0,1 of Cq $ ilde{x}$ are marked with observation labels. D) The cluster analysis showed no specific pattern with respect to the amplification curve signals. It appears that the observations D1, E1, F1, F3, G3 and H1 differ most from the other amplification curves.
</p>
</div>
<p>The analysis gives an overview of the variation of the amplification curve data.</p>

</div>
</div>
<div id="amplification-curve-analysis-functions-of-the-package" class="section level3">
<h3 class="hasAnchor">
<a href="#amplification-curve-analysis-functions-of-the-package" class="anchor"></a>Amplification Curve Analysis Functions of the  package </h3>
<p>On the basis of this observation, <strong>concepts for predictors</strong> (<em>features</em>) were developed and implemented in algorithms to describe amplification curves. The function described following are aimed for experimental studies. It is important to note that the concepts for the predictors proposed herein emerged by a <em>critical reasoning</em> process and <em>domain knowledge</em> of the  package creator. The aim of the package is to propose a set of predictors, functions and data for an independent research.</p>
<div id="pcrfit_single-and-encu--functions-to-calculate-predictors-from-an-amplification-curve" class="section level4">
<h4 class="hasAnchor">
<a href="#pcrfit_single-and-encu--functions-to-calculate-predictors-from-an-amplification-curve" class="anchor"></a><code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> and <code><a href="../reference/encu.html">encu()</a></code>- Functions to Calculate Predictors from an Amplification Curve </h4>
<p>The following sections give a concise description of the algorithms used to calculate predictor vectors by the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function . Based on considerations and experience the algorithms of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function are restricted to ROIs () to calculate specific predictors.</p>
<p>The <code><a href="../reference/encu.html">encu()</a></code> function is a wrapper for the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function. <code><a href="../reference/encu.html">encu()</a></code> can be used to process large records of amplification curve data arranged in columns. The progress of processing is displayed in the form of a progress bar and the estimated run-time. Additionally, the <code><a href="../reference/encu.html">encu()</a></code> allows to specify which monitoring chemistry (e. g., DNA binding dye, sequence specific probes) and which thermo-cycler was used. <span class="citation">Jan M. Ruijter et al. (2014)</span> have shown that the monitoring chemistry and the type of input DNA (single stranded, double stranded) are important when analysing qPCR data, because they have an influence on the shape of the amplification curve. For simplicity, the documentation will describe the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> only.</p>
<p>The underlying hypotheses and concepts of the predictors are formulated and supported by <em>exemplary applications</em>. Different representative data sets were used to support a concept or predictors. For example, the <code>RAS002</code> data set represents a typical qPCR. This means that the positive amplification curves start with a flat plateau phase and then transition into the sigmoid shape with a plateau. The negative amplification curves display no significant peculiarities. For both positive and negative amplification curves there is a shift from the origin. The <code>htPCR</code> data set serves as a problem example in several places, since it contains many observations (amplification curves from high-throughput experiments). In addition, the amplification curves have a high diversity of curve shapes that cannot be uniquely and reproducibly classified even by experienced users. Other data sets are used in the documentation, but these are not discussed in detail.</p>
<p>To underscore the usability of the algorithms and their predictors, 3302 observations (471 negative amplification curves, 2831 positive amplification curves) from the <code>batsch1</code>, <code>boggy</code>, <code>C126EG595</code>, <code>competimer</code>, <code>dil4reps94</code>, <code>guescini1</code>, <code>karlen1</code>, <code>lievens1</code>, <code>reps384</code>, <code>rutledge</code>, <code>testdat</code>, <code>vermeulen1</code>, <code>VIMCFX96_60</code>, <code>stepone_std</code>, <code>RAS002</code>, <code>RAS003</code>, <code>HCU32_aggR</code> and <code>lc96_bACTXY</code> were analyzed with the <code><a href="../reference/encu.html">encu()</a></code> function and the results (predictors) were combined in the file <strong><code>data_sample.rda</code></strong>. Users of this function should independently verify and validate the results of the methods for their applications.</p>
<p>A new data set called <code>data_sample_subset_balanced</code> has been compiled from the <code>data_sample</code> data set for some of the applications. Selection criteria included:</p>
<ul>
<li>both positive and negative amplification curves had to be included in a similar ratio,</li>
<li>there should not be a thermal cycler platform dominant,</li>
<li>the amplification curves should represent typical amplification curves (subjective criterion). The compilation of the data sets <code>batsch1</code>, <code>HCU32_aggR</code>, <code>lc96_bACTXY</code>, <code>RAS002</code>, <code>RAS003</code> and <code>stepone_std</code> met this requirement satisfactorily.</li>
</ul>
<p>, <code>rutledge</code>, <code>testdat</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_sample_subset_balanced &lt;-<span class="st"> </span>data_sample[data_sample<span class="op">$</span>dataset <span class="op">%in%</span><span class="st"> </span>
<span class="kw">c</span>(<span class="st">"batsch1"</span>, <span class="st">"boggy"</span>, <span class="st">"C126EG595"</span>, <span class="st">"HCU32_aggR"</span>, <span class="st">"lc96_bACTXY"</span>,
  <span class="st">"RAS002"</span>, <span class="st">"RAS003"</span>, <span class="st">"stepone_std"</span>, <span class="st">"testdat"</span>), ]
  
<span class="co"># Dimension of data_sample_subset_balanced</span>
<span class="kw">dim</span>(data_sample_subset_balanced) ## Observations predictors</code></pre></div>
<pre><code>## [1] 651  54</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Show the counts of negative and positive amplification </span>
<span class="co"># curves in a bar plot</span>
<span class="co"># Build a contingency table of the counts at each</span>
<span class="co"># combination of factor levels.</span>

dec_table&lt;-<span class="st"> </span><span class="kw">table</span>(data_sample_subset_balanced[[<span class="st">"decision"</span>]])
<span class="kw">barplot</span>(dec_table, <span class="dt">ylab =</span> <span class="st">"Number of Observations"</span>, <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">"green"</span>, <span class="st">"black"</span>), 
        <span class="dt">border =</span> <span class="st">"white"</span>)
<span class="kw">text</span>(<span class="kw">c</span>(<span class="fl">0.7</span>, <span class="fl">1.9</span>), <span class="kw">rep</span>(<span class="kw">min</span>(dec_table) <span class="op">*</span><span class="fl">0.9</span>, <span class="kw">length</span>(dec_table)), 
     <span class="kw">c</span>(<span class="kw">paste</span>(<span class="st">"y = "</span>, dec_table[<span class="dv">1</span>]), <span class="kw">paste</span>(<span class="st">"n = "</span>, dec_table[<span class="dv">2</span>])),
     <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">"black"</span>, <span class="st">"white"</span>))
<span class="kw">mtext</span>(<span class="st">"data_sample_subset_balanced"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, 
      <span class="dt">las =</span> <span class="dv">0</span>)</code></pre></div>
<p><img src="PCRedux_files/figure-html/unnamed-chunk-17-1.png" width="364.8"></p>
<p>For the comparison of predictors the data set was enlarged. Selection criteria for the data sets were comparatively less stringent.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_sample_subset &lt;-<span class="st"> </span>data_sample[data_sample<span class="op">$</span>dataset <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">"stepone_std"</span>, 
                                                             <span class="st">"RAS002"</span>, <span class="st">"RAS003"</span>, 
                                                             <span class="st">"lc96_bACTXY"</span>, 
                                                             <span class="st">"C126EG595"</span>, 
                                                             <span class="st">"dil4reps94"</span>,
                                                             <span class="st">"testdat"</span>, 
                                                             <span class="st">"boggy"</span>), ]

<span class="co"># Dimension of data_sample_subset</span>
<span class="kw">dim</span>(data_sample_subset) ## Observations predictors</code></pre></div>
<pre><code>## [1] 979  54</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Show the counts of negative and positive amplification </span>
<span class="co"># curves in a bar plot</span>
<span class="co"># Build a contingency table of the counts at each</span>
<span class="co"># combination of factor levels.</span>

dec_table&lt;-<span class="st"> </span><span class="kw">table</span>(data_sample_subset[[<span class="st">"decision"</span>]])
<span class="kw">barplot</span>(dec_table, <span class="dt">ylab =</span> <span class="st">"Number of Observations"</span>, <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">"green"</span>, <span class="st">"black"</span>), 
        <span class="dt">border =</span> <span class="st">"white"</span>)
<span class="kw">text</span>(<span class="kw">c</span>(<span class="fl">0.7</span>, <span class="fl">1.9</span>), <span class="kw">rep</span>(<span class="kw">min</span>(dec_table) <span class="op">*</span><span class="fl">0.9</span>, <span class="kw">length</span>(dec_table)), 
     <span class="kw">c</span>(<span class="kw">paste</span>(<span class="st">"y = "</span>, dec_table[<span class="dv">1</span>]), <span class="kw">paste</span>(<span class="st">"n = "</span>, dec_table[<span class="dv">2</span>])),
     <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">"black"</span>, <span class="st">"white"</span>))
<span class="kw">mtext</span>(<span class="st">"data_sample_subset"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, 
      <span class="dt">las =</span> <span class="dv">0</span>)</code></pre></div>
<p><img src="PCRedux_files/figure-html/unnamed-chunk-19-1.png" width="364.8"></p>
<p>The goal is to demonstrate the basic functionality of the algorithms for the predictor calculation. Similar concepts are presented in groups. The algorithms are divided into the following broad categories:</p>
<ul>
<li>algorithms that determine slopes, signal levels,</li>
<li>algorithms that determine turning points and</li>
<li>algorithms that determine areas.</li>
</ul>
<p>The algorithms in</p>
<ul>
<li>
<code><a href="../reference/earlyreg.html">earlyreg()</a></code> (),</li>
<li>
<code><a href="../reference/head2tailratio.html">head2tailratio()</a></code> (),</li>
<li>
<code><a href="../reference/hookreg.html">hookreg()</a></code>&amp; <code><a href="../reference/hookregNL.html">hookregNL()</a></code> () and</li>
<li>
<code><a href="../reference/mblrr.html">mblrr()</a></code> (),</li>
<li>
<code><a href="../reference/autocorrelation_test.html">autocorrelation_test()</a></code> ()</li>
</ul>
<p>were implemented as standalone functions to make them available for other applications.</p>
<p>The output below shows the predictors and their data type (<code>num</code>, numeric; <code>int</code>, integer; <code>Factor</code>, factor; <code>logi</code>, boolean) that were determined with the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PCRedux)
<span class="co"># Calculate predictor vector of column two from the RAS002 data set.</span>
<span class="kw">str</span>(<span class="kw"><a href="../reference/pcrfit_single.html">pcrfit_single</a></span>(RAS002[, <span class="dv">2</span>]))</code></pre></div>
<pre><code>## 'data.frame':    1 obs. of  49 variables:
##  $ cpD1                 : num 28.1
##  $ cpD2                 : num 25.9
##  $ eff                  : num 1.02
##  $ sliwin               : num 1.04
##  $ cpDdiff              : num 2.19
##  $ loglin_slope         : num 0.0343
##  $ cpD2_range           : num 4.48
##  $ top                  : num 25
##  $ f.top                : num 0.748
##  $ tdp                  : num 35
##  $ f.tdp                : num 1.65
##  $ bg.stop              : num 15
##  $ amp.stop             : num 40
##  $ b_slope              : num -13.6
##  $ f_intercept          : num 3.17
##  $ convInfo_iteratons   : int 14
##  $ qPCRmodel            : Factor w/ 1 level "l7": 1
##  $ qPCRmodelRF          : Factor w/ 1 level "l7": 1
##  $ minRFU               : num 0.682
##  $ maxRFU               : num 1
##  $ init2                : num 0.419
##  $ fluo                 : num 0.765
##  $ slope_bg             : num 0.00658
##  $ intercept_bg         : num 0.675
##  $ sigma_bg             : num 0.00455
##  $ sd_bg                : num 0.0939
##  $ head2tail_ratio      : num 0.704
##  $ mblrr_slope_pt       : num 0.00586
##  $ mblrr_intercept_bg   : num 0.693
##  $ mblrr_slope_bg       : num 0.00202
##  $ mblrr_cor_bg         : num 0.91
##  $ mblrr_intercept_pt   : num 0.774
##  $ mblrr_cor_pt         : num 0.942
##  $ polyarea             : num 0.0409
##  $ peaks_ratio          : num 0.0117
##  $ autocorellation      : num 0.741
##  $ cp_e.agglo           : int 2
##  $ cp_bcp               : int 0
##  $ amptester_shapiro    : logi FALSE
##  $ amptester_lrt        : logi TRUE
##  $ amptester_rgt        : logi TRUE
##  $ amptester_tht        : logi TRUE
##  $ amptester_slt        : logi TRUE
##  $ amptester_polygon    : num 4.5
##  $ amptester_slope.ratio: num 0.0384
##  $ hookreg_hook         : num 0
##  $ hookreg_hook_slope   : num 0
##  $ hookreg_hook_delta   : num 0
##  $ number_of_cycles     : int 40</code></pre>
<div id="amplification-curve-pre-processing" class="section level5">
<h5 class="hasAnchor">
<a href="#amplification-curve-pre-processing" class="anchor"></a>Amplification Curve Pre-Processing</h5>
<p>The <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function performs pre-processing steps before each calculation. That includes checking whether an amplification curve contains missing values. Missing values (NA) are measuring points in a data set where no measured values are available or if they have been removed arbitrarily. NAs may occur if no measurement has been carried out (e. g., defective detector) or lengths of the vectors differ (number of cyles) between the observation. Such missing values are automatically imputed by spline interpolation as described in <span class="citation">Rödiger, Burdukiewicz, and Schierack (2015)</span>.</p>
<p>All values of an amplification curve are normalized to their 99% quantile. The normalization is used to equalize the amplitudes differences of amplification curves from thermo-cyclers (sensor technology, software processing) and detection chemistries. To compare amplification curves from different thermo-cyclers, the values should always be scaled systematically using the same method. Although there are other normalization methods (e. g., minimum-maximum normalization, see [<span class="citation">Rödiger, Burdukiewicz, and Schierack (2015)</span>, the normalization by the 99% quantile preserves the information about the level of the background phase. A normalization to the maximum is not used to avoid strong extenuation by outliers. The data in D show that the <code>maxRFU</code> values after normalization are approximately 1. There is no statistical significant difference between <code>maxRFU</code> values of positive and negative amplification curves.</p>
<p>Selected algorithms of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function use the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/CPP">CPP()</a></code> [] function to pre-process (e. g., base-lining, smoothing, imputation of missing values) the amplification curves. Further details are given in <span class="citation">Rödiger, Burdukiewicz, and Schierack (2015)</span>.</p>
<p>During the analysis several values are determined to describe the amplitude of an amplification curve. The resulting potential predictors are <code>minRFU</code> (minimum of the amplification curve, which is determined at the 1% quantile to minimize the influence of outliers), <code>init2</code> (the initial template fluorescence from an exponential model) and <code>fluo</code> (raw fluorescence value at the second derivative maximum). The <code>minRFU</code>, <code>init2</code> and <code>fluo</code> values differ significantly between negative and positive amplification curves (C, E &amp; F).</p>
</div>
<div id="handling-of-missing-predictors" class="section level5">
<h5 class="hasAnchor">
<a href="#handling-of-missing-predictors" class="anchor"></a>Handling of Missing Predictors</h5>
<p>Missing values (NA) can occur if a calculation of a predictor is impossible (e.g., if a logistic function cannot be adapted to noisy raw data). The lack of a predictor is nevertheless a useful information (no predictor calculate <span class="math inline">\(\mapsto\)</span> amplification curves deviate from sigmoid shape). The NAs were left unchanged in the  package up to version 0.2.5-1. Since version 0.2.6 the NAs are replaced by numerical values (e. g., total number of cycles) or factors (e. g., <em>lNA</em> for non-fitted model). Under the term “imputation” there are a number of procedures based on statistical methods (e. g., neighboring median, spline interpolation) or on user-defined rules <span class="citation">(Williams 2009, <span class="citation">Cook and Swayne (2007)</span>, <span class="citation">Hothorn and Everitt (2014)</span>)</span>. Rules are mainly used in function of  to relieve the user from the decision as to how to deal with missing values. For example, slope parameters of a model are to zero when it cannot be determined. The disadvantage is that rules do not necessarily concur to real world values.</p>
</div>
</div>
<div id="multi-parametric-models-for-amplification-curve-fitting" class="section level4">
<h4 class="hasAnchor">
<a href="#multi-parametric-models-for-amplification-curve-fitting" class="anchor"></a>Multi-parametric Models for Amplification Curve Fitting</h4>
<p>Both the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function and the <code><a href="../reference/encu.html">encu()</a></code> function use four multi-parametric models based on the findings by <span class="citation">Spiess, Feig, and Ritz (2008)</span> and <span class="citation">Ritz and Spiess (2008)</span>. The <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function starts by adjusting a seven-parameter model since this adapts <em>easier</em> and more frequent to a data set ().</p>
<ul>
<li>
<strong>l7</strong>:</li>
</ul>
<span class="math display">\[\begin{equation}\label{l7}
f(x) = c + k1 \cdot x + k2 \cdot x^2 + \frac{d - c}{(1 + exp(b(log(x) - log(e))))^f}
\end{equation}\]</span>
<p>From that model, the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function outputs the variables <code>b_slope</code> and <code>f_intercept</code>, which describe the slope and the intercept. The number of iterations required to adapt the model is also stored. That value is returned by the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function as <code>convInfo_iteratons</code>. The higher the <code>convInfo_iteratons</code> value, the more iterations were necessary to converge from the start parameters (L). A low <code>convInfo_iteratons</code> value is an indicator for a sigmoid curve shape. High iterations numbers imply noisy or non-sigmoid amplification curves.</p>
<p>The amplification curve fitting process continues with four-parameter model (<em>l4</em>, ). This is followed by a model with five parameters (<em>l5</em>, ) and six parameters (<em>l6</em>, ).</p>
<ul>
<li>
<strong>l4</strong>:</li>
</ul>
<span class="math display">\[\begin{equation}\label{l4}
    f(x) = c + \frac{d - c}{1 + exp(b(log(x) - log(e)))}
\end{equation}\]</span>
<ul>
<li>
<strong>l5</strong>:</li>
</ul>
<span class="math display">\[\begin{equation}\label{l5}
    f(x) = c + \frac{d - c}{(1 + exp(b(log(x) - log(e))))^f}
\end{equation}\]</span>
<ul>
<li>
<strong>l6</strong>:</li>
</ul>
<span class="math display">\[\begin{equation}\label{l6}
    f(x) = c + k \cdot x + \frac{d - c}{(1 + exp(b(log(x) - log(e))))^f}
\end{equation}\]</span>
<p>The optimal model is selected on the basis of the Akaike information criterion and used for all further calculations. The <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function returns <code>qPCRmodel</code> as a factor (<em>l4</em>, <em>l5</em>, <em>l6</em>, <em>l7</em>). In case no model could be fitted, an <em>lNA</em> is returned.</p>
<p>The model is an indicator of the amplification curve shape. Model with many parameters deviate more from an ideal sigmoid model. For instance, a four-parameter model, unlike the six-parameter model, does not have a linear component. A negative linear slope in the plateau phase is an indicator of a <em>hook effect</em> [CITATION BDQ].</p>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_models-1.png" alt="Frequencies of the fitted multiparametric models and Cq values. The amplification curves (n = 3302) of the `data\_sample` data set were analyzed with the ``encu()`` function. The amplification curves have been broken down according to their classes (negative: grey, positive: green). A) The optimal multiparametric model was selected for each amplification curve based on the Akaike information criterion. lNA stands for `no model` and l4 \ldots l7 for a model with four to seven parameters. B) All Cq values were calculated from optimal multiparametric models. Cqs of positive amplification curves accumulate in the range between 15 and 30 PCR cycles (50\%). For the negative amplification curves, the Cqs are distributed over the entire span of the cycles. Note: The Cqs of the negative amplification curves are false-positive!" width="700"><p class="caption">
Frequencies of the fitted multiparametric models and Cq values. The amplification curves (n = 3302) of the <code>data\_sample</code> data set were analyzed with the <code><a href="../reference/encu.html">encu()</a></code> function. The amplification curves have been broken down according to their classes (negative: grey, positive: green). A) The optimal multiparametric model was selected for each amplification curve based on the Akaike information criterion. lNA stands for <code>no model</code> and l4 l7 for a model with four to seven parameters. B) All Cq values were calculated from optimal multiparametric models. Cqs of positive amplification curves accumulate in the range between 15 and 30 PCR cycles (50%). For the negative amplification curves, the Cqs are distributed over the entire span of the cycles. Note: The Cqs of the negative amplification curves are false-positive!
</p>
</div>
</div>
<div id="quantification-points-ratios-and-slopes" class="section level4">
<h4 class="hasAnchor">
<a href="#quantification-points-ratios-and-slopes" class="anchor"></a>Quantification Points, Ratios and Slopes</h4>
<p>The <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function calculates the <code>cpD1</code> and <code>cpD2</code> and uses them for further analysis. Both the <code>cpD1</code> value and the <code>cpD2</code> value are used to describe the amplification reaction quantitatively. For example, low <code>cpD1</code> and <code>cpD2</code> values (&lt; 5 cycles) indicate that the PCR reaction was negative or that the amount of input DNA was to high. B</p>
<p>Further predictors from the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function are:</p>
<ul>
<li>
<code>eff</code> is the optimized PCR efficiency found within a sliding window (C). A linear model of cycles versus log(Fluorescence) is fit within a sliding window (for details see <code><a href="http://www.rdocumentation.org/packages/qpcR/topics/sliwin">sliwin()</a></code> [] function). The comparison of positive and negative amplification curves in A demonstrates that the classes are significantly different from each other. The <code>eff</code> values differ significantly between negative and positive amplification curves (A).</li>
<li>
<code>sliwin</code> is the PCR efficiency by the ‘window-of-linearity’ method <span class="citation">(Spiess, Feig, and Ritz 2008)</span> (B). The <code>sliwin</code> values differ significantly between negative and positive amplification curves (B).</li>
<li>
<code>cpDdiff</code> is the difference between the first (<code>cpD1</code>) and the second derivative maximum <code>cpD2</code> (<span class="math inline">\(cpDdiff = cpD1 - cpD2\)</span>) <strong>from the fitted model</strong> (C). Provided that a model can be exactly fitted, the estimates of the difference are reliable. Higher <code>cpDdiff</code> values indicate a negative amplification reaction or a very low amplification efficiency. The comparison of positive and negative amplification curves in C demonstrates that the classes are significantly different from each other. In the event that the <code>cpDdiff</code> value cannot be determined (NA), it is replaced by zero. The <code>cpDdiff</code> values differ significantly between negative and positive amplification curves (C).</li>
<li>
<code>cpD2_range</code> is the absolute value of the difference between the minimum and the maximum of the second derivative maximum (<span class="math inline">\(cpD2\_range = |cpD2m - cpD2|\)</span>) from the <code>diffQ2()</code> function (<strong>no model fitted</strong>) (E). The <code>cpD2_range</code> value does not require an adjustment of a multiparametric model. The approximate first and second derivatives are determined using a five-point stencil <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015)</span>. The comparison of positive and negative amplification curves in E shows that the classes differ significantly from each other. In the event that the <code>cpD2_range</code> value cannot be determined (NA), it is replaced by zero. The <code>cpD2_range</code> values differ significantly between negative and positive amplification curves (E).</li>
</ul>
<div class="figure">
<img src="PCRedux_files/figure-html/figure_cpD2_range-1.png" alt="Location of the of the predictors `cpD2\_range`, `bg.start`, `bg.stop` within an amplification curve. The minimum (cpD2m) and maximum (cpD2) of the second derivative were calculated numerically using the ``diffQ2()`` function. This function also returns the maximum of the first derivative (cpD1). The `cpD2\_range` is defined as $cpD2\_range = |cpD2 - cpD2m|$. Large `cpD2\_range` values indicate a low amplification efficiency or a negative amplification reaction. The predictor `bg.start` is an estimate for the end of the ground phase. `bg.start` is an approximation for the onset of the plateau phase." width="700"><p class="caption">
Location of the of the predictors <code>cpD2\_range</code>, <code>bg.start</code>, <code>bg.stop</code> within an amplification curve. The minimum (cpD2m) and maximum (cpD2) of the second derivative were calculated numerically using the <code>diffQ2()</code> function. This function also returns the maximum of the first derivative (cpD1). The <code>cpD2\_range</code> is defined as <span class="math inline">\(cpD2\_range = |cpD2 - cpD2m|\)</span>. Large <code>cpD2\_range</code> values indicate a low amplification efficiency or a negative amplification reaction. The predictor <code>bg.start</code> is an estimate for the end of the ground phase. <code>bg.start</code> is an approximation for the onset of the plateau phase.
</p>
</div>
<ul>
<li><p><code>bg.stop</code> is the end of the ground phase and <code>amp.stop</code> is the end of the exponential phase estimated by the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/bg.max">bg.max()</a></code> [] function <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015)</span>. A graphical presentation of the locations in the amplification curve are shown in . The <code>bg.stop</code> and <code>bg.stop</code> values differ significantly between negative and positive amplification curves (J &amp; K).</p></li>
<li><p><code>top</code> is the <em>takeoff point</em> as proposed by <span class="citation">Tichopad et al. (2003)</span>. The <code>top</code> is calculated using externally studentized residuals, which tested to be an outlier in terms of the t-distribution. The <code>top</code> signifies to first PCR cycle entering the exponential phase. <code>tdp</code> is the <em>takedown point</em>. This is an implementation in the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function, which uses the rotated <span class="math inline">\(f(x) \mapsto f_{1}(f(x))\)</span> and flipped <span class="math inline">\(g(x) = -(x)\)</span> amplification curve for calculation. A describes the location of <code>top</code> and <code>tdp</code>. The position (<code>f.top</code>, <code>f.tdp</code>) on the ordinate is also determined from these points. If an amplification curve is negative or neither <code>top</code> nor <code>tdp</code> can be calculated, then <code>top</code> &amp; <code>tdp</code> will be assigned the number of cycles and <code>f.top</code> &amp; <code>f.tdp</code> the value 1. The distribution of <code>top</code>, <code>tdp</code>, <code>f.top</code> and <code>f.tdp</code> is shown in F-I. The <code>top</code>, <code>tdp</code>, <code>f.top</code> and <code>f.tdp</code> values differ significantly between negative and positive amplification curves. Potentially they enable a qualitative classification of the amplification reaction. An interesting aspect is that the positive <code>f.top</code> values are markedly lower than the negative <code>f.top</code> values The same applies inversely to the <code>tdp</code> values. In this way, amplification curves can be classified according to these values.</p></li>
<li><p><code>peaks_ratio</code> is based on a sequential chaining of functions. The <code>diffQ()</code> [] function determines numerically the first derivative of an amplification curve. This derivative is passed to the <code>mcaPeaks()</code> [] function. In the output all minima and all maxima are contained. The ranges are calculated from the minima and maxima. The Lagged Difference is determined from the ranges of the minima and maxima. Finally, the ratio of the differences (maximum/minimum) is calculated. The <code>peaks_ratio</code> values differ significantly between negative and positive amplification curves (B).</p></li>
</ul>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_dat_EffTop-1.png" alt="Values of predictors calculated from negative and positive amplification curves. Amplification curves predictors from the `data\_sample\_subset` data set were used since they contain positive and negative amplification curves and amplification curves that exhibit a hook effect or non-sigmoid shapes, for instance. A) `eff`, optimized PCR efficiency found within a sliding window. B) `sliwin`, PCR efficiency by the ‘window-of-linearity’ method. C) `cpDdiff`, difference between the Cq values calculated from the first and the second derivative maximum. D) `loglin\_slope`, slope from the cycle at the second derivative maximum to the second derivative minimum. E) `cpD2\_range`, absolute value of the difference between the minimum and the maximum of the second derivative maximum. F) `top`, takeoff point. G) `f.top`, fluorescence intensity at takeoff point. H) `tdp`,  takedown point. I) `f.tdp`, fluorescence intensity at takedown point. J) `bg.stop`, estimated end of the ground phase. K) `amp.stop`, estimated end of the exponential phase. L) `convInfo\_iteratons`, number of iterations until convergence." width="1056"><p class="caption">
Values of predictors calculated from negative and positive amplification curves. Amplification curves predictors from the <code>data\_sample\_subset</code> data set were used since they contain positive and negative amplification curves and amplification curves that exhibit a hook effect or non-sigmoid shapes, for instance. A) <code>eff</code>, optimized PCR efficiency found within a sliding window. B) <code>sliwin</code>, PCR efficiency by the ‘window-of-linearity’ method. C) <code>cpDdiff</code>, difference between the Cq values calculated from the first and the second derivative maximum. D) <code>loglin\_slope</code>, slope from the cycle at the second derivative maximum to the second derivative minimum. E) <code>cpD2\_range</code>, absolute value of the difference between the minimum and the maximum of the second derivative maximum. F) <code>top</code>, takeoff point. G) <code>f.top</code>, fluorescence intensity at takeoff point. H) <code>tdp</code>, takedown point. I) <code>f.tdp</code>, fluorescence intensity at takedown point. J) <code>bg.stop</code>, estimated end of the ground phase. K) <code>amp.stop</code>, estimated end of the exponential phase. L) <code>convInfo\_iteratons</code>, number of iterations until convergence.
</p>
</div>
<ul>
<li>
<code>loglin_slope</code> is calculated from the slope determined by a linear model of the data points from the cycle dependent fluorescence at the minimum of the second derivative and maximum of the second derivative (). Provided that the locations of the minimum of the second derivative and the maximum of the second derivative yield a <em>suitable</em> interval. As a precaution, the algorithm checks, for example, whether the distance between the minimum of the second derivative and the maximum of the second derivative is not more than nine PCR cycles. Failing this, the <code>loglin_slope</code> value is set to zero (no slope). In the following example, the data . The <code>loglin_slope</code> values differ significantly between negative and positive amplification curves (D).</li>
</ul>
<div class="figure">
<img src="PCRedux_files/figure-html/loglin_slope-1.png" alt="Concept of the `loglin\_slope` predictor. The algorithm determines the fluorescence values of the raw data at the approximate positions of the maximum of the first derivative, the minimum of the second derivative and the maximum of the second derivative, which are in the exponential phase of the amplification curve. A linear model is created from these parameter sets and the slope is determined. A) Positive amplification curves have a clearly positive slope. B) Negative amplification curves usually have a low, sometimes negative slope. The data were taken from the `RAS002` data set." width="700"><p class="caption">
Concept of the <code>loglin\_slope</code> predictor. The algorithm determines the fluorescence values of the raw data at the approximate positions of the maximum of the first derivative, the minimum of the second derivative and the maximum of the second derivative, which are in the exponential phase of the amplification curve. A linear model is created from these parameter sets and the slope is determined. A) Positive amplification curves have a clearly positive slope. B) Negative amplification curves usually have a low, sometimes negative slope. The data were taken from the <code>RAS002</code> data set.
</p>
</div>
<p>The predictor <code>loglin_slope</code> is used in the following to show that the slope between the slope within this ROI can be used to distinguish positive and negative amplification curves. The hypothesis is that positive amplification curves have a higher <code>loglin_slope</code> than negative amplification curves. As shown in D, there is a statistically significant difference between positive and negative amplification curves.</p>
<p>The <code>loglin_slope</code> values from the <code>data_sample_subset_balanced</code> data set () were used to save computing time. A binomial logistic regression (see )) was used to analyze the relationship between the <code>loglin_slope</code> value and the class (negative, positive). The data set was split into two chunks. This is an important step during such applications. One chunk is for adapting, i. e. training, the model and the other chunk for testing the model. By convention, 70% to 80% of the data is used for training <span class="citation">(Walsh, Pollastri, and Tosatto 2015, <span class="citation">Kuhn (2008)</span>)</span>. The binomial logistic regression model was adapted using the <code>glm()</code> [] function by using the parameter <code>family = binomial(link = 'logit')</code>. To objectify the splitting, the <code>sample()</code> [] function was used.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PCRedux)

data &lt;-<span class="st"> </span>data_sample_subset_balanced

n_positive &lt;-<span class="st"> </span><span class="kw">sum</span>(data[[<span class="st">"decision"</span>]] <span class="op">==</span><span class="st"> "y"</span>)
n_negative &lt;-<span class="st"> </span><span class="kw">sum</span>(data[[<span class="st">"decision"</span>]] <span class="op">==</span><span class="st"> "n"</span>)

dat &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">loglin_slope =</span> data[, <span class="st">"loglin_slope"</span>], 
                  <span class="dt">decision =</span> <span class="kw">as.numeric</span>(<span class="kw">factor</span>(data<span class="op">$</span>decision, 
                                               <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">"n"</span>, <span class="st">"y"</span>), 
                                               <span class="dt">label =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)

<span class="co"># Select randomly observations from 70% of the data for training.</span>
<span class="co"># n_train is the number of observations used for training.</span>

n_train &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">nrow</span>(data) <span class="op">*</span><span class="st"> </span><span class="fl">0.7</span>)

<span class="kw">paste0</span>(<span class="st">"Percentage of observations ("</span>, n_train, <span class="st">") = "</span>, 
       <span class="kw">signif</span>((n_train<span class="op">/</span><span class="kw">nrow</span>(data)<span class="op">*</span><span class="dv">100</span>),<span class="dv">3</span>), <span class="st">"%"</span>)</code></pre></div>
<pre><code>## [1] "Percentage of observations (456) = 70%"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># index_test is the index of observations to be selected for the training</span>
index_test &lt;-<span class="st"> </span><span class="kw">sample</span>(1L<span class="op">:</span><span class="kw">nrow</span>(dat), <span class="dt">size =</span> n_train)

<span class="co"># index_test is the index of observations to be selected for the testing</span>
index_training &lt;-<span class="st"> </span><span class="kw">which</span>(<span class="op">!</span>(1L<span class="op">:</span><span class="kw">nrow</span>(dat) <span class="op">%in%</span><span class="st"> </span>index_test))

<span class="co"># train_data contains the data used for training</span>

train_data &lt;-<span class="st"> </span>dat[index_test, ]

<span class="co"># test_data contains the data used for training</span>

test_data &lt;-<span class="st"> </span>dat[index_training, ]

<span class="co"># Fit the binomial logistic regression model</span>

model_glm &lt;-<span class="st"> </span><span class="kw">glm</span>(decision <span class="op">~</span><span class="st"> </span>loglin_slope, <span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">'logit'</span>), 
                 <span class="dt">data =</span> train_data)

predictions &lt;-<span class="st"> </span><span class="kw">ifelse</span>(<span class="kw">predict</span>(model_glm, 
                              <span class="dt">newdata =</span> test_data, <span class="dt">type =</span> <span class="st">'response'</span>) <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>,
                      <span class="dv">1</span>, <span class="dv">0</span>)

res_performeR &lt;-<span class="st"> </span><span class="kw"><a href="../reference/performeR.html">performeR</a></span>(predictions, test_data[[<span class="st">"decision"</span>]])[, <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dv">12</span>)]</code></pre></div>
<p>The <code>summary()</code> function returns the results of the model fitting. This can be analysed and interpreted.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(model_glm)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = decision ~ loglin_slope, family = binomial(link = "logit"), 
##     data = train_data)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.2643  -0.1835  -0.1835   0.0058   2.8608  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   -4.0754     0.4759  -8.564   &lt;2e-16 ***
## loglin_slope 207.8395    24.3486   8.536   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 631.931  on 455  degrees of freedom
## Residual deviance:  68.728  on 454  degrees of freedom
## AIC: 72.728
## 
## Number of Fisher Scoring iterations: 8</code></pre>
<p>Based on the results it can be concluded that the parameters <code>(Intercept)</code> and <code>loglin_slope</code> are statistically significant (<em>P</em> &lt; 2e-16). This indicates a strong association between <code>loglin_slope</code> and the probability that an amplification curve is positive.</p>
<p>In order to apply the model to a new data set, further steps are necessary. <code>predict()</code> [] is a generic function for prediction from the results of a model fitting function. All previously split test data is passed to the function argument <code>newdata</code>. By setting the <code>type = 'response'</code> parameter, the <code>predict()</code> function returns probabilities in the form of <span class="math inline">\(P(y=1|X)\)</span>. In the case in hand, it was decided that a decision limit of 0.5 is to be applied. If <span class="math inline">\(P(y=1|X) &lt; 0.5\)</span> then <span class="math inline">\(y = 0\)</span> (amplification curve negative), otherwise <span class="math inline">\(y = 1\)</span> (amplification curves positive).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PCRedux)

<span class="co"># Create graphic device for the plot(s)</span>
<span class="co"># Plot train_data (grey points) and the predicted model (blue)</span>
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))


<span class="kw">plot</span>(train_data<span class="op">$</span>loglin_slope, train_data<span class="op">$</span>decision, <span class="dt">pch =</span> <span class="dv">19</span>, 
     <span class="dt">xlab =</span> <span class="st">"loglin_slope"</span>, <span class="dt">ylab =</span> <span class="st">"Probability"</span>, 
     <span class="dt">col =</span> <span class="kw">adjustcolor</span>(<span class="st">"grey"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.9</span>), <span class="dt">cex =</span> <span class="fl">1.5</span>)
<span class="kw">mtext</span>(<span class="st">"A"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, <span class="dt">las =</span> <span class="dv">0</span>)
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="fl">0.5</span>, <span class="dt">col =</span> <span class="st">"grey"</span>)

<span class="kw">curve</span>(<span class="kw">predict</span>(model_glm, <span class="kw">data.frame</span>(<span class="dt">loglin_slope =</span> x), <span class="dt">type =</span> <span class="st">"resp"</span>), 
      <span class="dt">add =</span> <span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">"blue"</span>)

<span class="co"># Plot test_data (red)</span>

<span class="kw">points</span>(test_data<span class="op">$</span>loglin_slope, test_data<span class="op">$</span>decision, <span class="dt">pch =</span> <span class="dv">19</span>,
       <span class="dt">col =</span> <span class="kw">adjustcolor</span>(<span class="st">"red"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.3</span>))
<span class="kw">legend</span>(<span class="st">"right"</span>, <span class="kw">paste</span>(<span class="st">"Positive: "</span>, n_positive, 
                      <span class="st">"</span><span class="ch">\n</span><span class="st">Negative: "</span>, n_negative), <span class="dt">bty =</span> <span class="st">"n"</span>)


<span class="co"># Plot the sensitivity, specificity and other measures to describe </span>
<span class="co"># the prediction.</span>

position_bp &lt;-<span class="st"> </span><span class="kw">barplot</span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/as.matrix">as.matrix</a></span>(res_performeR), <span class="dt">yaxt =</span> <span class="st">"n"</span>, 
                       <span class="dt">ylab =</span> <span class="st">"Probability"</span>, <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">las =</span> <span class="dv">2</span>, 
                       <span class="dt">col =</span> <span class="kw">adjustcolor</span>(<span class="st">"grey"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.5</span>), 
                       <span class="dt">border =</span> <span class="st">"white"</span>)

<span class="kw">par</span>(<span class="dt">srt =</span> <span class="dv">90</span>)
<span class="kw">text</span>(position_bp, <span class="kw">rep</span>(<span class="fl">0.8</span>, <span class="kw">length</span>(res_performeR)), 
     <span class="kw">paste</span>(<span class="kw">signif</span>(res_performeR, <span class="dv">2</span>)<span class="op">*</span><span class="dv">100</span>, <span class="st">"%"</span>), <span class="dt">cex =</span> <span class="fl">0.6</span>)
<span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">"0"</span>, <span class="st">"1"</span>), <span class="dt">las =</span> <span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="fl">0.85</span>, <span class="dt">col =</span> <span class="st">"grey"</span>)

<span class="kw">mtext</span>(<span class="st">"B"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, <span class="dt">las =</span> <span class="dv">0</span>)</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_Logistic_Regression-1.png" alt="Machine classification by means of binomial logistic regression using the `loglin\_slope` predictor. A) For the calculation of a binomial logistic regression model, the categorical response variable $Y$ (decision with classes: negative and positive) must be converted to a numerical value. With binomial logistic regression, the probability of a categorical response can be estimated using the $X$ predictor variable. In this example, the predictor variable `loglin\_slope` is used. Grey measurement points (70\% of the data set) were used for training. Red dots represent the values used for testing. The regression curve of the binomial logistic regression is shown in blue. The grey horizontal line at 0.5 marks the threshold of probability above which it is determined whether an amplification curve is negative or positive. B) The performance indicators were calculated using the ``performeR()`` function. Sensitivity, TPR; Specificity, SPC; Precision, PPV; Negative prediction value, NPV; Fall-out, FPR; False negative rate, FNR; False detection rate, FDR; Accuracy, ACC; F1 score, F1; Matthews correlation coefficient, MCC, Cohens kappa (binary classification), kappa ($\kappa$)." width="700"><p class="caption">
Machine classification by means of binomial logistic regression using the <code>loglin\_slope</code> predictor. A) For the calculation of a binomial logistic regression model, the categorical response variable <span class="math inline">\(Y\)</span> (decision with classes: negative and positive) must be converted to a numerical value. With binomial logistic regression, the probability of a categorical response can be estimated using the <span class="math inline">\(X\)</span> predictor variable. In this example, the predictor variable <code>loglin\_slope</code> is used. Grey measurement points (70% of the data set) were used for training. Red dots represent the values used for testing. The regression curve of the binomial logistic regression is shown in blue. The grey horizontal line at 0.5 marks the threshold of probability above which it is determined whether an amplification curve is negative or positive. B) The performance indicators were calculated using the <code><a href="../reference/performeR.html">performeR()</a></code> function. Sensitivity, TPR; Specificity, SPC; Precision, PPV; Negative prediction value, NPV; Fall-out, FPR; False negative rate, FNR; False detection rate, FDR; Accuracy, ACC; F1 score, F1; Matthews correlation coefficient, MCC, Cohens kappa (binary classification), kappa (<span class="math inline">\(\kappa\)</span>).
</p>
</div>
<p>The sensitivity, specificity and further parameters for estimating the prediction were calculated using the <code><a href="../reference/performeR.html">performeR()</a></code> function (). The results indicate that the sensitivity and specificity for the test data set provides a good result. However, the results in this case depend heavily on the computer-aided random sampling of the training data and the total size of the data set. Over-fitting and under-fitting and other problems need to be addressed <span class="citation">(Walsh, Pollastri, and Tosatto 2015)</span>.</p>
<p>To proof the results, further methods such as Likelihood Ratio Test, McFadden’s <span class="math inline">\(R^{2}\)</span>, k-fold cross-validation, Receiver Operating Characteristic (ROC) analysis and model interpretation should be used <span class="citation">(Arlot and Celisse 2010, <span class="citation">McFadden (1974)</span>, <span class="citation">Sing et al. (2005)</span>)</span>.</p>
<ul>
<li>
<code>sd_bg</code> is the standard deviation from the first PCR cycle to the takeoff point (A). Manufacturers of thermo-cyclers use different sensors and data processing algorithms. Same applies to the detection chemistry used in experiments . The signal variation in the ground phase differs between the different systems (D). If no takeoff point can be determined from an amplification curve, the value for <code>sd_bg</code> is calculated from the first to the eighth PCR cycle. The results for the predictor <code>sd_bg</code> were broken down by the thermo-cycler and the output of the amplification reaction (negative, positive). It can be seen that the signal variation between the thermo-cyclers seems to be different. There is also a difference between negative and positive amplification curves . The <code>sd_bg</code> values differ significantly between negative and positive amplification curves (J).</li>
</ul>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_sd_bg-1.png" alt="Standard deviation in the ground phase of various qPCR devices. The `sd\_bg` predictor was used to determine if the standard deviation between the thermo-cyclers and between positive and negative amplification curves was different. The standard deviation was determined from the fluorescence values from the first cycle to the takeoff point. If the takeoff point could not be determined, the standard deviation from the first cycle to the eighth cycle was calculated. The Mann-Whitney test was used to compare the medians of the two populations (y, positive; n, negative). The differences were significant for A) LC\_480 (Roche), B) CFX96 (Bio-Rad) and C) LC96 (Roche)." width="700"><p class="caption">
Standard deviation in the ground phase of various qPCR devices. The <code>sd\_bg</code> predictor was used to determine if the standard deviation between the thermo-cyclers and between positive and negative amplification curves was different. The standard deviation was determined from the fluorescence values from the first cycle to the takeoff point. If the takeoff point could not be determined, the standard deviation from the first cycle to the eighth cycle was calculated. The Mann-Whitney test was used to compare the medians of the two populations (y, positive; n, negative). The differences were significant for A) LC_480 (Roche), B) CFX96 (Bio-Rad) and C) LC96 (Roche).
</p>
</div>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_bg_pt-1.png" alt="Values of predictors calculated from negative and positive amplification curves. Amplification curves predictors from the `data\_sample\_subset` data set were used since they contain positive and negative amplification curves and amplification curves that exhibit a hook effect or non-sigmoid shapes, for instance. A) `eff`, optimized PCR efficiency in a sliding window. B) `sliwin`, PCR efficiency according to the window-of-linearity method. C) `cpDdiff`, difference between the Cq values calculated from the first and the second derivative maximum. D) `loglin\_slope`, slope from cycle at second derivative maximum to second derivative minimum. E) `cpD2\_range`, absolute difference between the minimum and maximum of the second derivative. F) `top`, takeoff point. G) `f.top`, fluorescence intensity at takeoff point. H) `tdp`, takedown point. I) `f.tdp`, fluorescence intensity at the takedown point. J) `bg.stop`, estimated end of the ground phase. K) `amp.stop`, estimated end of the exponential phase. L) `convInfo\_iteratons`, number of iterations until convergence when fitting a multiparametric model. The classes were compared using the Wilcoxon Rank Sum Test." width="1056"><p class="caption">
Values of predictors calculated from negative and positive amplification curves. Amplification curves predictors from the <code>data\_sample\_subset</code> data set were used since they contain positive and negative amplification curves and amplification curves that exhibit a hook effect or non-sigmoid shapes, for instance. A) <code>eff</code>, optimized PCR efficiency in a sliding window. B) <code>sliwin</code>, PCR efficiency according to the window-of-linearity method. C) <code>cpDdiff</code>, difference between the Cq values calculated from the first and the second derivative maximum. D) <code>loglin\_slope</code>, slope from cycle at second derivative maximum to second derivative minimum. E) <code>cpD2\_range</code>, absolute difference between the minimum and maximum of the second derivative. F) <code>top</code>, takeoff point. G) <code>f.top</code>, fluorescence intensity at takeoff point. H) <code>tdp</code>, takedown point. I) <code>f.tdp</code>, fluorescence intensity at the takedown point. J) <code>bg.stop</code>, estimated end of the ground phase. K) <code>amp.stop</code>, estimated end of the exponential phase. L) <code>convInfo\_iteratons</code>, number of iterations until convergence when fitting a multiparametric model. The classes were compared using the Wilcoxon Rank Sum Test.
</p>
</div>
</div>
</div>
<div id="integration-of-the-amptester-function-in" class="section level3">
<h3 class="hasAnchor">
<a href="#integration-of-the-amptester-function-in" class="anchor"></a>Integration of the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/amptester">amptester()</a></code> function in </h3>
<p><code>amptester_polygon</code> is another method to calculate the area under an amplification curve. <code>amptester_polygon</code> is part of the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/amptester">amptester()</a></code> [] package <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015)</span>. In contrast to the implementation in the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/amptester">amptester()</a></code> is the <code>amptester_polygon</code> value normalized to the total number of cycles. This method may allow comparable predictions (Ds).</p>
<div class="figure">
<img src="PCRedux_files/figure-html/statistical_methods_amptester-1.png" alt="Analysis of amplification curves with the ``amptester()`` function. A \&amp; B) The threshold test (THt) is based on the Wilcoxon ranksum test and compares 20\% of the fluorescence values of the ground phase with 15\% of the plateau phase. In the example, a significant difference ($p = 0.000512$) was found for the positive amplification curve. However, this did not apply to the negative amplification curve ($p = 0.621$). C \&amp; D) A Q-Q diagram is used to graphically compare two probability distributions.  In this study the probability distribution of the amplification curve was compared with a theoretical normal distribution. The orange line is the theoretically normal quantil-quantile plot that passes through the probabilities of the first and third quartiles. The Shapiro-Wilk test (SHt) of normality checks whether the underlying measurement data of the amplification curve is significantly normal distributed. Since the p-value of $7.09 e^{-9}$ of the positive amplification curve is $\alpha \leq 5e^{-4}$, the null hypothesis is rejected. However, this does not apply to the negative amplification curve ($p = 0.895$). E \&amp; F) The linear regression test (LRt) calculates the coefficient of determination ($R^{2}$) using an ordinary least square regression where all measured values are integrated into the model in a cycle-dependent manner. Experience shows that the non-linear part of an amplification curve has a $R^{2}$ smaller than 0.8, which is also shown in the example." width="700"><p class="caption">
Analysis of amplification curves with the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/amptester">amptester()</a></code> function. A &amp; B) The threshold test (THt) is based on the Wilcoxon ranksum test and compares 20% of the fluorescence values of the ground phase with 15% of the plateau phase. In the example, a significant difference (<span class="math inline">\(p = 0.000512\)</span>) was found for the positive amplification curve. However, this did not apply to the negative amplification curve (<span class="math inline">\(p = 0.621\)</span>). C &amp; D) A Q-Q diagram is used to graphically compare two probability distributions. In this study the probability distribution of the amplification curve was compared with a theoretical normal distribution. The orange line is the theoretically normal quantil-quantile plot that passes through the probabilities of the first and third quartiles. The Shapiro-Wilk test (SHt) of normality checks whether the underlying measurement data of the amplification curve is significantly normal distributed. Since the p-value of <span class="math inline">\(7.09 e^{-9}\)</span> of the positive amplification curve is <span class="math inline">\(\alpha \leq 5e^{-4}\)</span>, the null hypothesis is rejected. However, this does not apply to the negative amplification curve (<span class="math inline">\(p = 0.895\)</span>). E &amp; F) The linear regression test (LRt) calculates the coefficient of determination (<span class="math inline">\(R^{2}\)</span>) using an ordinary least square regression where all measured values are integrated into the model in a cycle-dependent manner. Experience shows that the non-linear part of an amplification curve has a <span class="math inline">\(R^{2}\)</span> smaller than 0.8, which is also shown in the example.
</p>
</div>

<div id="earlyreg---a-function-to-calculate-the-slope-and-intercept-in-the-ground-phase-of-an-amplification-curve" class="section level4">
<h4 class="hasAnchor">
<a href="#earlyreg---a-function-to-calculate-the-slope-and-intercept-in-the-ground-phase-of-an-amplification-curve" class="anchor"></a><code><a href="../reference/earlyreg.html">earlyreg()</a></code> - A Function to Calculate the Slope and Intercept in the Ground Phase of an Amplification Curve </h4>
<p>The signal height and the slope in the first cylces (1 - 10) of amplification curves are potentially useful because some qPCR systems calibrate themselves by fluorescence intensity of the first cycles. This is noticeable as strong signal changes which appear spontaneously between the first and second cycle (e.g., B). For another, the signal level can be used to determine which background signal is present and whether the ground phase already has a slope. Moreover, characteristics of the detection probe system are noticeable (see ). From the slope it could be deduced whether amplification has already started (see ).</p>
<p>In addition, the <code><a href="../reference/earlyreg.html">earlyreg()</a></code> function was developed. This function uses an ordinary least squares linear regression within a limited number of cycles. As ROI, the first 10 cycles were defined. This restriction is based on empirical data suggesting that during the first ten cycles only a significant increase in signal strength can be measured within few qPCRs. However, <code><a href="../reference/earlyreg.html">earlyreg()</a></code> does not ignore the first cycle, as many thermo-cyclers use this cycle for sensor calibration. Extreme values are therefore included. As standard, the next nine amplitude values are used for the linear regression. The number of cycles can also be adjusted via the parameter <code>range</code>. Since all amplification curves are normalized to the 99%-percentile, there is also a comparability between the background signals and the slopes. The output of the <code><a href="../reference/earlyreg.html">earlyreg()</a></code> function is:</p>
<ul>
<li>
<code>slope_bg</code>, which is the slope of the ordinary least squares linear regression model,</li>
<li>
<code>intercept_bg</code>, which is the intercept of the linear model and</li>
<li>
<code>sigma_bg</code>, which is the square root of the estimated variance of the random error.</li>
</ul>
<p>The <code>slope_bg</code>, <code>intercept_bg</code> and <code>sigma_bg</code> values differ significantly between negative and positive amplification curves (G-I).</p>
<p>The following example illustrates a possible use of the function <code><a href="../reference/earlyreg.html">earlyreg()</a></code>. For that purpose amplification curves from the <code>C127EGHP</code> data set were analysed (A). In figure A the amplification curves for all cycles are shown. Next, the <code><a href="../reference/earlyreg.html">earlyreg()</a></code> function was used to determine the <code>slope_bg</code>, <code>intercept_bg</code> and <code>sigma_bg</code> in the range of the first ten PCR cycles. The results were used in a cluster analysis using k-means clustering. Therefore, the slope seems to be an indicator of differences between the amplification curves. The B shows the first 8 cycles colored according to their cluster. After the cluster analysis this could also be observed (D-F). Hence, it can be postulated that the slope in the background phase is useful for the amplification curve classification.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PCRedux)

<span class="co"># box_cox() function for the Box-Cox transformation of data</span>

box_cox &lt;-<span class="st"> </span><span class="cf">function</span>(x, <span class="dt">lambda =</span> <span class="dv">1</span>, <span class="dt">offset =</span> <span class="dv">0</span>) {
    <span class="cf">if</span> (lambda <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) {
        <span class="kw">log</span>(x <span class="op">+</span><span class="st"> </span>offset)
    } <span class="cf">else</span> 
    {
        ((x <span class="op">+</span><span class="st"> </span>offset)<span class="op">^</span>lambda <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)<span class="op">/</span>lambda
    }
}

<span class="co"># Load the C127EGHP data set</span>
data &lt;-<span class="st"> </span>chipPCR<span class="op">::</span>C127EGHP[, <span class="op">-</span><span class="dv">1</span>]

<span class="co"># Normalize each amplification curve to their 0.99 percentile and use the</span>
<span class="co"># earlyreg() function to determine the slope and intercept of the first</span>
<span class="co"># cycles 'user_range'</span>

user_range &lt;-<span class="st"> </span><span class="dv">8</span>

res_earlyreg &lt;-<span class="st"> </span><span class="kw">do.call</span>(rbind, <span class="kw">lapply</span>(2L<span class="op">:</span><span class="kw">ncol</span>(data), <span class="cf">function</span>(i) {
  <span class="kw"><a href="../reference/earlyreg.html">earlyreg</a></span>(<span class="dt">x =</span> data[, <span class="dv">1</span>], <span class="dt">y =</span> data[, i], <span class="dt">range =</span> user_range, <span class="dt">normalize =</span> <span class="ot">TRUE</span>)
})) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">box_cox</span>(.)

<span class="co"># Label the observation with their names</span>
<span class="kw">rownames</span>(res_earlyreg) &lt;-<span class="st"> </span><span class="kw">substr</span>(<span class="kw">colnames</span>(data)[<span class="op">-</span><span class="dv">1</span>], <span class="dv">1</span>, <span class="dv">10</span>)

<span class="co"># Show the first five lines of the res_earlyreg data matrix</span>

<span class="kw">head</span>(res_earlyreg)</code></pre></div>
<pre><code>##      intercept      slope      sigma
## EG1 -0.9996982 -1.0000257 -0.9994170
## EG2 -0.9999187 -0.9999724 -0.9994349
## EG3 -1.0001748 -0.9999236 -0.9995357
## EG4 -1.0000410 -0.9999487 -0.9994961
## EG5 -1.0001467 -0.9999259 -0.9995627
## EG6 -1.0003437 -0.9998825 -0.9995230</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Perform k-means clustering on the res_earlyreg data matrix</span>
cl &lt;-<span class="st"> </span><span class="kw">kmeans</span>(res_earlyreg, <span class="dt">centers =</span> <span class="dv">2</span>)

<span class="co"># Plot the results</span>
<span class="co"># Use x_roi (cycles) and rfu_range (RFU values) to limit the </span>
<span class="co"># range for the detailed plot of first cycles. </span>

x_roi &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span>(user_range <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)
rfu_range &lt;-<span class="st"> </span><span class="kw">range</span>(data[x_roi, <span class="op">-</span><span class="dv">1</span>])

<span class="co"># Create graphic device for the plot(s)</span>
<span class="kw">layout</span>(<span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>), <span class="dv">3</span>, <span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>))

<span class="co"># Plot of raw amplification curves</span>

<span class="kw">matplot</span>(
    data[, <span class="dv">1</span>], data[, <span class="op">-</span><span class="dv">1</span>], <span class="dt">ylim =</span> <span class="kw">range</span>(data[, <span class="op">-</span><span class="dv">1</span>]), <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">lty =</span> <span class="dv">1</span>, 
        <span class="dt">type =</span> <span class="st">"l"</span>, <span class="dt">xlab =</span> <span class="st">"Cycles"</span>, <span class="dt">ylab =</span> <span class="st">"RFU"</span>, <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">col =</span> <span class="st">"grey"</span>
)
<span class="kw">mtext</span>(<span class="st">"A"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">c</span>(<span class="dv">1</span>,user_range))
<span class="kw">text</span>(<span class="dv">3</span>, <span class="kw">range</span>(data[, <span class="op">-</span><span class="dv">1</span>])[<span class="dv">2</span>], <span class="st">"ROI"</span>)

<span class="co"># Detailed plot of the first cycles and the clusters according</span>
<span class="co"># to the k-means clustering</span>
<span class="co"># Define some user colors (blue: EvaGreen, orange: Hydrolysis probes)</span>
colors &lt;-<span class="st"> </span><span class="kw">c</span>(
    <span class="kw">adjustcolor</span>(<span class="st">"blue"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.5</span>),
            <span class="kw">adjustcolor</span>(<span class="st">"orange"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.8</span>)
)

<span class="kw">matplot</span>(<span class="ot">NA</span>, <span class="ot">NA</span>, <span class="dt">xlim =</span> <span class="kw">range</span>(x_roi), <span class="dt">ylim =</span> rfu_range, <span class="dt">xlab =</span> <span class="st">"Cycles"</span>, 
        <span class="dt">ylab =</span> <span class="st">"RFU"</span>, <span class="dt">main =</span> <span class="st">""</span>)

<span class="cf">for</span>(i <span class="cf">in</span> 1L<span class="op">:</span><span class="kw">length</span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/duplicated">unique</a></span>(cl<span class="op">$</span>cluster))) {
cl_id &lt;-<span class="st"> </span><span class="kw">which</span>(cl[[<span class="st">"cluster"</span>]] <span class="op">==</span><span class="st"> </span>i) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
<span class="kw">par</span>(<span class="dt">new=</span><span class="ot">TRUE</span>)
<span class="kw">matplot</span>(data[x_roi, <span class="dv">1</span>], <span class="dt">xlab =</span> <span class="st">""</span>, <span class="dt">ylab =</span> <span class="st">""</span>, <span class="dt">xaxt =</span> <span class="st">"n"</span>, <span class="dt">yaxt =</span> <span class="st">"n"</span>, 
        data[x_roi, cl_id], <span class="dt">ylim =</span> rfu_range, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">"l"</span>, 
        <span class="dt">col =</span> colors[i])
}


<span class="kw">mtext</span>(<span class="st">"B"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">c</span>(<span class="dv">1</span>,user_range))
<span class="kw">text</span>(<span class="dv">3</span>, rfu_range[<span class="dv">2</span>], <span class="st">"ROI"</span>)
<span class="kw">legend</span>(<span class="st">"bottomleft"</span>, <span class="kw">c</span>(<span class="st">"Cluster 1"</span>, <span class="st">"Cluster 2"</span>), <span class="dt">pch =</span> <span class="dv">15</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, 
       <span class="dt">col =</span> colors, <span class="dt">bty =</span> <span class="st">"n"</span>)

<span class="co"># Overview of clusters and corresponding detection chemistry</span>

eghp &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="fl">0.7</span>, <span class="kw">length</span>(cl<span class="op">$</span>cluster))
<span class="kw">names</span>(eghp) &lt;-<span class="st"> </span><span class="kw">names</span>(cl<span class="op">$</span>cluster)

<span class="kw">barplot</span>(eghp, <span class="dt">las =</span> <span class="dv">2</span>, <span class="dt">col =</span> colors[cl[[<span class="st">"cluster"</span>]]], 
        <span class="dt">border =</span> <span class="st">"white"</span>, <span class="dt">xlab =</span> <span class="st">""</span>, <span class="dt">ylab =</span> <span class="st">""</span>, 
        <span class="dt">yaxt =</span> <span class="st">"n"</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">2.2</span>), <span class="dt">cex.axis =</span> <span class="fl">0.7</span>)
<span class="kw">mtext</span>(<span class="st">"C"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)
<span class="kw">legend</span>(<span class="st">"topleft"</span>, <span class="kw">c</span>(<span class="st">"Cluster 1"</span>, <span class="st">"Cluster 2"</span>), <span class="dt">pch =</span> <span class="dv">15</span>, <span class="dt">col =</span> colors, 
       <span class="dt">bty =</span> <span class="st">"n"</span>, <span class="dt">box.col =</span>  <span class="st">"white"</span>, <span class="dt">cex =</span> <span class="fl">0.9</span>)
<span class="kw">arrows</span>(<span class="fl">0.5</span>, <span class="dv">2</span>, <span class="dv">38</span>, <span class="dv">2</span>, <span class="dt">angle =</span> <span class="dv">90</span>, <span class="dt">code =</span> <span class="dv">3</span>)
<span class="kw">arrows</span>(<span class="dv">39</span>, <span class="dv">2</span>, <span class="fl">76.5</span>, <span class="dv">2</span>, <span class="dt">angle =</span> <span class="dv">90</span>, <span class="dt">code =</span> <span class="dv">3</span>)
<span class="kw">text</span>(<span class="kw">c</span>(<span class="fl">18.75</span>, <span class="fl">57.5</span>), <span class="kw">c</span>(<span class="fl">1.6</span>, <span class="fl">1.6</span>), <span class="kw">c</span>(<span class="st">"EvaGreen"</span>, <span class="st">"Hydrolysis probes"</span>))</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/earlyreg_slopes-1.png" alt="Analysis of the ground phase with the ``earlyreg()`` function . The amplification curves (`C127EGHP` data set, n = 64 amplification curves). This data set consists of 32 samples, which were simultaneously monitored with the intercalator EvaGreen or hydrolysis probes . A) All amplification curves have slightly different slopes and intercepts in the first cycles of the ground phase (ROI: Cycles 1 to 8). Both the slope and the intercept of each amplification curve were used for a cluster analysis (k-means, Hartigan-Wong algorithm, number of centers \textit{k = 2}). B) The amplification curves were assigned to five clusters, depending on their slope and their intersection (red, black). C) Finally, the clusters were associated to the detection chemistries (EvaGreen (EG) or hydrolysis probes (HP))." width="700"><p class="caption">
Analysis of the ground phase with the <code><a href="../reference/earlyreg.html">earlyreg()</a></code> function . The amplification curves (<code>C127EGHP</code> data set, n = 64 amplification curves). This data set consists of 32 samples, which were simultaneously monitored with the intercalator EvaGreen or hydrolysis probes . A) All amplification curves have slightly different slopes and intercepts in the first cycles of the ground phase (ROI: Cycles 1 to 8). Both the slope and the intercept of each amplification curve were used for a cluster analysis (k-means, Hartigan-Wong algorithm, number of centers ). B) The amplification curves were assigned to five clusters, depending on their slope and their intersection (red, black). C) Finally, the clusters were associated to the detection chemistries (EvaGreen (EG) or hydrolysis probes (HP)).
</p>
</div>
</div>
<div id="head2tailratio---a-function-to-calculate-the-ratio-of-the-head-and-the-tail-of-a-quantitative-pcr-amplification-curve" class="section level4">
<h4 class="hasAnchor">
<a href="#head2tailratio---a-function-to-calculate-the-ratio-of-the-head-and-the-tail-of-a-quantitative-pcr-amplification-curve" class="anchor"></a><code><a href="../reference/head2tailratio.html">head2tailratio()</a></code> - A Function to Calculate the Ratio of the Head and the Tail of a Quantitative PCR Amplification Curve</h4>
<p>The ratios from the ground and plateau phase can be used to search for patterns in amplification curves. Positive amplification curves have different slopes and intercepts at the start of the amplification curve (head, background region) and the end of the amplification curve (tail, plateau region). Therefore, these regions are potentially useful to extract a predictor for an amplification curve classification. Negative amplification curves (no slope) are assumed to have a ratio of about 1. In contrast, positive amplification curves should have a ratio of less than 1.</p>
<p>The <span class="math inline">\(n\)</span>-dimensional space of all predictor variables <span class="math inline">\(X_{1,2 \ldots n}\)</span> is also called feature space. In the present study the feature space was extended by domian knowledge using known features. The<code><a href="../reference/head2tailratio.html">head2tailratio()</a></code>-function is an example for this. Here the feature <span class="math inline">\(X_{3}\equiv head2tail\_ratio\)</span> could be generated by determining the ratio of the <span class="math inline">\(X_{1}\equiv\)</span> <em>fluorescence intensity in the head region</em> and <span class="math inline">\(X_{2}\equiv\)</span> <em>fluorescence intensity in the tail region</em> of a quantitative PCR amplification curve (<span class="math inline">\(X_{3} = \frac{X_{1}}{X_{2}}\)</span>). As ROI, the areas in the ground phase (head) and plateau phases (tail) are used (A). For the calculation, the median from the first six data points of the amplification curve and the median from the last six data points are used. The determination of six data points in both regions was made on the basis of . As a rule, no significant increase in amplification signals can be measured in the first six cycles and in the last six cycles, the amplification curve is usually about to transition into the plateau. This assumption is sometimes violated (e.g.. <em>hook effect</em>) and might lead to false estimates.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PCRedux)

<span class="co"># Load the RAS002 amplification curve data set and assign it to the object data</span>

data &lt;-<span class="st"> </span>RAS002

<span class="co"># Load the RAS002 decision data set and assign it to the object data_decisions</span>
data_decisions &lt;-<span class="st"> </span>RAS002_decisions

<span class="co"># Calculate the head2tailratio of all amplification curves</span>

res_head2tailratio &lt;-<span class="st"> </span><span class="kw">lapply</span>(2L<span class="op">:</span><span class="kw">ncol</span>(data), <span class="cf">function</span>(i) {
  <span class="kw"><a href="../reference/head2tailratio.html">head2tailratio</a></span>(
    <span class="dt">y =</span> data[, i], <span class="dt">normalize =</span> <span class="ot">TRUE</span>, <span class="dt">slope_normalizer =</span> <span class="ot">TRUE</span>,
    <span class="dt">verbose =</span> <span class="ot">TRUE</span>
  )
})

<span class="co"># Fetch all values of the head2tailratio analysis for a later comparison</span>
<span class="co"># by a boxplot.</span>

res &lt;-<span class="st"> </span><span class="kw">sapply</span>(1L<span class="op">:</span><span class="kw">length</span>(res_head2tailratio), <span class="cf">function</span>(i)
  res_head2tailratio[[i]]<span class="op">$</span>head_tail_ratio)

data_normalized &lt;-<span class="st"> </span><span class="kw">cbind</span>(
  data[, <span class="dv">1</span>],
  <span class="kw">sapply</span>(2L<span class="op">:</span><span class="kw">ncol</span>(data), <span class="cf">function</span>(i) {
    data[, i] <span class="op">/</span><span class="st"> </span><span class="kw">quantile</span>(data[, i], <span class="fl">0.99</span>)
  })
)

<span class="co"># Assign colors to the classes (n: black, y: green).</span>
colors &lt;-<span class="st"> </span><span class="kw">as.character</span>(<span class="kw">factor</span>(
  data_decisions, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">"y"</span>, <span class="st">"n"</span>),
  <span class="dt">labels =</span> <span class="kw">c</span>(
      <span class="kw">adjustcolor</span>(<span class="st">"green"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.5</span>), <span class="kw">adjustcolor</span>(<span class="st">"black"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.5</span>))
))

res_wilcox.test &lt;-<span class="st"> </span>stats<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/stats/topics/wilcox.test">wilcox.test</a></span>(res <span class="op">~</span><span class="st"> </span>data_decisions)</code></pre></div>
<p>The amplification curves in  show a signal increase within the first three cycles and the amplification curves in C have a negative slope in the tail. The median is used to minimize the influence of outliers.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Plot the results of the analysis</span>
<span class="co">#</span>
<span class="co"># Position and plot parameters</span>
h &lt;-<span class="st"> </span><span class="kw">max</span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/na.omit.data.table">na.omit</a></span>(res))
h_text &lt;-<span class="st"> </span><span class="kw">rep</span>(h <span class="op">*</span><span class="st"> </span><span class="fl">0.976</span>, <span class="dv">2</span>)

<span class="co"># Create graphic device for the plot(s)</span>
<span class="kw">layout</span>(<span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>), <span class="dv">1</span>, <span class="dv">3</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>))

<span class="kw">matplot</span>(
  data_normalized[, <span class="dv">1</span>], data_normalized[, <span class="op">-</span><span class="dv">1</span>],
  <span class="dt">xlab =</span> <span class="st">"Cycles"</span>, <span class="dt">ylab =</span> <span class="st">"normalized RFU"</span>, <span class="dt">main =</span> <span class="st">""</span>,
  <span class="dt">type =</span> <span class="st">"l"</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> colors
)
<span class="cf">for</span> (i <span class="cf">in</span> 1L<span class="op">:</span>(<span class="kw">ncol</span>(data_normalized) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)) {
  <span class="kw">points</span>(
    res_head2tailratio[[i]]<span class="op">$</span>x_roi, res_head2tailratio[[i]]<span class="op">$</span>y_roi,
    <span class="dt">col =</span> colors[i], <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">cex =</span> <span class="fl">1.5</span>
  )
  <span class="kw">abline</span>(res_head2tailratio[[i]]<span class="op">$</span>fit, <span class="dt">col =</span> colors[i], <span class="dt">lwd =</span> <span class="dv">2</span>)
}
<span class="kw">mtext</span>(<span class="st">"A"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)

<span class="co"># Boxplot of the head2tail ratios of the positive and negative</span>
<span class="co"># amplification curves.</span>

<span class="kw">boxplot</span>(res <span class="op">~</span><span class="st"> </span>data_decisions, <span class="dt">col =</span> <span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/duplicated">unique</a></span>(colors), <span class="dt">ylab =</span> <span class="st">"Head to Tail Ratio"</span>)

<span class="kw">lines</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">rep</span>(h <span class="op">*</span><span class="st"> </span><span class="fl">0.945</span>, <span class="dv">2</span>))
<span class="kw">text</span>(<span class="fl">1.5</span>, h_text, <span class="kw">paste0</span>(<span class="st">"P = "</span>, <span class="kw">signif</span>(res_wilcox.test[[<span class="st">"p.value"</span>]])), 
     <span class="dt">cex =</span> <span class="dv">1</span>)

<span class="kw">mtext</span>(<span class="st">"B"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/figure_head2tailratio-1.png" alt="Ratio between the head and the tail of a quantitative PCR amplification curve. A) Plot of quantile normalized amplification curves from the `RAS002` data set. Data points used in the head and and tail are highlighted by circles. The intervals for the Robust Linear Regression are automatically selected using the 25\% and 75\% quantiles. Therefore, not all data points are used in the regression model. The straight line is the regression line from the robust linear model. The slopes of the positive and negative amplification curves differ. B) Boxplot for the comparison of the $head/tail$ ratio. Positive amplification curves have a lower ratio than negative curves. The difference between the classes is significant." width="700"><p class="caption">
Ratio between the head and the tail of a quantitative PCR amplification curve. A) Plot of quantile normalized amplification curves from the <code>RAS002</code> data set. Data points used in the head and and tail are highlighted by circles. The intervals for the Robust Linear Regression are automatically selected using the 25% and 75% quantiles. Therefore, not all data points are used in the regression model. The straight line is the regression line from the robust linear model. The slopes of the positive and negative amplification curves differ. B) Boxplot for the comparison of the <span class="math inline">\(head/tail\)</span> ratio. Positive amplification curves have a lower ratio than negative curves. The difference between the classes is significant.
</p>
</div>
<p>In  and in  it was shown that negative amplification curves may have a slope with the positive or negative sign. The is no consent in the literate and among peers how to deal with this during the processing. One solution is to include the slope as factor in the ratio calculation. The <code><a href="../reference/head2tailratio.html">head2tailratio()</a></code> function uses a linear model that calculates the slope between the ground and plateau phases. If the slope of the model is significant, then the ratio from the head and tail is normalized to this slope. This requires setting the <code>slope_normalizer</code> parameter in the <code><a href="../reference/head2tailratio.html">head2tailratio()</a></code> function. By default, this parameter is not set.</p>
<p>The <code>head2tail_ratio</code> values differ significantly between negative and positive amplification curves (K).</p>
</div>
<div id="hookreg-and-hookregnl---functions-to-detect-hook-effect-like-curvatures" class="section level4">
<h4 class="hasAnchor">
<a href="#hookreg-and-hookregnl---functions-to-detect-hook-effect-like-curvatures" class="anchor"></a><code><a href="../reference/hookreg.html">hookreg()</a></code> and <code><a href="../reference/hookregNL.html">hookregNL()</a></code> - Functions to Detect Hook Effect-like Curvatures</h4>
<p><code><a href="../reference/hookreg.html">hookreg()</a></code> and <code><a href="../reference/hookregNL.html">hookregNL()</a></code> are functions to detect amplification curves bearing a hook effect <span class="citation">(Barratt and Mackay 2002)</span> or negative slope at the end of the amplification curve. Both functions calculate the slope and intercept of an amplification curve data. The assumption is that a strong negative slope at the end of an amplification curve is indicative for a hook effect. <code><a href="../reference/hookreg.html">hookreg()</a></code> and <code><a href="../reference/hookregNL.html">hookregNL()</a></code> are part of a peer-reviewed publication. For this reason, the functions will not be discussed here.</p>
</div>
<div id="mblrr---a-function-perform-the-quantile-filter-based-local-robust-regression" class="section level4">
<h4 class="hasAnchor">
<a href="#mblrr---a-function-perform-the-quantile-filter-based-local-robust-regression" class="anchor"></a><code><a href="../reference/mblrr.html">mblrr()</a></code> - A Function Perform the Quantile-filter Based Local Robust Regression </h4>
<p><code><a href="../reference/mblrr.html">mblrr()</a></code> is a function to perform the edian ased ocal obust egression (mblrr) from a quantitative PCR experiment. In detail, this function attempts to break the amplification curve in two ROIs (head (~background) and tail (~plateau)). As opposed to the <code><a href="../reference/earlyreg.html">earlyreg()</a></code> function, the <code><a href="../reference/mblrr.html">mblrr()</a></code> function does not use a fixed interval. Instead, the <code><a href="../reference/mblrr.html">mblrr()</a></code> function dynamically determines cut points for each amplification curve. For the <code><a href="../reference/mblrr.html">mblrr()</a></code> function was defined:</p>
<ul>
<li>The 25% quantile is the value for which 25% of all values are smaller than this value.</li>
<li>The 75% quantile is the value for which 75% of all values are greater than this value.</li>
</ul>
<p>Subsequent, a robust linear regression analysis (<code>lmrob()</code>) is preformed individually on both regions of the amplification curve. The rationale behind this analysis is that the slope and intercept of an amplification curve differ in the background and plateau region. This is also shown by the simulations in A-C. In the example shown below, the observations “P01.W19”, “P06.W35”, “P33.W66”, “P65.W90”, “P71.W23” and “P87.W01” were arbitrarily selected for demonstration purposes . Another example is shown in A. Those amplification curves have a slight negative trend in the base-line region and a positive trend in the plateau region.</p>
<p>The correlation coefficient is a measure to quantify the dependence on variables (e. g., number of cycles, signal height). The correlation coefficient is always between -1 and 1, with a value close to -1 describing a strong-negative dependency and close to 1 describing a strong-positive dependency; if the value is 0, there is no dependency between the variables. The most frequently used correlation coefficient to describe a linear dependency is the Pearson correlation coefficient <em>r</em>.</p>
<p>The correlation coefficient can also be used as a predictor. Similar data structures have similar correlation coefficients. Correlation coefficients are between -1 and +1, with -1 being a strong negative correlation and 1 a strong positive correlation. The values of -1 and 1 have a perfect correlation. If the value is 0, there is no correlation between the two variables. However, variables that are not strongly correlated can also be important for modeling.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PCRedux)

<span class="co"># Select four amplification curves from the RAS002 data set</span>
amplification_curves &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">44</span>, <span class="dv">45</span>)
data &lt;-<span class="st"> </span>RAS002[, <span class="kw">c</span>(<span class="dv">1</span>, amplification_curves)]

<span class="co"># Load the decision_res_htPCR.csv data set from a csv file.</span>
filename &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">"decision_res_RAS002.csv"</span>, <span class="dt">package =</span> <span class="st">"PCRedux"</span>)
decision_res &lt;-<span class="st"> </span>data.table<span class="op">::</span><span class="kw">fread</span>(filename, <span class="dt">data.table =</span> <span class="ot">FALSE</span>)

<span class="co"># Overview of the amplicon curve classifications</span>
res_decision &lt;-<span class="st"> </span>decision_res[amplification_curves <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="op">-</span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">4</span>)]

res_decision</code></pre></div>
<pre><code>##                      RAS002 test.result.1 conformity
## 1  A01_gDNA.._unkn_B.Globin             y       TRUE
## 2     A01_gDNA.._unkn_HPRT1             n       TRUE
## 3  A02_gDNA.._unkn_B.Globin             y       TRUE
## 4     A02_gDNA.._unkn_HPRT1             n       TRUE
## 43 B10_gDNA.._unkn_B.Globin             n       TRUE
## 44    B10_gDNA.._unkn_HPRT1             n       TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Plot the regions and the linear regression line in the </span>
<span class="co"># amplification curve plot</span>

colors &lt;-<span class="st"> </span><span class="kw">c</span>(
            <span class="kw">adjustcolor</span>(<span class="st">"blue"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.5</span>),
            <span class="kw">adjustcolor</span>(<span class="st">"orange"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.8</span>)
           )

<span class="co"># Create graphic device for the plot(s)</span>
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">2</span>))

<span class="cf">for</span> (i <span class="cf">in</span> 2L<span class="op">:</span><span class="kw">ncol</span>(data)) {
  x &lt;-<span class="st"> </span>data[, <span class="dv">1</span>]
  y_tmp &lt;-<span class="st"> </span>data[, i] <span class="op">/</span><span class="st"> </span><span class="kw">quantile</span>(data[, i], <span class="fl">0.99</span>)
  res_q25 &lt;-<span class="st"> </span>y_tmp <span class="op">&lt;</span><span class="st"> </span><span class="kw">quantile</span>(y_tmp, <span class="fl">0.25</span>)
  res_q75 &lt;-<span class="st"> </span>y_tmp <span class="op">&gt;</span><span class="st"> </span><span class="kw">quantile</span>(y_tmp, <span class="fl">0.75</span>)
  res_q25_lm &lt;-<span class="st"> </span><span class="kw">try</span>(
    <span class="kw">suppressWarnings</span>(<span class="kw">lmrob</span>(y_tmp[res_q25] <span class="op">~</span><span class="st"> </span>x[res_q25])),
    <span class="dt">silent =</span> <span class="ot">TRUE</span>
  )
  res_q75_lm &lt;-<span class="st"> </span><span class="kw">try</span>(
    <span class="kw">suppressWarnings</span>(<span class="kw">lmrob</span>(y_tmp[res_q75] <span class="op">~</span><span class="st"> </span>x[res_q75])),
    <span class="dt">silent =</span> <span class="ot">TRUE</span>
  )

  <span class="kw">plot</span>(x, y_tmp, <span class="dt">xlab =</span> <span class="st">"Cycles"</span>, <span class="dt">ylab =</span> <span class="st">"RFU (normalized)"</span>,
    <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">type =</span> <span class="st">"b"</span>, <span class="dt">pch =</span> <span class="dv">19</span>)
  
  <span class="kw">mtext</span>(<span class="kw">paste0</span>(LETTERS[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>], <span class="st">"   "</span>, <span class="kw">colnames</span>(data)[i]), <span class="dt">cex =</span> <span class="dv">1</span>, 
        <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)
  <span class="kw">legend</span>(<span class="st">"topleft"</span>, <span class="kw">paste0</span>(<span class="kw">ifelse</span>(res_decision[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dv">2</span>] <span class="op">==</span><span class="st"> "n"</span>,
                                  <span class="st">"negative"</span>, <span class="st">"positive"</span>)), 
         <span class="dt">bty =</span> <span class="st">"n"</span>)
  <span class="kw">abline</span>(res_q25_lm, <span class="dt">col =</span> colors[<span class="dv">1</span>])
  <span class="kw">points</span>(x[res_q25], y_tmp[res_q25], <span class="dt">cex =</span> <span class="fl">2.5</span>, <span class="dt">col =</span> colors[<span class="dv">1</span>])
  <span class="kw">abline</span>(res_q75_lm, <span class="dt">col =</span> colors[<span class="dv">2</span>])
  <span class="kw">points</span>(x[res_q75], y_tmp[res_q75], <span class="dt">cex =</span> <span class="fl">2.5</span>, <span class="dt">col =</span> colors[<span class="dv">2</span>])
}</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_mblrr-1.png" alt="Robust local regression to analyze amplification curves. The amplification curves were arbitrarily selected from the `RAS002` data set. In the qPCR, the target genes beta globin (B. globin) and HPRT1 were simultaneously measured in a PCR cavity using two specific hydrolysis probes (duplex qPCR). Both positive (A, C, E) and negative (B, D, F) amplification curves were used. The amplification curves are normalized to the 99\% quantile. Not the differences in slopes and intercepts (blue and orange lines and dots). The ``mblrr()`` function is presumably useful for data sets which are accompanied by noise and artifacts." width="700"><p class="caption">
Robust local regression to analyze amplification curves. The amplification curves were arbitrarily selected from the <code>RAS002</code> data set. In the qPCR, the target genes beta globin (B. globin) and HPRT1 were simultaneously measured in a PCR cavity using two specific hydrolysis probes (duplex qPCR). Both positive (A, C, E) and negative (B, D, F) amplification curves were used. The amplification curves are normalized to the 99% quantile. Not the differences in slopes and intercepts (blue and orange lines and dots). The <code><a href="../reference/mblrr.html">mblrr()</a></code> function is presumably useful for data sets which are accompanied by noise and artifacts.
</p>
</div>
<p>Finally, the results of the analysis were printed in a tabular format.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the xtable library for an appealing table output</span>
<span class="kw">library</span>(xtable)

<span class="co"># Analyze the data via the mblrr() function</span>

res_mblrr &lt;-<span class="st"> </span><span class="kw">do.call</span>(cbind, <span class="kw">lapply</span>(2L<span class="op">:</span><span class="kw">ncol</span>(data), <span class="cf">function</span>(i) {
  <span class="kw">suppressMessages</span>(<span class="kw"><a href="../reference/mblrr.html">mblrr</a></span>(
    <span class="dt">x =</span> data[, <span class="dv">1</span>], <span class="dt">y =</span> data[, i],
    <span class="dt">normalize =</span> <span class="ot">TRUE</span>
  )) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">data.frame</span>()
}))
<span class="kw">colnames</span>(res_mblrr) &lt;-<span class="st"> </span><span class="kw">colnames</span>(data)[<span class="op">-</span><span class="dv">1</span>]

<span class="co"># Transform the data for a tabular output and assign the results to the object</span>
<span class="co"># output_res_mblrr.</span>

output_res_mblrr &lt;-<span class="st"> </span>res_mblrr <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">t</span>()

<span class="co"># The output variable names of the mblrr() function are rather long. For better</span>
<span class="co"># readability the variable names were changed to "nBG" (intercept of the head </span>
<span class="co"># region), "mBG" (slope of the head region), "rBG" (Pearson correlation of head </span>
<span class="co"># region), "nTP" (intercept of the tail region), "mTP" (slope of tail region), </span>
<span class="co"># "rBG" (Pearson correlation of the tail region)</span>

<span class="kw">colnames</span>(output_res_mblrr) &lt;-<span class="st"> </span><span class="kw">c</span>(
  <span class="st">"nBG"</span>, <span class="st">"mBG"</span>, <span class="st">"rBG"</span>,
  <span class="st">"nTP"</span>, <span class="st">"mTP"</span>, <span class="st">"rTP"</span>
)

<span class="kw">print</span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/xtable/topics/xtable">xtable</a></span>(
  output_res_mblrr, <span class="dt">caption =</span> <span class="st">"mblrr() text intro. nBG, intercept of </span>
<span class="st">             head region; mBG, slope of head region; rBG, Pearson </span>
<span class="st">             correlation of head region; nTP, intercept of tail region; mTP, </span>
<span class="st">             slope of tail region; rBG, Pearson correlation of tail region"</span>,
  <span class="dt">label =</span> <span class="st">"tablemblrrintroduction"</span>
), <span class="dt">comment =</span> <span class="ot">FALSE</span>, <span class="dt">caption.placement =</span> <span class="st">"top"</span>)</code></pre></div>

<p>In another example, the results from the <code><a href="../reference/mblrr.html">mblrr()</a></code> function were combined with the classifications (positive, negative) by a human to apply them in an analysis with Fast and Frugal Trees (FFTrees). FFTrees belong to class of simple decision rules. DT’s are a classic approach to machine learning <span class="citation">(Quinlan 1986)</span>. Here relatively simple algorithms and simple tree structures are used to create a model. A general introduction to decision trees is given in <span class="citation">(Quinlan 1986, <span class="citation">Luan, Schooler, and Gigerenzer (2011)</span>)</span>. In many situations, FFTrees make fast decisions based on a few predictors (N = 1 - 5). In this example six predictors were used for the analysis.</p>
<p>The  package <span class="citation">(Phillips et al. 2017)</span> provides an implementation for the  statistical computing language. All that is needed for the present example are:</p>
<ul>
<li>the data assessed by the <code><a href="../reference/mblrr.html">mblrr()</a></code> function,</li>
<li>the classification of the amplification curve data by a human,</li>
<li>and a standard formula, which looks like <span class="math inline">\(outcome \leftarrow var1 + var2 + \ldots\)</span> along with the data arguments. The function <code><a href="http://www.rdocumentation.org/packages/FFTrees/topics/FFTrees">FFTrees()</a></code> returns a fast and frugal tree object. This rich object contains the underlying trees and many classification statistics (similar to ). In the following example, the <code>RAS002</code> data set was used.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the xtable library for an appealing table output</span>
<span class="kw">library</span>(FFTrees)
<span class="kw">library</span>(PCRedux)

<span class="co"># The RAS002 amplification curves were analyzed with the mblrr() function </span>
<span class="co"># to save computing time and the.results of this analysis are stored in the </span>
<span class="co"># `data_sample` data set.</span>

data &lt;-<span class="st"> </span>data_sample[data_sample<span class="op">$</span>dataset <span class="op">==</span><span class="st"> "RAS002"</span>, <span class="kw">c</span>(<span class="st">"mblrr_intercept_bg"</span>, 
                                                       <span class="st">"mblrr_slope_bg"</span>, 
                                                       <span class="st">"mblrr_cor_bg"</span>, 
                                                       <span class="st">"mblrr_intercept_pt"</span>, 
                                                       <span class="st">"mblrr_slope_pt"</span>, 
                                                       <span class="st">"mblrr_cor_pt"</span>)]

<span class="co"># The output variable names of the mblrr() function are rather long. For better</span>
<span class="co"># readability the variable names were changed to "nBG" (intercept of head</span>
<span class="co"># region), "mBG" (slope of head region), "rBG" (Pearson correlation of head</span>
<span class="co"># region), "nTP" (intercept of tail region), "mTP" (slope of tail region),</span>
<span class="co"># "rBG" (Pearson correlation of tail region).</span>


res_mblrr &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
    <span class="dt">class =</span> <span class="kw">as.numeric</span>(<span class="kw">as.character</span>(<span class="kw">factor</span>(RAS002_decisions, 
                                           <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">"y"</span>, <span class="st">"n"</span>), 
                                           <span class="dt">label =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>)))),
  data
)

<span class="kw">colnames</span>(res_mblrr) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">"class"</span>, <span class="st">"nBG"</span>, <span class="st">"mBG"</span>, <span class="st">"rBG"</span>, <span class="st">"nTP"</span>, <span class="st">"mTP"</span>, <span class="st">"rTP"</span>)

res_mblrr.fft &lt;-<span class="st"> </span><span class="kw">suppressMessages</span>(
            <span class="kw"><a href="http://www.rdocumentation.org/packages/FFTrees/topics/FFTrees">FFTrees</a></span>(<span class="dt">formula =</span> class <span class="op">~</span>., <span class="dt">data =</span> res_mblrr)
            )</code></pre></div>
<p> shows the Fast and Frugal Trees by using the predictors nBG (intercept of head region), mBG (slope of head region), rBG (Pearson correlation of head region), nTP (intercept of tail region), mTP (slope of tail region), and rBG (Pearson correlation of tail region).</p>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_FFTrees-1.png" alt="Visualization of decisions in  Fast and Frugal Trees after data analysis of amplification curves via the ``mblrr()`` function. \textbf{Top row} `Data`) Overview of the data set, with displaying the total number of observations (N = 192) and percentage of positive (22\%) and negative (78\%) amplification curves. \textbf{Middle row} `FFT \#1 (of 6)`) Decision Tree with the number of observations classified at each level of the tree. For the analysis, six predictors (nBG, intercept of head region; mBG, slope of head region; rBG, Pearson correlation of head region; nTP, intercept of tail region; mTP, slope of tail region; rBG, Pearson correlation of tail region) have been used for the analysis. After two tree levels (nBG, nTP) already the decision tree is created. All positive amplification curves (N = 40) are correctly classified. Two observations are classified as false-negative in the negative amplification curves. \textbf{Lower row} `Performance`)  The ``FFTrees()`` function determines several performance statistics. For the training data, there is a classification table on the left side showing the relationship between tree `decision` and the `truth`. The correct rejection (`Cor Rej`) and `Hit` are the right decisions. `Miss` and false alarm (`False Al`) are wrong decisions. The centre shows the cumulative tree performance in terms of mean of used cues (`mcu`), Percent of ignored cues (`pci`), sensitivity (`sens`), specificity (`spec`), accuracy (`acc`) and weighted Accuracy (`wacc`). The receiver operating characteristic (ROC) curve on the right-hand side compares the performance of all trees in the FFTrees object. The system also displays the performance of the fast frugal trees (`\#`, green), CART (`C`, red), logistical regression (`L`, blue), random forest (`R`, violet) and the support vector machine (`S`, yellow)." width="1056"><p class="caption">
Visualization of decisions in Fast and Frugal Trees after data analysis of amplification curves via the <code><a href="../reference/mblrr.html">mblrr()</a></code> function.  <code>Data</code>) Overview of the data set, with displaying the total number of observations (N = 192) and percentage of positive (22%) and negative (78%) amplification curves.  <code>FFT \#1 (of 6)</code>) Decision Tree with the number of observations classified at each level of the tree. For the analysis, six predictors (nBG, intercept of head region; mBG, slope of head region; rBG, Pearson correlation of head region; nTP, intercept of tail region; mTP, slope of tail region; rBG, Pearson correlation of tail region) have been used for the analysis. After two tree levels (nBG, nTP) already the decision tree is created. All positive amplification curves (N = 40) are correctly classified. Two observations are classified as false-negative in the negative amplification curves.  <code>Performance</code>) The <code><a href="http://www.rdocumentation.org/packages/FFTrees/topics/FFTrees">FFTrees()</a></code> function determines several performance statistics. For the training data, there is a classification table on the left side showing the relationship between tree <code>decision</code> and the <code>truth</code>. The correct rejection (<code>Cor Rej</code>) and <code>Hit</code> are the right decisions. <code>Miss</code> and false alarm (<code>False Al</code>) are wrong decisions. The centre shows the cumulative tree performance in terms of mean of used cues (<code>mcu</code>), Percent of ignored cues (<code>pci</code>), sensitivity (<code>sens</code>), specificity (<code>spec</code>), accuracy (<code>acc</code>) and weighted Accuracy (<code>wacc</code>). The receiver operating characteristic (ROC) curve on the right-hand side compares the performance of all trees in the FFTrees object. The system also displays the performance of the fast frugal trees (<code>\#</code>, green), CART (<code>C</code>, red), logistical regression (<code>L</code>, blue), random forest (<code>R</code>, violet) and the support vector machine (<code>S</code>, yellow).
</p>
</div>
<p> offers several packages like  <span class="citation">(Hothorn, Hornik, and Zeileis 2006)</span>,  <span class="citation">(Therneau, Atkinson, and Ripley 2017)</span> and  <span class="citation">(Williams 2009)</span> for creating decision trees.</p>
</div>
<div id="autocorrelation_test---a-function-to-detect-positive-amplification-curves" class="section level4">
<h4 class="hasAnchor">
<a href="#autocorrelation_test---a-function-to-detect-positive-amplification-curves" class="anchor"></a><code><a href="../reference/autocorrelation_test.html">autocorrelation_test()</a></code> - A Function to Detect Positive Amplification Curves </h4>
<p>Autocorrelation analysis is a technique that is used in the field of time series analysis. It can be used to reveal regularly occurring patterns in one-dimensional data <span class="citation">(Spiess et al. 2016)</span>. The autocorrelation measures the correlation of a signal <span class="math inline">\(f(t)\)</span> with itself shifted by some time delay <span class="math inline">\(f(t - \tau)\)</span>.</p>
<p>The <code><a href="../reference/autocorrelation_test.html">autocorrelation_test()</a></code> function coercers the amplification curve data to an object of the class “zoo” ( package) as indexed totally ordered observations. Next follows the computation of a lagged version of the amplification curve data. The shifting of the amplification curve data is based on the number of observations (number of cycles ‘c’) with the following <span class="math inline">\(\tau\)</span>.</p>
<table class="table">
<thead><tr class="header">
<th>Number of Cycles (c)</th>
<th><span class="math inline">\(\tau\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(c \leq 35\)</span></td>
<td>8</td>
</tr>
<tr class="even">
<td><span class="math inline">\(35 &gt; c \leq 40\)</span></td>
<td>10</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(40 &lt; c \leq 45\)</span></td>
<td>12</td>
</tr>
<tr class="even">
<td><span class="math inline">\(c &gt; 45\)</span></td>
<td>14</td>
</tr>
</tbody>
</table>
<p>This is followed by a significance test for correlation between paired observations (amplification curve data &amp; lagged amplification curve data). The hypothesis is that the paired observation of positive amplification curves has a significant correlation (<code><a href="http://www.rdocumentation.org/packages/stats/topics/cor.test">stats::cor.test</a></code>, significance level is 0.01) in contrast to negative amplification curves (noise). The application of the <code><a href="../reference/autocorrelation_test.html">autocorrelation_test()</a></code> function is shown in the following example.</p>
<p>In addition, the decisions file <code>decision_res_RAS002.csv</code> from the user was analyzed for the most frequent decision (modus) using the <code><a href="../reference/decision_modus.html">decision_modus()</a></code> function ().</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Test for autocorrelation in amplification curve data. The amplification </span>
<span class="co"># curve data from the `htPCR` data set was used. The data.table package was </span>
<span class="co"># used for fast import of the csv data.</span>
<span class="kw">library</span>(PCRedux)

<span class="co"># Load the decision_res_htPCR.csv data set from a csv file.</span>
filename &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">"decision_res_htPCR.csv"</span>, <span class="dt">package =</span> <span class="st">"PCRedux"</span>)
decision_res_htPCR &lt;-<span class="st"> </span>data.table<span class="op">::</span><span class="kw">fread</span>(filename, <span class="dt">data.table =</span> <span class="ot">FALSE</span>)

<span class="co"># Select only amplification curves (obs) were all </span>
<span class="co"># classifications were in concordance ("conformity == TRUE" ).</span>
<span class="co"># This subset of the htPCR data set contains the classes </span>
<span class="co"># n: negative</span>
<span class="co"># a: ambiguous</span>
<span class="co"># p: positive</span>

obs_number &lt;-<span class="st"> </span><span class="kw">which</span>(decision_res_htPCR[[<span class="st">"conformity"</span>]] <span class="op">==</span><span class="st"> </span><span class="ot">TRUE</span>)
dec &lt;-<span class="st"> </span>decision_res_htPCR[obs_number, <span class="st">"test.result.1"</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>(.)

<span class="co"># Give tabular output of classes</span>
<span class="kw">table</span>(dec)</code></pre></div>
<pre><code>## dec
##   a   n   y 
##   2 202 280</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Since the number of ambiguous is low (n = 2), they were re-assigned to the </span>
<span class="co"># class negative</span>

dec[dec <span class="op">==</span><span class="st"> "a"</span>] &lt;-<span class="st"> "n"</span>

<span class="kw">table</span>(dec)</code></pre></div>
<pre><code>## dec
##   n   y 
## 204 280</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load only the amplification curves from the htPCR data set that were </span>
<span class="co"># uniquely assigned to one class (e.g., eight out of eight positive).</span>

data &lt;-<span class="st"> </span>qpcR<span class="op">::</span>htPCR[, <span class="kw">c</span>(<span class="dv">1</span>, obs_number <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)]

<span class="co"># Assign colors to the classes (n: black, y: green).</span>

colors &lt;-<span class="st"> </span><span class="kw">factor</span>(dec, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">"y"</span>, <span class="st">"n"</span>), <span class="dt">label =</span> <span class="kw">c</span>(<span class="st">"black"</span>, <span class="st">"green"</span>))


<span class="co"># Test for autocorrelation in the subset of the htPCR data set</span>

res_ac &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">2</span><span class="op">:</span><span class="kw">ncol</span>(data), <span class="cf">function</span>(i) {
    <span class="kw"><a href="../reference/autocorrelation_test.html">autocorrelation_test</a></span>(data[, i], <span class="dt">ns_2_numeric =</span> <span class="ot">TRUE</span>)
})


<span class="co"># Plot curve data as overview</span>
<span class="co"># Names of the observations</span>
<span class="co"># Create graphic device for the plot(s)</span>

<span class="kw">layout</span>(<span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">4</span>), <span class="dv">2</span>, <span class="dv">3</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>))
<span class="kw">matplot</span>(
    data[, <span class="dv">1</span>], data[, <span class="op">-</span><span class="dv">1</span>], <span class="dt">xlab =</span> <span class="st">"Cycles"</span>, <span class="dt">ylab =</span> <span class="st">"RFU"</span>,
    <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">type =</span> <span class="st">"l"</span>, <span class="dt">lty =</span> <span class="dv">1</span>,
    <span class="dt">col =</span> colors, <span class="dt">lwd =</span> <span class="dv">2</span>
)
<span class="kw">legend</span>(<span class="st">"topleft"</span>, <span class="kw">c</span>(<span class="st">"positive"</span>, <span class="st">"negative"</span>), <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">col =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="dt">bty =</span> <span class="st">"n"</span>)
<span class="kw">mtext</span>(<span class="st">"A    RAS002 data set"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)


<span class="co"># Convert the n.s. (not significant) in 0 and others to 1.</span>
<span class="co"># Combine the results of the aromatic autocorrelation_test as variable "ac",</span>
<span class="co"># the human classified values as variable "hc" in a new data frame (res_ac_hc).</span>

cutoff &lt;-<span class="st"> </span><span class="fl">0.85</span>

res_ac_hc &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
    <span class="dt">ac =</span> <span class="kw">ifelse</span>(res_ac <span class="op">&gt;</span><span class="st"> </span>cutoff, <span class="dv">1</span>, <span class="dv">0</span>),
                        <span class="dt">hc =</span> <span class="kw">ifelse</span>(dec <span class="op">==</span><span class="st"> "y"</span>, <span class="dv">0</span>, <span class="dv">1</span>)
) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/as.matrix">as.matrix</a></span>()
res_performeR &lt;-<span class="st"> </span><span class="kw"><a href="../reference/performeR.html">performeR</a></span>(<span class="dt">s =</span> res_ac_hc[, <span class="st">"ac"</span>], <span class="dt">r =</span> res_ac_hc[, <span class="st">"hc"</span>])


<span class="kw">plot</span>(<span class="kw">density</span>(res_ac), <span class="dt">xlab =</span> <span class="st">"Autocorrelation"</span>, <span class="dt">ylab =</span> <span class="st">"Density"</span>, <span class="dt">main =</span> <span class="st">""</span>)
<span class="kw">rug</span>(res_ac)

<span class="kw">abline</span>(<span class="dt">v =</span> cutoff)
<span class="kw">mtext</span>(<span class="st">"B"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, <span class="dt">las =</span> <span class="dv">0</span>)


<span class="kw">cdplot</span>(
    <span class="kw">as.factor</span>(dec) <span class="op">~</span><span class="st"> </span>res_ac, <span class="dt">xlab =</span> <span class="st">"Autocorrelation"</span>,
       <span class="dt">ylab =</span> <span class="st">"Class decision"</span>
)
<span class="kw">mtext</span>(<span class="st">"C"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, <span class="dt">las =</span> <span class="dv">0</span>)

<span class="kw">barplot</span>(
    <span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/as.matrix">as.matrix</a></span>(res_performeR[, <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dv">12</span>)]), <span class="dt">yaxt =</span> <span class="st">"n"</span>, <span class="dt">ylab =</span> <span class="st">""</span>,
        <span class="dt">main =</span> <span class="st">"Performance of autocorrelation_test"</span>,
        <span class="dt">col =</span> <span class="kw">adjustcolor</span>(<span class="st">"grey"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.5</span>), <span class="dt">border =</span> <span class="st">"white"</span>
)
<span class="kw">text</span>(position_bp, <span class="kw">rep</span>(<span class="fl">0.8</span>, <span class="kw">length</span>(res_performeR[, <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dv">12</span>)])), 
     <span class="kw">paste</span>(<span class="kw">signif</span>(res_performeR[, <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dv">12</span>)], <span class="dv">2</span>)<span class="op">*</span><span class="dv">100</span>, <span class="st">"%"</span>))
<span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">"0"</span>, <span class="st">"1"</span>), <span class="dt">las =</span> <span class="dv">2</span>)
<span class="kw">mtext</span>(<span class="st">"D"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, <span class="dt">las =</span> <span class="dv">0</span>)</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/autocorrelation-1.png" alt="Autocorrelation analysis of the amplification curves of the `RAS002` data set. A) Display of all amplification curves of the data set `RAS002`. Negative amplification curves are shown in red and positive amplification curves in black. The `autocorrelation\_test()` function was used to analyze all amplification curves. B) The density diagram of the autocorrelation of positive and negative amplification curves shows a bimodal distribution. C) The cdplot calculates the conditional densities of x based on the values of y weighted by the boundary distribution of y. The densities are derived cumulatively via the values of y. The probability that the decision is negative (n) when autocorrelation equals 0.85 is approximately 100\%. D) Performance analysis using the ``performeR()`` function (see \autoref{section_performeR} for details)." width="1056"><p class="caption">
Autocorrelation analysis of the amplification curves of the <code>RAS002</code> data set. A) Display of all amplification curves of the data set <code>RAS002</code>. Negative amplification curves are shown in red and positive amplification curves in black. The <code>autocorrelation\_test()</code> function was used to analyze all amplification curves. B) The density diagram of the autocorrelation of positive and negative amplification curves shows a bimodal distribution. C) The cdplot calculates the conditional densities of x based on the values of y weighted by the boundary distribution of y. The densities are derived cumulatively via the values of y. The probability that the decision is negative (n) when autocorrelation equals 0.85 is approximately 100%. D) Performance analysis using the <code><a href="../reference/performeR.html">performeR()</a></code> function (see  for details).
</p>
</div>
<p>As shown in this example, the <code><a href="../reference/autocorrelation_test.html">autocorrelation_test()</a></code> function is able to distinguish between positive and negative amplification curves. Negative amplification curve were in all cases non-significant. In contrast, the coefficients of correlation for positive amplification curves ranged between 0.766 and 0.999 at a significance level of 0.01 and a lag of 3.</p>

<div class="figure">
<img src="PCRedux_files/figure-html/plot_cp_area-1.png" alt="Values of predictors calculated from negative and positive amplification curves. Amplification curves predictors from the `data\_sample\_subset` data set were used since they contain positive and negative amplification curves and amplification curves that exhibit a hook effect or non-sigmoid shapes, for instance. A) `polyarea`, is the area under the amplification curve determined by the Gauss polygon area formula. B) `peaks\_ratio`, is the ratio of the local minima and the local maxima. C) `cp\_e.agglo`, makes use of energy agglomerative clustering. Positive amplification curves have fewer change points than negative amplification curves. These two change point analyses generally separate positive and negative amplification curves. D) `cp\_bcp`, analyses change points by a Bayesian approach. Positive amplification curves appear to contain more change points than negative amplification curves. Nevertheless, there is an overlap between the positive and negative amplification curves in both methods. This can lead to false-positive or false-negative classifications. E) `amptester\_polygon`, is the cycle normalized order of a polygon.  F) `amptester\_slope.ratio`, is the slope (linear model) of the raw fluorescence values at the approximate first derivate maximum, second derivative minimum and second derivative maximum." width="700"><p class="caption">
Values of predictors calculated from negative and positive amplification curves. Amplification curves predictors from the <code>data\_sample\_subset</code> data set were used since they contain positive and negative amplification curves and amplification curves that exhibit a hook effect or non-sigmoid shapes, for instance. A) <code>polyarea</code>, is the area under the amplification curve determined by the Gauss polygon area formula. B) <code>peaks\_ratio</code>, is the ratio of the local minima and the local maxima. C) <code>cp\_e.agglo</code>, makes use of energy agglomerative clustering. Positive amplification curves have fewer change points than negative amplification curves. These two change point analyses generally separate positive and negative amplification curves. D) <code>cp\_bcp</code>, analyses change points by a Bayesian approach. Positive amplification curves appear to contain more change points than negative amplification curves. Nevertheless, there is an overlap between the positive and negative amplification curves in both methods. This can lead to false-positive or false-negative classifications. E) <code>amptester\_polygon</code>, is the cycle normalized order of a polygon. F) <code>amptester\_slope.ratio</code>, is the slope (linear model) of the raw fluorescence values at the approximate first derivate maximum, second derivative minimum and second derivative maximum.
</p>
</div>
</div>
<div id="change-point-analysis" class="section level4">
<h4 class="hasAnchor">
<a href="#change-point-analysis" class="anchor"></a>Change point analysis</h4>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_cpa-1.png" alt="Bayesian and energy agglomerative change point analysis on negative and positive amplification curves. An analysis of a negative and a positive amplification curve from the `RAS002` data set was performed using the ``pcrfit\_single()`` function. In this process, the amplification curves were analysed for change points using Bayesian change point analysis and energy agglomerative clustering. A) The negative amplification curve has a base signal of circa 2450 RFU and only a small signal increase to 2650 RFU. There is a clear indication of the signal variation (noise). B) The first negative derivative amplifies the noise so that some peaks are visible. C) The change point analysis shows changes in energy agglomerative clustering at several positions (green vertical line). The Bayesian change point analysis rarely exceeds a probability of 0.6 (grey vert line). D) The positive amplification curve has a lower base signal ($\sim 2450$ RFU) and increases up to the 40th cycle ($\sim 3400$ RFU). A sigmoid shape of the curve is visible. E) The first negative derivation of the positive amplification curve shows a distinctive peak with a minimum at cycle 25. F) The change point analysis in energy agglomerative clustering shows changes (green vertical line) only at two positions. The Bayesian change point analysis shows a probability higher than 0.6 (grey horizontal line) at several positions." width="700"><p class="caption">
Bayesian and energy agglomerative change point analysis on negative and positive amplification curves. An analysis of a negative and a positive amplification curve from the <code>RAS002</code> data set was performed using the <code>pcrfit\_single()</code> function. In this process, the amplification curves were analysed for change points using Bayesian change point analysis and energy agglomerative clustering. A) The negative amplification curve has a base signal of circa 2450 RFU and only a small signal increase to 2650 RFU. There is a clear indication of the signal variation (noise). B) The first negative derivative amplifies the noise so that some peaks are visible. C) The change point analysis shows changes in energy agglomerative clustering at several positions (green vertical line). The Bayesian change point analysis rarely exceeds a probability of 0.6 (grey vert line). D) The positive amplification curve has a lower base signal (<span class="math inline">\(\sim 2450\)</span> RFU) and increases up to the 40th cycle (<span class="math inline">\(\sim 3400\)</span> RFU). A sigmoid shape of the curve is visible. E) The first negative derivation of the positive amplification curve shows a distinctive peak with a minimum at cycle 25. F) The change point analysis in energy agglomerative clustering shows changes (green vertical line) only at two positions. The Bayesian change point analysis shows a probability higher than 0.6 (grey horizontal line) at several positions.
</p>
</div>
<p>Change point analysis (CPA) encompasses methods to identify or estimate single or multiple locations of distributional changes in a series of data points indexed in time order. A change herein refers to a statistical property. CPA is used for example in econometrics and bioinformatics <span class="citation">(Killick and Eckley 2014, <span class="citation">Erdman, Emerson, and others (2007)</span>)</span>. There exist several change point algorithms such as the binary segmentation algorithm <span class="citation">(A. J. Scott and Knott 1974)</span>. In the change point analysis one assumes independent ordered observations <span class="math inline">\(x_{1}, x_{2}, \ldots, x_{n} \in \mathbb{R}^{\textit{d}}\)</span> <span class="citation">(N. A. James and Matteson 2013)</span>. The case of qPCR this is simply the cycle-dependent fluorescence. This is used to create <span class="math inline">\(k\)</span> homogeneous subsets of unknown size <span class="citation">(Erdman, Emerson, and others 2007)</span>. While frequentist methods make an estimation of the parameter at the location (e. g., mean, variance) of the change points at specific points, change point analysis using the Bayesian method produces a probability for the occurrence of a change point at certain points. For the analysis of the amplification curves it was hypothesized that the number of change points differs between positive (sigmoidal) and negative (noise) amplification curves.</p>
<p>The <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function uses two independent approaches for change point analysis. These are the <code>bcp()</code> [] function <span class="citation">(Erdman, Emerson, and others 2007)</span> and the <code>e.agglo()</code> [] function <span class="citation">(N. A. James and Matteson 2013)</span>. The <code>e.agglo()</code> function performs a non-parametric change point analysis based on agglomerative hierarchical estimation and is useful to “detect changes within the marginal distributions” <span class="citation">(N. A. James and Matteson 2013)</span>. Measurement from the qPCR systems typically shows noise that typically has rapidly changing components. Differentiators amplify these rapidly changing noise components <span class="citation">(Rödiger, Böhm, and Schimke 2013)</span>. Therefore, the first derivation of the amplification curve was used for both change point analyses. It was assumed for the change point analysis of amplification curves that this leads to larger differences between positive and negative amplification curves. An example is shown on . In contrast the <code>bcp()</code> [] function performs a change point analysis based on a Bayesian approach. This method can detect changes in the mean of independent Gaussian observations. As result the analysis returns the posterior probability of a change point at each <span class="math inline">\(x_{i}\)</span>. An example is shown on . Both the change point analysis methods provide additional information to distinguish positive and negative amplification curves E &amp; F).</p>
</div>
<div id="frequentist-approaches-to-test-the-class-of-an-amplification-reaction" class="section level4">
<h4 class="hasAnchor">
<a href="#frequentist-approaches-to-test-the-class-of-an-amplification-reaction" class="anchor"></a>Frequentist Approaches to Test the Class of an Amplification Reaction</h4>
<p>A part of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/amptester">amptester()</a></code> [] function, which contains tests to determine whether an amplification curve is positive or negative. The input values for the function differ due to the different pre-processing steps in the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function. Therefore, the concepts of the tests are briefly described below.</p>
<ul>
<li>The first test, designated as SHt, is based on this Shapiro-Wilk test of normality. This relatively simple procedure can be used to check whether the underlying population of a sample (amplification curve) is significantly (<span class="math inline">\(\alpha \leq 5e-04\)</span>) normal distributed. The name of the output of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is <code>amptester_shapiro</code>.</li>
<li>The second test is the <em>Resids growth test</em> (RGt), which tests if the fluorescence values in linear phase are stable. Whenever no amplification occurs, fluorescence values quickly deviate from linear model. Their standardized residuals will be strongly correlated with their value. For real amplification curves, situation is much more stable. Noise (that means deviations from linear model) in background do not correlate strongly with the changes in fluorescence. The decision is based on the threshold value (here 0.5). The output is binary coded (negative = 0, positive = 1). The output name of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is <code>amptester_rgt</code>.</li>
<li>The third test is the <em>Linear Regression test</em> (LRt). This test determines the coefficient of determination (<span class="math inline">\(R^{2}\)</span>) by an ordinary least squares linear (OLS) regression. The <span class="math inline">\(R^{2}\)</span> are determined from a run of circa 15% range of the data. If a sequence of more than six <span class="math inline">\(R^{2}\)</span>s is larger than 0.8 is found that is likely a nonlinear signal. This is a bit counterintuitive because <span class="math inline">\(R^{2}\)</span> of nonlinear data should be low. The output is binary coded (negative = 0, positive = 1). The output name of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is <code>amptester_lrt</code>.</li>
<li>The fourth test is called <em>Threshold test</em> (THt), which is based on the Wilcoxon rank sum test. As a simple rule the first 20% (head) and the last 15% (tail) of an amplification curve are used as input data. From that a one-sided Wilcoxon rank sum tests of the head versus the tail is performed (<span class="math inline">\(\alpha \leq 1e-02\)</span>). The output is binary coded (negative = 0, positive = 1). The output name of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is <code>amptester_tht</code>.</li>
<li>The fifth test is called <em>Signal level test</em> (SLt). he test compares the signals of the head and the tail by a robust “sigma” rule (median + 2 * MAD) and the comparison of the head/tail ratio. If the returned value is less than 1.25 (25 percent), then the amplification curve is likely negative.The output is binary coded (negative = 0, positive = 1). The output name of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is <code>amptester_slt</code>.</li>
<li>The sixth test is called <em>Polygon test</em> (pco). The pco test determines if the points in an amplification curve (like a polygon) are in a “clockwise” order. The sum over the edges result in a positive value if the amplification curve is “clockwise” and is negative if the curve is counter-clockwise. From experience is noise positive and “true” amplification curves “highly” negative. In contrast to the implementation in the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/amptester">amptester()</a></code> function, the result is normalized by a division to the number of PCR cycles. The output is numeric. The output name of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is <code>amptester_polygon</code>.</li>
<li>The seventh test is the <em>Slope Ratio test</em> (SlR). This test uses the approximated first derivative maximum, the second derivative minimum and the second derivative maximum of the amplification curve. Next the raw fluorescence at the approximated second derivative minimum and the second derivative maximum are taken from the original data set. The fluorescence intensities are normalized to the maximum fluorescence of this data. This data is used for a linear regression. Where the slope is used. The output is numeric. The output name of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is <code>amptester_slope.ratio</code>.</li>
</ul>
</div>
<div id="application-of-the-amptester-predictors" class="section level4">
<h4 class="hasAnchor">
<a href="#application-of-the-amptester-predictors" class="anchor"></a>Application of the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/amptester">amptester()</a></code> Predictors</h4>
<p>Random Forest is an enhancement of decision tree algorithms. Random Forest uses <em>n</em> random data subsets. The subset is to be used to capture trends precisely without taking into account the whole data. To do this, an ensemble consisting of <em>n</em> small decision trees is generated. Each decision tree contains a biased classifier. Most of the classes are then selected for classification. Compared to a single tree classifier, the Random Forest has a high robustness against noise, outliers and over-fitting <span class="citation">(Williams 2009, <span class="citation">Breiman (2001)</span>)</span>.</p>
<p>In the following example, the <code><a href="http://www.rdocumentation.org/packages/randomForest/topics/randomForest">randomForest()</a></code> [] function <span class="citation">(Liaw and Wiener 2002)</span> was used for the classification. With classification problems we try to predict a discrete number of values. Thus in this case it is a binary classification. The aim of this <strong>proof-pf-concept</strong> <em>in silico</em> experiment was to find the most important predictors for the classification of positive and negative amplification curves. As response vector (<span class="math inline">\(y\)</span>) served <code>decision</code> with its possible finite classes labeled as “positive” and “negative”. The response vector <code>decision</code> must be a vector.</p>
<ul>
<li>
<code>amptester_shapiro</code>,</li>
<li>
<code>amptester_lrt</code>,</li>
<li>
<code>amptester_rgt</code>,</li>
<li>
<code>amptester_tht</code>,</li>
<li>
<code>amptester_slt</code>,</li>
<li>
<code>amptester_polygon</code> and</li>
<li>
<code>amptester_slope.ratio</code> served as a matrix of predictors describing the model to be adapted. The <code>data_sample_subset_balanced</code> data set () was used for the analysis to save computing time. The <code>data_sample_subset_balanced</code> data set contains similar proportions of observations (positive and negative amplification curves.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(randomForest)
<span class="kw">library</span>(PCRedux)
<span class="kw">set.seed</span>(<span class="dv">1999</span>) 

<span class="co"># Dimensions of the data_sample_subset_balanced object</span>
<span class="kw">dim</span>(data_sample_subset_balanced)</code></pre></div>
<pre><code>## [1] 651  54</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Show proportions of positive and negative amplification curves in</span>
<span class="co"># data_sample_subset_balanced</span>

<span class="kw">table</span>(data_sample_subset_balanced[[<span class="st">"decision"</span>]])</code></pre></div>
<pre><code>## 
##   y   n 
## 322 329</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/as.matrix">as.matrix</a></span>(<span class="kw">cbind</span>(data_sample_subset_balanced[, <span class="kw">c</span>(<span class="st">"amptester_shapiro"</span>, 
                           <span class="st">"amptester_lrt"</span>, 
                           <span class="st">"amptester_rgt"</span>, 
                           <span class="st">"amptester_tht"</span>, 
                           <span class="st">"amptester_slt"</span>,
                           <span class="st">"amptester_polygon"</span>, 
                           <span class="st">"amptester_slope.ratio"</span>)],
                  <span class="dt">decision =</span> <span class="kw">as.numeric</span>(
                      <span class="kw">factor</span>(data_sample_subset_balanced<span class="op">$</span>decision, 
                                         <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">"n"</span>, <span class="st">"y"</span>), 
                                         <span class="dt">label =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)
                 )


<span class="co"># Summary of data</span>

<span class="kw">summary</span>(data)</code></pre></div>
<pre><code>##  amptester_shapiro amptester_lrt    amptester_rgt    amptester_tht   
##  Min.   :0.0000    Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:0.0000    1st Qu.:1.0000   1st Qu.:1.0000   1st Qu.:1.0000  
##  Median :0.0000    Median :1.0000   Median :1.0000   Median :1.0000  
##  Mean   :0.4117    Mean   :0.9785   Mean   :0.9462   Mean   :0.9708  
##  3rd Qu.:1.0000    3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  
##  Max.   :1.0000    Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  
##  amptester_slt    amptester_polygon amptester_slope.ratio    decision     
##  Min.   :0.0000   Min.   :0.0000    Min.   :-0.96073      Min.   :0.0000  
##  1st Qu.:0.0000   1st Qu.:0.0000    1st Qu.: 0.00000      1st Qu.:0.0000  
##  Median :1.0000   Median :0.6099    Median : 0.00000      Median :0.0000  
##  Mean   :0.5008   Mean   :0.5935    Mean   : 0.10078      Mean   :0.4946  
##  3rd Qu.:1.0000   3rd Qu.:1.1536    3rd Qu.: 0.05925      3rd Qu.:1.0000  
##  Max.   :1.0000   Max.   :1.6221    Max.   : 0.99916      Max.   :1.0000</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Select randomly 70% of the observations data for training (-&gt; n_train).</span>
<span class="co"># n_train is the number of observations used for training.</span>

<span class="co"># First determine the number of observations that would cover 70% of all data.</span>

n_train &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">nrow</span>(data) <span class="op">*</span><span class="st"> </span><span class="fl">0.7</span>)
<span class="kw">paste0</span>(<span class="st">"Percentage of observations (n = "</span>, n_train, <span class="st">") -&gt; "</span>, 
       <span class="kw">signif</span>((n_train<span class="op">/</span><span class="kw">nrow</span>(data)<span class="op">*</span><span class="dv">100</span>), <span class="dv">3</span>), <span class="st">"%"</span>)</code></pre></div>
<pre><code>## [1] "Percentage of observations (n = 456) -&gt; 70%"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># index_test is the index of observations to be selected for the testing</span>
index_test &lt;-<span class="st"> </span><span class="kw">sample</span>(1L<span class="op">:</span><span class="kw">nrow</span>(data), <span class="dt">size =</span> n_train)

<span class="co"># index_test is the index of observations to be selected for the training</span>
index_training &lt;-<span class="st"> </span><span class="kw">which</span>(<span class="op">!</span>(1L<span class="op">:</span><span class="kw">nrow</span>(data) <span class="op">%in%</span><span class="st"> </span>index_test))


<span class="co"># The randomForest() function was used to train a forest of 200 trees.</span>
<span class="co"># Convert decision into factor, since randomForest() uses type="regression", </span>
<span class="co"># instead of type="classification" by default. Each tree is trained on 63.2 %</span>
<span class="co"># of the training data. Each observation is drawn at random with replacement </span>
<span class="co"># from the original data.</span>
<span class="co"># The predictor variables are drawn at random out of the feature space </span>
<span class="co"># "amptester_shapiro", "amptester_lrt", "amptester_rgt", "amptester_tht", </span>
<span class="co"># "amptester_slt", "amptester_polygon" and "amptester_slope.ratio".</span>

model_rf &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/randomForest/topics/randomForest">randomForest</a></span>(<span class="kw">as.factor</span>(decision) <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> data, 
                         <span class="dt">subset =</span> index_training, 
                         <span class="dt">ntree =</span> <span class="dv">200</span>, <span class="dt">importance =</span> <span class="ot">TRUE</span>)

<span class="co"># The prediction accuracy of the random forest is summarized</span>
model_rf</code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = as.factor(decision) ~ ., data = data,      ntree = 200, importance = TRUE, subset = index_training) 
##                Type of random forest: classification
##                      Number of trees: 200
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 0.51%
## Confusion matrix:
##     0  1 class.error
## 0 103  1 0.009615385
## 1   0 91 0.000000000</code></pre>
<p>The number of variables randomly selected at each split is <em>mtry = </em>2 (as starter the square root of total number of all predictors). The out-of-bag (OOB) error (<span class="math inline">\(=\)</span> misclassification rate) is 0.513%. error rate was. To fine tune a random forest model the number of <em>ntree</em> values must be varied and plotted against the OOB rate. Select mtry value with minimum OOB error. This was not done in the presented example.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Determine variable importance</span>
res_importance &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/randomForest/topics/importance">importance</a></span>(model_rf)

<span class="kw">print</span>(xtable<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/xtable/topics/xtable">xtable</a></span>(res_importance, <span class="dt">caption =</span> <span class="st">"Results of the random fores </span>
<span class="st">classification."</span>,
<span class="dt">label =</span> <span class="st">"randomforstresults"</span>
), <span class="dt">comment =</span> <span class="ot">FALSE</span>, <span class="dt">caption.placement =</span> <span class="st">"top"</span>)</code></pre></div>

<p>The variables <em>MeanDecreaseAccuracy</em> and <em>MeanDecreaseGini</em> are used to determine the importance of the variables for a classification from a <code>Random Forest</code> model. MeanDecreaseAccuracy tells how much removing each variable reduces the accuracy of the model. Mean Decrease Gini tells how important a variable is based on the Gini impurity index used for the calculation of splits in trees. The higher their values are, the more significant they are.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create graphic device for the plot(s)</span>
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))

<span class="co"># Plot the properties if the Random Forest model</span>

<span class="kw">plot</span>(model_rf, <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">las =</span> <span class="dv">2</span>)
<span class="kw">mtext</span>(<span class="st">"A"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, <span class="dt">las =</span> <span class="dv">0</span>)

<span class="kw">rownames</span>(res_importance) &lt;-<span class="st"> </span><span class="kw">substr</span>(<span class="kw">rownames</span>(res_importance), <span class="dv">11</span>, <span class="dv">22</span>)

<span class="co"># Show the predictors sorted by their importance using MeanDecreaseAccuracy</span>
<span class="co"># and MeanDecreaseGini</span>

<span class="kw">barplot</span>(<span class="kw">t</span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/as.matrix">as.matrix</a></span>(<span class="kw">sort</span>(res_importance[, <span class="st">"MeanDecreaseAccuracy"</span>]))), 
        <span class="dt">ylab =</span> <span class="st">"MeanDecreaseAccuracy"</span>, 
        <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">max</span>(res_importance[, <span class="st">"MeanDecreaseAccuracy"</span>]) <span class="op">+</span><span class="st"> </span><span class="dv">5</span>), 
        <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">las =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="kw">adjustcolor</span>(<span class="st">"grey"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.5</span>), 
        <span class="dt">border =</span> <span class="st">"white"</span>)
<span class="kw">mtext</span>(<span class="st">"B"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, <span class="dt">las =</span> <span class="dv">0</span>)

<span class="kw">barplot</span>(<span class="kw">t</span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/as.matrix">as.matrix</a></span>(<span class="kw">sort</span>(res_importance[, <span class="st">"MeanDecreaseGini"</span>]))), 
        <span class="dt">ylab =</span> <span class="st">"MeanDecreaseGini"</span>, 
        <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="kw">max</span>(res_importance[, <span class="st">"MeanDecreaseGini"</span>]) <span class="op">+</span><span class="st"> </span><span class="dv">10</span>), 
        <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">las =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="kw">adjustcolor</span>(<span class="st">"grey"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.5</span>), 
        <span class="dt">border =</span> <span class="st">"white"</span>)
<span class="kw">mtext</span>(<span class="st">"C"</span>, <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, <span class="dt">las =</span> <span class="dv">0</span>)</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_random_forest-1.png" alt=" The predictors `amptester\_lrt` (lrt), `amptester\_rgt` (rgt), `amptester\_tht` (tht), `amptester\_slt` (slt), `amptester\_polygon`(polygon) and `amptester\_slope.ratio` (slope.ratio) were used for classification using random forest. A) This plot shows the error depending on the number of trees. The error decreases as more and more trees are added and averaged. B). Mean Decrease Accuracy shown how much the model accuracy decreases if a variable is dropped. C) Mean Decrease Gini shows the importance of a variable based on the Gini impurity index used for the calculation of splits in trees." width="700"><p class="caption">
The predictors <code>amptester\_lrt</code> (lrt), <code>amptester\_rgt</code> (rgt), <code>amptester\_tht</code> (tht), <code>amptester\_slt</code> (slt), <code>amptester\_polygon</code>(polygon) and <code>amptester\_slope.ratio</code> (slope.ratio) were used for classification using random forest. A) This plot shows the error depending on the number of trees. The error decreases as more and more trees are added and averaged. B). Mean Decrease Accuracy shown how much the model accuracy decreases if a variable is dropped. C) Mean Decrease Gini shows the importance of a variable based on the Gini impurity index used for the calculation of splits in trees.
</p>
</div>
<p>The top two important predictors are <code>polygon</code> (MeanDecreaseAccuracy = 12.82, MeanDecreaseGini = 35.31) and <code>slt</code> (MeanDecreaseAccuracy = 13.54, MeanDecreaseGini = 36.71).</p>
</div>
</div>
</div>
<div id="summary-and-conclusions" class="section level1">
<h1 class="hasAnchor">
<a href="#summary-and-conclusions" class="anchor"></a>Summary and Conclusions </h1>
<p>Positive amplification curves usually have a sigmoid shape of a ground phase, exponential phase, plateau phase. Negative amplification curves resemble a flat noisy signal. As a result, the experienced user is normally able to interpret the shape of the curve well. Outliers and measurement errors can also be easily identified by the user in amplification curves. When setting up a qPCR assay, manual handling is a useful and necessary approach to familiarize oneself with the properties of the qPCR amplification curves.</p>
<p>It is challenging to analyze and classify amplification curves if they deviate significantly from the sigmoid shape or if their number is no longer feasible for manual analysis. The supposed objectivity of the user must also be questioned. In the scientific environment there is often the temptation, or rather the compulsion, to use all data for publications. As a result, amplification curves of rather poor quality are used. In  it was shown that the reproducible and objective analysis of amplification curves is not always given. For a novice user, the quality of an amplification curve can be acceptable, for an experienced user, however, not. In  further reasons were given why statistical methods are necessary for the objective and reproducible interpretation of the amplification curves.</p>
<p>In the past, developers of qPCR software focused mainly on tools and pipelines for calculating quantitative parameters of amplification curves. Examples of qPCR software are  <span class="citation">(Baebler et al. 2017)</span> and  <span class="citation">(Mallona et al. 2017)</span>. With these software, Cq values and amplification efficiencies can be determined. Both parameters are necessary for expression analysis or genotyping<span class="citation">(Pabinger et al. 2014)</span>.</p>
<p>There were few approaches where machine learning was used for the analysis of amplification curves. The intention of <span class="citation">Gunay, Goceri, and Balasubramaniyan (2016)</span> was to improve the determination of Cq values. The authors postulated that they had developed an improved prediction of Cq values using a modified three-parameter model. One assumption of their approach was that their modified three-parameter model could be applied to any amplification curve. However, there are reasons why such an assumption is not valid. In chapters  and  it was described that a considerable proportion of amplification curves deviate clearly from a three-parameter model. Multiparametric models with more than four parameters are more frequently adapted to amplification curves. In addition, the multiparametric models tend to adapt to noise (). Unsurprisingly, a Cq-value is calculated for actually negative amplification curves (). This demonstrates that a three-parameter model alone cannot provide reliable predictions. However, a correct model is important for the extraction of Cq values, for the determination of predictors from the curves and consequently for classification.</p>
<p>Besides the determination of quantification points, the classification of amplification curves is necessary. For example, a diagnostician is interested in whether a sample is positive or negative. In research using high-throughput screening methods, it is important to classify large data sets quickly and cost-effectively. It is important to borne in mind that in manual classification, the classification result is influenced by the subjective perception of the experimenter and that manual analysis is comparatively time-consuming.</p>
<p>An automatic computer-assisted classification of amplification curves is important because it makes the entire analysis process faster, more objective and more reproducible. The objectives were therefore</p>
<ol style="list-style-type: decimal">
<li>create a collection of classified amplification curve data,</li>
<li>propose algorithms that can be used to calculate predictors from amplification curves,</li>
<li>to develop pipelines (e.g., machine learning, decision trees) that can be used for automatic classification of amplification curves and</li>
<li>distribute the results in a public repository as open source software and open data.class</li>
</ol>
<p>For this purpose the  package was developed. This package contains proof-of-concept algorithms and functions with which predictors (mathematically describable properties) of amplification curves can be calculated. The <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is an extensible wrapper function for all algorithms and functions developed.  version 0.2.6.2 offers concepts to calculate 49 predictors from an amplification curve. In addition, predictors such as the used detection chemistry, the qPCR device and further experimental details can be added by the user. Other parameters (e.g. hydrolysis probe, DNA binding dye) can be converted into binary classifiers and used for modeling. Machine learning requires predictors to train a model <span class="citation">(Saeys, Inza, and Larranaga 2007)</span>. The model should then be able to put new unknown data into a meaningful context. The predictors have a significant influence on the accuracy of the prediction model. The predictors of the  package have not yet been described in the literature for the classification of amplification curves. Presumably the collection of predictors in the  package was the most extensive at the time of the first release on  (summer 2017).</p>
<p>It can be assumed that not all predictors are suitable or necessary for machine learning. Some <strong>potential</strong> predictors are more likely to be suitable for validation of data integrity (quality management) and data mining. The <code>maxRFU</code> predictors and <code>sigma_bg</code> () are mentioned here as examples. The predictor <code>maxRFU</code> ought to normally be at a value of 1. If this is not the case, it can be assumed that a pre-processing problem was encountered. The <code>sigma_bg</code> value describes the standard deviation in the ground phase. This should be low (<span class="math inline">\(sigma\_bg \leq 0.1\)</span>). Otherwise it can be assumed that unusually high variations of the intensity values are present in the ground phase. The relevance of the predictors must be determined independently by each user on the basis of domain knowledge, the objective and the given data set.</p>
<p>At this point it should be mentioned that these approaches were deliberately sought to make the approach and implementation more understandable. Self-learning machine-learning methods are expected to be included in the  package sometime later. Nonetheless, it appears to be important to design and test additional predictors.</p>
<p>To a modest extent, the usefulness of the predictors was tested on exemplary data sets. The aim was to achieve a high degree of objectivity and reproducibility. It is probably not possible to fulfill this ideal, since the algorithms were designed from the limited human perspective. That is a generic problem in machine learning. In particular, data records can be distorted if the user excludes seemingly problematic data. It is advisable to perform a more comprehensive analysis of all predictors.</p>
<p>Several ROIs (see ) can be obtained from amplification curves. Sigmoidal amplification curves have turning points that can serve as an indicator of a positive amplification curve. These turning points, for example, are mathematical and statistical starting points for calculating predictors. Amplification curves can have unique forms and sometimes deviate drastically from the ideal sigmoid models (see A and B). Some amplification curves, for example, have only a slight increase with positive or negative signs without a typical sigmoid curvature.</p>
<p>Almost all real-time thermo-cyclers have built-in software that performs pre-processing steps such as smoothing, baseline correction and normalization on the amplification curves <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015, <span class="citation">Spiess et al. (2015)</span>, <span class="citation">Spiess et al. (2016)</span>)</span>. For this reason it is almost impossible to get access to the raw data. The impact on the predictor extraction process cannot be adequately estimated.</p>
<p>The volume and classification of data sets needs to be representative <span class="citation">(Herrera et al. 2016)</span>. The  package contains a large number of manually classified amplification curves. Data preparation is an important step. It encompasses data cleansing, data transformation and data integration <span class="citation">(Herrera et al. 2016)</span>. The  package <span class="citation">(Seibelt 2017)</span> can be used to analyze the distribution form and the variables in records for anomalies such as missing values, zeros, empty strings (Blank) and infinite numbers (Inf) and their categories. Users of the package should use this kind of tools before proceeding with the data sets. Even though the records in the  package have a very similar data structure, some records contain missing values or have different dimensions. For example, the data set <code>C127EGHP</code> comprises a matrix of 40 x 66 (35 cycles x observations (65 amplification curves)), while the data set <code>htPCR</code> comprises a matrix of 35 x 8859.</p>
<p>Although the data set in the  package is large compared to what has been available so far, there is no conclusive evidence of how well it represents amplification curves in general. Bellman coined the term “Curse of Dimensionality” in 1961 when he dealt with adaptive control processes. The “Curse of Dimensionality” vaguely describes the practical difficulties of high-dimensional analysis and estimation. There is only a maximum number of predictors for a sample of a certain size. If there are too many predictors, the performance of an algorithm decreases rather than improves. As a result, many data mining algorithms fail with high dimensionality because the data points are thin and far apart <span class="citation">(Herrera et al. 2016)</span>. In addition, the following applies:</p>
<ul>
<li>The user’s knowledge, prejudices and skills are reflected in the classified data. For example, an amplification can be classified as “ambiguous” by one user and “positive” by another user.</li>
<li>Not all data sets have a comparable number of cases as described above. The majority of the amplification curves of the <code>C127EGHP</code> data set have an <em>ideal</em> sigmoid waveform. In contrast, the amplification curves from the <code>htPCR</code> data set are noisy and difficult to classify.</li>
<li>The user decides
<ul>
<li>how the data is preprocessed,</li>
<li>which predictors are determined by the amplification curves,</li>
<li>which data set is used for machine learning and to what extent,</li>
<li>how the models are tested and</li>
<li>which results are reported.</li>
</ul>
</li>
</ul>
<p>For the examples in the  package, the question was not clarified whether class imbalances in the data sets cause a confirmation distortion. However, a class imbalance may result in lose of the prediction strength, because some classifiers make the assumption of similar class distributions <span class="citation">(Herrera et al. 2016)</span>.</p>
<p>A new concept for the fast group-wise classification of amplification curves was introduced within the  package. Based on experience with the collected data sets it can be said that only a few iterations are necessary to classify a large data set. This software is intended as an assistance for the users of the package.</p>
<p>Actions to minimize the these sources of error are the implementation of algorithms in the form of an open source package and the publication of the data sets. Unlike black box algorithms and inaccessible data sets, every user can check and correct all steps. Users of  packages should independently verify whether their models are objective. Failure to do so may have severe implications. For instance, amplification curves classified as false negative may lead to misleading inferences in a forensic analysis.</p>
<p>Machine-learning algorithms require careful data pre-processing and quality management. In a first step, relatively large data sets of known characteristic vectors have to be collected and predictors calculated. In a second step, these characteristics are used to classify unknown characteristic vectors using the automatic learning algorithm. As an example, the amplification curves would need to be randomly divided into training data and test data from the whole data set. Some examples were used in the  package to show how predictors of an amplification curve data set can be calculated and used for classifications.</p>
<p>The scope of the  package is presumably wide. The quantitation of nucleic acids by curve parameters such as the quantification point (Cq) and the amplification efficiency (AE) is meaningful only if the amplification curves has a sigmoid shape <span class="citation">(Jan M. Ruijter et al. 2013, <span class="citation">Jan M. Ruijter et al. (2014)</span>, <span class="citation">Ritz and Spiess (2008)</span>)</span>. In principle, this can be checked out with the  package.</p>
<p>The concepts may also be applied to other bioanalytical methods (e.g. enzyme kinetics) with sigmoidal curves. This will require further studies. Possibly the  software can also be coupled with other technologies, e.g. Next Generation Sequencing. A typical situation is that the result classes are positive, negative or ambiguous. Ambiguous amplification curves are a big challenge for the user, as both classes (positive and negative) can be true. In most cases, however, the user is interested in an automatic distinction between positive and negative samples. This is important for screening applications. Next generation sequencing depends on pre-tests of the input DNA before sequencing. qPCR is used for pre-testing and as a confirmation test for RNA-Seq quantification. For this purpose, automated quality control and decision support are conceivable.</p>

</div>
<div id="references" class="section level1 unnumbered">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<div id="refs" class="references">
<div id="ref-arlot_survey_2010">
<p>Arlot, Sylvain, and Alain Celisse. 2010. “A survey of cross-validation procedures for model selection.” <em>Statistics Surveys</em> 4: 40–79. doi:<a href="https://doi.org/10.1214/09-SS054">10.1214/09-SS054</a>.</p>
</div>
<div id="ref-baebler_quantgenius:_2017">
<p>Baebler, Miha Svalina, Marko Petek, Katja Stare, Ana Rotter, Maruša Pompe-Novak, and Kristina Gruden. 2017. “quantGenius: implementation of a decision support system for qPCR-based gene quantification.” <em>BMC Bioinformatics</em> 18 (1). doi:<a href="https://doi.org/10.1186/s12859-017-1688-7">10.1186/s12859-017-1688-7</a>.</p>
</div>
<div id="ref-barratt_improving_2002">
<p>Barratt, Kevin, and John F. Mackay. 2002. “Improving Real-Time PCR Genotyping Assays by Asymmetric Amplification.” <em>Journal of Clinical Microbiology</em> 40 (4): 1571–2. doi:<a href="https://doi.org/10.1128/JCM.40.4.1571-1572.2002">10.1128/JCM.40.4.1571-1572.2002</a>.</p>
</div>
<div id="ref-Baaaath_2012">
<p>Bååth, Rasmus. 2012. “The State of Naming Conventions in R.” <em>The R Journal</em> 4 (2): 74–75. <a href="http://journal.r-project.org/archive/2012-2/RJournal_2012-2_Baaaath.pdf" class="uri">http://journal.r-project.org/archive/2012-2/RJournal_2012-2_Baaaath.pdf</a>.</p>
</div>
<div id="ref-bischl_mlr:_2010">
<p>Bischl, Bernd, Michel Lang, Lars Kotthoff, Julia Schiffner, Jakob Richter, Erich Studerus, Giuseppe Casalicchio, and Zachary M. Jones. 2010. <em>mlr: Machine learning in R</em>. <a href="http://www.jmlr.org/papers/volume17/15-066/source/15-066.pdf" class="uri">http://www.jmlr.org/papers/volume17/15-066/source/15-066.pdf</a>.</p>
</div>
<div id="ref-breiman_random_2001">
<p>Breiman, Leo. 2001. “Random forests.” <em>Machine Learning</em> 45 (1): 5–32.</p>
</div>
<div id="ref-noauthor_compstat_2008">
<p>Brito, Paula, ed. 2008. <em>COMPSTAT 2008: Proceedings in Computational Statistics</em>. Physica-Verlag Heidelberg.</p>
</div>
<div id="ref-bustin_continuing_2017">
<p>Bustin, Stephen. 2017. “The continuing problem of poor transparency of reporting and use of inappropriate methods for RT-qPCR.” <em>Biomolecular Detection and Quantification</em> 12 (June): 7–9. doi:<a href="https://doi.org/10.1016/j.bdq.2017.05.001">10.1016/j.bdq.2017.05.001</a>.</p>
</div>
<div id="ref-charpiat_shape_2003">
<p>Charpiat, Guillaume, Olivier Faugeras, and Renaud Keriven. 2003. “Shape metrics, warping and statistics.” In <em>Image Processing, 2003. ICIP 2003. Proceedings. 2003 International Conference on</em>, 2:II–627. IEEE. <a href="http://ieeexplore.ieee.org/abstract/document/1246758/" class="uri">http://ieeexplore.ieee.org/abstract/document/1246758/</a>.</p>
</div>
<div id="ref-cook_interactive_2007">
<p>Cook, Dianne, and Deborah F. Swayne. 2007. <em>Interactive and Dynamic Graphics for Data Analysis: With R and GGobi</em>. 2007 edition. 1st Ser. New York: Springer. <a href="http://www.springer.com/us/book/9780387717616" class="uri">http://www.springer.com/us/book/9780387717616</a>.</p>
</div>
<div id="ref-de_vries_r_2012">
<p>De Vries, Andrie, and Joris Meys. 2012. <em>R for Dummies</em>. 2nd ed. John Wiley &amp; Sons.</p>
</div>
<div id="ref-dvinge_htqpcr:_2009">
<p>Dvinge, Heidi, and Paul Bertone. 2009. “HTqPCR: high-throughput analysis and visualization of quantitative real-time PCR data in R.” <em>Bioinformatics</em> 25 (24): 3325–6. doi:<a href="https://doi.org/10.1093/bioinformatics/btp578">10.1093/bioinformatics/btp578</a>.</p>
</div>
<div id="ref-erdman_bcp:_2007">
<p>Erdman, Chandra, John W. Emerson, and others. 2007. “bcp: an R package for performing a Bayesian analysis of change point problems.” <em>Journal of Statistical Software</em> 23 (3): 1–13. <a href="https://www.researchgate.net/profile/Chandra_Erdman/publication/26538600_bcp_An_R_Package_for_Performing_a_Bayesian_Analysis_of_Change_Point_Problems/links/56dee56608aec8c022cf2fd2.pdf" class="uri">https://www.researchgate.net/profile/Chandra_Erdman/publication/26538600_bcp_An_R_Package_for_Performing_a_Bayesian_Analysis_of_Change_Point_Problems/links/56dee56608aec8c022cf2fd2.pdf</a>.</p>
</div>
<div id="ref-Febrero_Bande_2012">
<p>Febrero-Bande, Manuel, and Manuel Oviedo de la Fuente. 2012. “Statistical Computing in Functional Data Analysis: The R Package fda.usc.” <em>Journal of Statistical Software</em> 51 (4): 1–28. <a href="http://www.jstatsoft.org/v51/i04/" class="uri">http://www.jstatsoft.org/v51/i04/</a>.</p>
</div>
<div id="ref-feuer_lemming:_2015">
<p>Feuer, Ronny, Sebastian Vlaic, Janine Arlt, Oliver Sawodny, Uta Dahmen, Ulrich M. Zanger, and Maria Thomas. 2015. “LEMming: A Linear Error Model to Normalize Parallel Quantitative Real-Time PCR (qPCR) Data as an Alternative to Reference Gene Based Methods.” <em>PLOS ONE</em> 10 (9): e0135852. doi:<a href="https://doi.org/10.1371/journal.pone.0135852">10.1371/journal.pone.0135852</a>.</p>
</div>
<div id="ref-greene_big_2014">
<p>Greene, Casey S., Jie Tan, Matthew Ung, Jason H. Moore, and Chao Cheng. 2014. “Big Data Bioinformatics.” <em>Journal of Cellular Physiology</em> 229 (12): 1896–1900. doi:<a href="https://doi.org/10.1002/jcp.24662">10.1002/jcp.24662</a>.</p>
</div>
<div id="ref-gunay_machine_2016">
<p>Gunay, Melih, Evgin Goceri, and Rajarajeswari Balasubramaniyan. 2016. “Machine Learning for Optimum CT-Prediction for qPCR.” In <em>Machine Learning and Applications (ICMLA), 2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)</em>, 588–92. IEEE. doi:<a href="https://doi.org/10.1109/ICMLA.2016.0103">10.1109/ICMLA.2016.0103</a>.</p>
</div>
<div id="ref-herrera_multiple_2016">
<p>Herrera, Francisco, Sebastián Ventura, Rafael Bello, Chris Cornelis, Amelia Zafra, Dánel Sánchez-Tarragó, and Sarah Vluymans. 2016. <em>Multiple Instance Learning</em>. Cham: Springer International Publishing. <a href="http://link.springer.com/10.1007/978-3-319-47759-6" class="uri">http://link.springer.com/10.1007/978-3-319-47759-6</a>.</p>
</div>
<div id="ref-covr">
<p>Hester, Jim. 2018. <em>Covr: Test Coverage for Packages</em>. <a href="https://CRAN.R-project.org/package=covr" class="uri">https://CRAN.R-project.org/package=covr</a>.</p>
</div>
<div id="ref-hothorn_handbook_2014">
<p>Hothorn, Torsten, and Brian S. Everitt. 2014. <em>A Handbook of Statistical Analyses using R, Third Edition</em>. 3rd ed. Oakville: Chapman; Hall/CRC.</p>
</div>
<div id="ref-hothorn_unbiased_2006">
<p>Hothorn, Torsten, Kurt Hornik, and Achim Zeileis. 2006. “Unbiased Recursive Partitioning: A Conditional Inference Framework.” <em>Journal of Computational and Graphical Statistics</em> 15 (3): 651–74. doi:<a href="https://doi.org/10.1198/106186006X133933">10.1198/106186006X133933</a>.</p>
</div>
<div id="ref-igual_introduction_2017">
<p>Igual, Laura, and Santi Seguí. 2017. <em>Introduction to Data Science</em>. Undergraduate Topics in Computer Science. Cham: Springer International Publishing. <a href="http://link.springer.com/10.1007/978-3-319-50017-1" class="uri">http://link.springer.com/10.1007/978-3-319-50017-1</a>.</p>
</div>
<div id="ref-isaac_essentials_2009">
<p>Isaac, Peter G. 2009. “Essentials of nucleic acid analysis: a robust approach.” <em>Annals of Botany</em> 104 (2): vi–vi. doi:<a href="https://doi.org/10.1093/aob/mcp135">10.1093/aob/mcp135</a>.</p>
</div>
<div id="ref-james_introduction_2013">
<p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. Vol. 103. Springer Texts in Statistics. New York, NY: Springer New York. <a href="http://link.springer.com/10.1007/978-1-4614-7138-7" class="uri">http://link.springer.com/10.1007/978-1-4614-7138-7</a>.</p>
</div>
<div id="ref-james_ecp:_2013">
<p>James, Nicholas A., and David S. Matteson. 2013. “ecp: An R package for nonparametric multiple change point analysis of multivariate data.” <em>arXiv Preprint arXiv:1309.3295</em>. <a href="https://arxiv.org/abs/1309.3295" class="uri">https://arxiv.org/abs/1309.3295</a>.</p>
</div>
<div id="ref-Killick_2014">
<p>Killick, Rebecca, and Idris A. Eckley. 2014. “changepoint: An R Package for Changepoint Analysis.” <em>Journal of Statistical Software</em> 58 (3): 1–19. <a href="http://www.jstatsoft.org/v58/i03/" class="uri">http://www.jstatsoft.org/v58/i03/</a>.</p>
</div>
<div id="ref-kitchin2014">
<p>Kitchin, Rob. 2014. <em>The data revolution : big data, open data, data infrastructures &amp; their consequences</em>. Los Angeles, California London: SAGE Publications.</p>
</div>
<div id="ref-knuth_literate_1984">
<p>Knuth, D. E. 1984. “Literate Programming.” <em>The Computer Journal</em> 27 (2): 97–111. doi:<a href="https://doi.org/10.1093/comjnl/27.2.97">10.1093/comjnl/27.2.97</a>.</p>
</div>
<div id="ref-kruppa_probability_2014">
<p>Kruppa, Jochen, Yufeng Liu, Gérard Biau, Michael Kohler, Inke R. König, James D. Malley, and Andreas Ziegler. 2014. “Probability Estimation with Machine Learning Methods for Dichotomous and Multicategory Outcome: Theory.” <em>Biometrical Journal</em>, no. 4 (July): 534–63. doi:<a href="https://doi.org/10.1002/bimj.201300068">10.1002/bimj.201300068</a>.</p>
</div>
<div id="ref-kuhn_building_2008">
<p>Kuhn, Max. 2008. “Building Predictive Models in R Using the caret Package.” <em>Journal of Statistical Software</em> 28 (5). <a href="http://www.jstatsoft.org/v28/i05/" class="uri">http://www.jstatsoft.org/v28/i05/</a>.</p>
</div>
<div id="ref-lanubile_collaboration_2010">
<p>Lanubile, F., C. Ebert, R. Prikladnicki, and A. Vizcaíno. 2010. “Collaboration Tools for Global Software Engineering.” <em>IEEE Software</em> 27 (2): 52–55. doi:<a href="https://doi.org/10.1109/MS.2010.39">10.1109/MS.2010.39</a>.</p>
</div>
<div id="ref-lee_statistical_2010">
<p>Lee, J. K. 2010. <em>Statistical Bioinformatics: For Biomedical and Life Science Researchers</em>. Wiley. <a href="https://books.google.de/books?id=aT1MBGtxSNsC" class="uri">https://books.google.de/books?id=aT1MBGtxSNsC</a>.</p>
</div>
<div id="ref-lefever_rdml_2009">
<p>Lefever, Steve, Jan Hellemans, Filip Pattyn, Daniel R. Przybylski, Chris Taylor, René Geurts, Andreas Untergasser, Jo Vandesompele, and RDML on behalf of the Consortium. 2009. “RDML: structured language and reporting guidelines for real-time quantitative PCR data.” <em>Nucleic Acids Research</em> 37 (7): 2065–9. doi:<a href="https://doi.org/10.1093/nar/gkp056">10.1093/nar/gkp056</a>.</p>
</div>
<div id="ref-liaw_classification_2002">
<p>Liaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” <em>R News</em> 2 (3): 18–22. <a href="http://CRAN.R-project.org/doc/Rnews/" class="uri">http://CRAN.R-project.org/doc/Rnews/</a>.</p>
</div>
<div id="ref-luan_signal-detection_2011">
<p>Luan, Shenghua, Lael J. Schooler, and Gerd Gigerenzer. 2011. “A signal-detection analysis of fast-and-frugal trees.” <em>Psychological Review</em> 118 (2): 316–38. doi:<a href="https://doi.org/10.1037/a0022684">10.1037/a0022684</a>.</p>
</div>
<div id="ref-mallona_chainy:_nodate">
<p>Mallona, Izaskun, Anna Díez-Villanueva, Berta Martín, and Miguel A. Peinado. 2017. “Chainy: an universal tool for standardized relative quantification in real-time PCR.” <em>Bioinformatics</em>. doi:<a href="https://doi.org/10.1093/bioinformatics/btw839">10.1093/bioinformatics/btw839</a>.</p>
</div>
<div id="ref-mallona_pcrefficiency:_2011">
<p>Mallona, Izaskun, Julia Weiss, and Marcos Egea-Cortines. 2011. “pcrEfficiency: a Web tool for PCR amplification efficiency prediction.” <em>BMC Bioinformatics</em> 12: 404. doi:<a href="https://doi.org/10.1186/1471-2105-12-404">10.1186/1471-2105-12-404</a>.</p>
</div>
<div id="ref-martins_dna_2015">
<p>Martins, C., G. Lima, Mr. Carvalho, L. Cainé, and Mj. Porto. 2015. “DNA quantification by real-time PCR in different forensic samples.” <em>Forensic Science International: Genetics Supplement Series</em> 5 (December): e545–e546. doi:<a href="https://doi.org/10.1016/j.fsigss.2015.09.215">10.1016/j.fsigss.2015.09.215</a>.</p>
</div>
<div id="ref-matz_no_2013">
<p>Matz, Mikhail V., Rachel M. Wright, and James G. Scott. 2013. “No Control Genes Required: Bayesian Analysis of qRT-PCR Data.” <em>PLoS ONE</em> 8 (8): e71448. doi:<a href="https://doi.org/10.1371/journal.pone.0071448">10.1371/journal.pone.0071448</a>.</p>
</div>
<div id="ref-mccall_non-detects_2014">
<p>McCall, Matthew N., Helene R. McMurray, Hartmut Land, and Anthony Almudevar. 2014. “On non-detects in qPCR data.” <em>Bioinformatics</em> 30 (16): 2310–6. doi:<a href="https://doi.org/10.1093/bioinformatics/btu239">10.1093/bioinformatics/btu239</a>.</p>
</div>
<div id="ref-mcfadden_conditional_1974">
<p>McFadden, Daniel L. 1974. “Conditional Logit Analysis of Qualitative Choice Behavior.” In <em>Frontiers in Economics</em>, Frontiers in Economics:105–42. P. Zarembka (ed.). New York: Academic Press. <a href="https://eml.berkeley.edu/reprints/mcfadden/zarembka.pdf" class="uri">https://eml.berkeley.edu/reprints/mcfadden/zarembka.pdf</a>.</p>
</div>
<div id="ref-myers_art_2004">
<p>Myers, Glenford J., Tom Badgett, Todd M. Thomas, and Corey Sandler. 2004. <em>The art of software testing</em>. 2nd ed. Hoboken, N.J: John Wiley &amp; Sons.</p>
</div>
<div id="ref-neve_unifiedwmwqpcr:_2014">
<p>Neve, Jan De, Joris Meys, Jean-Pierre Ottoy, Lieven Clement, and Olivier Thas. 2014. “unifiedWMWqPCR: the unified Wilcoxon–Mann–Whitney test for analyzing RT-qPCR data in R.” <em>Bioinformatics</em> 30 (17): 2494–5. doi:<a href="https://doi.org/10.1093/bioinformatics/btu313">10.1093/bioinformatics/btu313</a>.</p>
</div>
<div id="ref-nolan_2006">
<p>Nolan, Tania, Rebecca E Hands, and Stephen A Bustin. 2006. “Quantification of mRNA using real-time RT-PCR.” <em>Nature Protocols</em> 1 (November): 1559. <a href="http://dx.doi.org/10.1038/nprot.2006.236" class="uri">http://dx.doi.org/10.1038/nprot.2006.236</a>.</p>
</div>
<div id="ref-pabinger_2014">
<p>Pabinger, Stephan, Stefan Rödiger, Albert Kriegner, Klemens Vierlinger, and Andreas Weinhäusel. 2014. “A survey of tools for the analysis of quantitative PCR (qPCR) data.” <em>Biomolecular Detection and Quantification</em> 1 (1): 23–33. doi:<a href="https://doi.org/10.1016/j.bdq.2014.08.002">10.1016/j.bdq.2014.08.002</a>.</p>
</div>
<div id="ref-pabinger_qpcr:_2009">
<p>Pabinger, Stephan, Gerhard G. Thallinger, René Snajder, Heiko Eichhorn, Robert Rader, and Zlatko Trajanoski. 2009. “QPCR: Application for real-time PCR data management and analysis.” <em>BMC Bioinformatics</em> 10 (1): 268. doi:<a href="https://doi.org/10.1186/1471-2105-10-268">10.1186/1471-2105-10-268</a>.</p>
</div>
<div id="ref-perkins_readqpcr_2012">
<p>Perkins, James R., John M. Dawes, Steve B. McMahon, David LH Bennett, Christine Orengo, and Matthias Kohl. 2012. “ReadqPCR and NormqPCR: R packages for the reading, quality checking and normalisation of RT-qPCR quantification cycle (Cq) data.” <em>BMC Genomics</em> 13 (1): 296. doi:<a href="https://doi.org/10.1186/1471-2164-13-296">10.1186/1471-2164-13-296</a>.</p>
</div>
<div id="ref-FFTrees_package">
<p>Phillips, Nathaniel, Hansjoerg Neth, Jan Woike, and Wolfgang Gaissmaer. 2017. <em>FFTrees: Generate, Visualise, and Evaluate Fast-and-Frugal Decision Trees</em>. <a href="https://CRAN.R-project.org/package=FFTrees" class="uri">https://CRAN.R-project.org/package=FFTrees</a>.</p>
</div>
<div id="ref-quinlan_induction_1986">
<p>Quinlan, J. Ross. 1986. “Induction of decision trees.” <em>Machine Learning</em> 1 (1): 81–106. <a href="http://link.springer.com/article/10.1007/BF00116251" class="uri">http://link.springer.com/article/10.1007/BF00116251</a>.</p>
</div>
<div id="ref-richards_flexible_1959">
<p>Richards, F. J. 1959. “A Flexible Growth Function for Empirical Use.” <em>Journal of Experimental Botany</em> 10 (2): 290–301. doi:<a href="https://doi.org/10.1093/jxb/10.2.290">10.1093/jxb/10.2.290</a>.</p>
</div>
<div id="ref-Ritz2008">
<p>Ritz, Christian, and Andrej-Nikolai Spiess. 2008. “qpcR: an R package for sigmoidal model selection in quantitative real-time polymerase chain reaction analysis.” <em>Bioinformatics</em> 24 (13): 1549–51. doi:<a href="https://doi.org/10.1093/bioinformatics/btn227">10.1093/bioinformatics/btn227</a>.</p>
</div>
<div id="ref-ronde_practical_2017">
<p>Ronde, Maurice W. J. de, Jan M. Ruijter, David Lanfear, Antoni Bayes-Genis, Maayke G. M. Kok, Esther E. Creemers, Yigal M. Pinto, and Sara-Joan Pinto-Sietsma. 2017. “Practical data handling pipeline improves performance of qPCR-based circulating miRNA measurements.” <em>RNA</em> 23 (5): 811–21. doi:<a href="https://doi.org/10.1261/rna.059063.116">10.1261/rna.059063.116</a>.</p>
</div>
<div id="ref-rote_computing_1991">
<p>Rote, Günter. 1991. “Computing the minimum Hausdorff distance between two point sets on a line under translation.” <em>Information Processing Letters</em> 38 (3): 123–27. doi:<a href="https://doi.org/10.1016/0020-0190(91)90233-8">10.1016/0020-0190(91)90233-8</a>.</p>
</div>
<div id="ref-roediger_RJ_2013">
<p>Rödiger, Stefan, Alexander Böhm, and Ingolf Schimke. 2013. “Surface Melting Curve Analysis with R.” <em>The R Journal</em> 5 (2): 37–53. <a href="http://journal.r-project.org/archive/2013-2/roediger-bohm-schimke.pdf" class="uri">http://journal.r-project.org/archive/2013-2/roediger-bohm-schimke.pdf</a>.</p>
</div>
<div id="ref-roediger2015chippcr">
<p>Rödiger, Stefan, Michał Burdukiewicz, and Peter Schierack. 2015. “chipPCR: an R package to pre-process raw data of amplification curves.” <em>Bioinformatics</em> 31 (17): 2900–2902. doi:<a href="https://doi.org/10.1093/bioinformatics/btv205">10.1093/bioinformatics/btv205</a>.</p>
</div>
<div id="ref-roediger2015r">
<p>Rödiger, Stefan, Michał Burdukiewicz, Konstantin A. Blagodatskikh, and Peter Schierack. 2015. “R as an Environment for the Reproducible Analysis of DNA Amplification Experiments.” <em>The R Journal</em> 7 (2): 127–50. <a href="http://journal.r-project.org/archive/2015-1/RJ-2015-1.pdf" class="uri">http://journal.r-project.org/archive/2015-1/RJ-2015-1.pdf</a>.</p>
</div>
<div id="ref-roediger_enabling_2017">
<p>Rödiger, Stefan, Michał Burdukiewicz, Andrej-Nikolai Spiess, and Konstantin Blagodatskikh. 2017. “Enabling reproducible real-time quantitative PCR research: the RDML package.” <em>Bioinformatics</em>, August. doi:<a href="https://doi.org/10.1093/bioinformatics/btx528">10.1093/bioinformatics/btx528</a>.</p>
</div>
<div id="ref-roediger_highly_2013">
<p>Rödiger, Stefan, Peter Schierack, Alexander Böhm, Jörg Nitschke, Ingo Berger, Ulrike Frömmel, Carsten Schmidt, et al. 2013. “A highly versatile microscope imaging technology platform for the multiplex real-time detection of biomolecules and autoimmune antibodies.” <em>Advances in Biochemical Engineering/Biotechnology</em> 133: 35–74. doi:<a href="https://doi.org/10.1007/10_2011_132">10.1007/10_2011_132</a>.</p>
</div>
<div id="ref-ruijter_amplification_2009">
<p>Ruijter, J M, C Ramakers, W M H Hoogaars, Y Karlen, O Bakker, M J B van den Hoff, and A F M Moorman. 2009. “Amplification efficiency: linking baseline and bias in the analysis of quantitative PCR data.” <em>Nucleic Acids Research</em> 37 (6): e45. doi:<a href="https://doi.org/10.1093/nar/gkp045">10.1093/nar/gkp045</a>.</p>
</div>
<div id="ref-ruijter_2014">
<p>Ruijter, Jan M., Peter Lorenz, Jari M. Tuomi, Michael Hecker, and Maurice J. B. van den Hoff. 2014. “Fluorescent-increase kinetics of different fluorescent reporters used for qPCR depend on monitoring chemistry, targeted sequence, type of DNA input and PCR efficiency.” <em>Microchimica Acta</em>, 1–8. doi:<a href="https://doi.org/10.1007/s00604-013-1155-8">10.1007/s00604-013-1155-8</a>.</p>
</div>
<div id="ref-ruijter_evaluation_2013">
<p>Ruijter, Jan M., Michael W. Pfaffl, Sheng Zhao, Andrej N. Spiess, Gregory Boggy, Jochen Blom, Robert G. Rutledge, et al. 2013. “Evaluation of qPCR curve analysis methods for reliable biomarker discovery: Bias, resolution, precision, and implications.” <em>Methods</em> 59 (1): 32–46. doi:<a href="https://doi.org/10.1016/j.ymeth.2012.08.011">10.1016/j.ymeth.2012.08.011</a>.</p>
</div>
<div id="ref-ruijter_removal_2015">
<p>Ruijter, Jan M., Adrián Ruiz Villalba, Jan Hellemans, Andreas Untergasser, and Maurice J. B. van den Hoff. 2015. “Removal of between-run variation in a multi-plate qPCR experiment.” <em>Biomolecular Detection and Quantification</em>, Special Issue: Advanced Molecular Diagnostics for Biomarker Discovery – Part I, 5 (September): 10–14. doi:<a href="https://doi.org/10.1016/j.bdq.2015.07.001">10.1016/j.bdq.2015.07.001</a>.</p>
</div>
<div id="ref-saeys_review_2007">
<p>Saeys, Y., I. Inza, and P. Larranaga. 2007. “A review of feature selection techniques in bioinformatics.” <em>Bioinformatics</em> 23 (19): 2507–17. doi:<a href="https://doi.org/10.1093/bioinformatics/btm344">10.1093/bioinformatics/btm344</a>.</p>
</div>
<div id="ref-sauer_differentiation_2016">
<p>Sauer, Eva, Ann-Kathrin Reinke, and Cornelius Courts. 2016. “Differentiation of five body fluids from forensic samples by expression analysis of four microRNAs using quantitative PCR.” <em>Forensic Science International: Genetics</em> 22 (May): 89–99. doi:<a href="https://doi.org/10.1016/j.fsigen.2016.01.018">10.1016/j.fsigen.2016.01.018</a>.</p>
</div>
<div id="ref-scott_cluster_1974">
<p>Scott, A. J., and M. Knott. 1974. “A Cluster Analysis Method for Grouping Means in the Analysis of Variance.” <em>Biometrics</em> 30 (3): 507. doi:<a href="https://doi.org/10.2307/2529204">10.2307/2529204</a>.</p>
</div>
<div id="ref-Seibelt_xray">
<p>Seibelt, Pablo. 2017. <em>xray: X Ray Vision on your Datasets</em>. <a href="https://CRAN.R-project.org/package=xray" class="uri">https://CRAN.R-project.org/package=xray</a>.</p>
</div>
<div id="ref-sing_rocr:_2005">
<p>Sing, Tobias, Oliver Sander, Niko Beerenwinkel, and Thomas Lengauer. 2005. “ROCR: visualizing classifier performance in R.” <em>Bioinformatics</em> 21 (20): 3940–1. doi:<a href="https://doi.org/10.1093/bioinformatics/bti623">10.1093/bioinformatics/bti623</a>.</p>
</div>
<div id="ref-spiess_impact_2015">
<p>Spiess, Andrej-Nikolai, Claudia Deutschmann, Michał Burdukiewicz, Ralf Himmelreich, Katharina Klat, Peter Schierack, and Stefan Rödiger. 2015. “Impact of Smoothing on Parameter Estimation in Quantitative DNA Amplification Experiments.” <em>Clinical Chemistry</em> 61 (2): 379–88. doi:<a href="https://doi.org/10.1373/clinchem.2014.230656">10.1373/clinchem.2014.230656</a>.</p>
</div>
<div id="ref-spiess_highly_2008">
<p>Spiess, Andrej-Nikolai, Caroline Feig, and Christian Ritz. 2008. “Highly accurate sigmoidal fitting of real-time PCR data by introducing a parameter for asymmetry.” <em>BMC Bioinformatics</em> 9 (1): 221. doi:<a href="https://doi.org/10.1186/1471-2105-9-221">10.1186/1471-2105-9-221</a>.</p>
</div>
<div id="ref-spiess_system-specific_2016">
<p>Spiess, Andrej-Nikolai, Stefan Rödiger, Michał Burdukiewicz, Thomas Volksdorf, and Joel Tellinghuisen. 2016. “System-specific periodicity in quantitative real-time polymerase chain reaction data questions threshold-based quantitation.” <em>Scientific Reports</em> 6 (December): 38951. doi:<a href="https://doi.org/10.1038/srep38951">10.1038/srep38951</a>.</p>
</div>
<div id="ref-rpart_2017">
<p>Therneau, Terry, Beth Atkinson, and Brian Ripley. 2017. <em>rpart: Recursive Partitioning and Regression Trees</em>. <a href="https://CRAN.R-project.org/package=rpart" class="uri">https://CRAN.R-project.org/package=rpart</a>.</p>
</div>
<div id="ref-tichopad_standardized_2003">
<p>Tichopad, Ales, Michael Dilger, Gerhard Schwarz, and Michael W Pfaffl. 2003. “Standardized determination of real-time PCR efficiency from a single reaction set-up.” <em>Nucleic Acids Research</em> 31 (20): e122.</p>
</div>
<div id="ref-walsh_correct_2015">
<p>Walsh, Ian, Gianluca Pollastri, and Silvio C. E. Tosatto. 2015. “Correct machine learning on protein sequences: a peer-reviewing perspective.” <em>Briefings in Bioinformatics</em>, September, bbv082. doi:<a href="https://doi.org/10.1093/bib/bbv082">10.1093/bib/bbv082</a>.</p>
</div>
<div id="ref-westermeier2004">
<p>Westermeier, Reiner. 2004. <em>Electrophoresis in Practice: A Guide to Methods and Applications of DNA and Protein Separations, Fourth Edition</em>. Wiley-Blackwell. doi:<a href="https://doi.org/10.1002/3527603468">10.1002/3527603468</a>.</p>
</div>
<div id="ref-wickham_testthat_2011">
<p>Wickham, Hadley. 2011. “testthat: Get Started with Testing.” <em>The R Journal</em> 3 (1): 5–10. <a href="http://journal.r-project.org/archive/2011/RJ-2011-002/index.html" class="uri">http://journal.r-project.org/archive/2011/RJ-2011-002/index.html</a>.</p>
</div>
<div id="ref-williams_rattle:_2009">
<p>Williams, Graham J. 2009. “Rattle: A Data Mining GUI for R.” <em>The R Journal</em> 1 (2): 45–55. <a href="http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Williams.pdf" class="uri">http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Williams.pdf</a>.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#development-implementation-and-installation">Development, Implementation and Installation </a></li>
      <li><a href="#analysis-of-sigmoid-shaped-curves-for-data-mining-and-machine-learning-applications">Analysis of Sigmoid Shaped Curves for Data Mining and Machine Learning Applications</a></li>
      <li><a href="#technologies-for-amplification-curve-classification-and-classified-amplification-curves">Technologies for Amplification Curve Classification and Classified Amplification Curves</a></li>
      <li><a href="#data-analysis-functions-of-the-package">Data Analysis Functions of the  Package </a></li>
      <li><a href="#summary-and-conclusions">Summary and Conclusions </a></li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Stefan Roediger, Michal Burdukiewicz, Andrej-Nikolai Spiess, Konstantin A. Blagodatskikh.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
