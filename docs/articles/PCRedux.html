<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>PCRedux Package - An Overview • PCRedux</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="PCRedux Package - An Overview">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">PCRedux</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">0.2.6.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/PCRedux.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/SI1.html">Algorithms for Automatized Detection of Hook Effect-bearing Amplification Curves</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/devSJR/PCRedux">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>PCRedux Package - An Overview</h1>
                        <h4 class="author">Stefan Rödiger</h4>
            
            <h4 class="date">2018-08-07</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/devSJR/PCRedux/blob/master/vignettes/PCRedux.Rmd"><code>vignettes/PCRedux.Rmd</code></a></small>
      <div class="hidden name"><code>PCRedux.Rmd</code></div>

    </div>

    
    


<div id="analysis-of-sigmoid-shaped-curves-for-data-mining-and-machine-learning-applications" class="section level2">
<h2 class="hasAnchor">
<a href="#analysis-of-sigmoid-shaped-curves-for-data-mining-and-machine-learning-applications" class="anchor"></a>Analysis of Sigmoid Shaped Curves for Data Mining and Machine Learning Applications</h2>
<p> is an open source software package for the analysis and numerical description of sigmoid curves. The descriptors (features) () can be used for applications such as data mining, automatic classification (e. g., positive, negative). This is in useful for applications in machine learning.</p>
<p>In the following chapters information are provided, which can be used for the analysis and numerical description of quantitative real-time PCR amplification curves. The determination of quantification points such as the Cq value is dealt with only marginally (e. g.,  ff.), since specific software packages and analysis procedures have already been described in other studies ().</p>
<p>Instead, characteristics of amplification curves and sigmoid functions that can be used for the statistical and analytical description are discussed (). The examples described in the following focus on the binary classification as positive or negative. Further, chapters describe the implementation of the hypotheses in the  package. This includes technologies used for quality control of the  package.</p>
<p>The availability of classified amplification curve datasets and technologies for the classification of amplification curves is of high importance to train and validate models. This is dealt with in  and , respectively.</p>
<div id="why-is-there-is-need-for-this-software" class="section level3">
<h3 class="hasAnchor">
<a href="#why-is-there-is-need-for-this-software" class="anchor"></a>Why is there is need for this software?</h3>
<p>A classification as negative or positive amplification curve is feasible using bioanalytical methods such as melting curve analysis or an electrokinetic separation. However, this is not always possible or desirable. For example,</p>
<ul>
<li>Melting curves cannot be obtained with certain detection chemistries. For example, Taqman probes get hydrolyzed. An electrokinetic separation often requires too much effort for experiments with high sample throughput. A classification must also be carried out for both melting curve analysis and electrokinetic separation.</li>
<li>There are algorithms such as  <span class="citation">(J M Ruijter et al. 2009)</span> that require information on whether an amplification curve is negative or positive for subsequent calculation.</li>
<li>The mere classification into positive or negative is not necessarily the only aim of the  package. Instead, it is aimed that users and developers have tools to classify amplification curves automatically by any category conceivable. This can be for example a description of the amplification curve quality.</li>
</ul>
</div>
<div id="technologies-for-working-with-amplification-curve-data" class="section level3">
<h3 class="hasAnchor">
<a href="#technologies-for-working-with-amplification-curve-data" class="anchor"></a>Technologies for Working with Amplification Curve Data</h3>
<p>Data mining algorithms and machine learning can be used for descriptive and predictive tasks during the analysis of complex datasets. Data mining uses specific methods from statistical interference, software engineering and domain knowledge to</p>
<ul>
<li>obtain a better understanding of the data and</li>
<li>to extract <em>hidden knowledge</em>
</li>
</ul>
<p>from the pre-processed data <span class="citation">(Herrera et al. 2016)</span>. All this implies that a human being interacts with the data at the different stages of the whole process. The human being is therefore always a part of the workflow in data mining. Parts of the data mining process are</p>
<ul>
<li>the pre-processing of the data ,</li>
<li>the description of the data,</li>
<li>the exploration of the data and</li>
<li>the search for connections and causes.</li>
</ul>
<p>In contrast, machine learning uses instructions and data in software modules to create models that can be used to make predictions on novel data. In machine learning, the human being is much less necessary in the entire process. During machine learning, processes (algorithms) are used to create models with tunable parameters. These models automatically adapt their performance to the information (features) from the data. Well-known examples of machine learning technologies are Decision Trees (DT), Boosting, Random Forests (RF), Support Vector Machines (SVM), generalized linear models (GLM), logistic regression (LR) and deep neural networks (DNN) <span class="citation">(Lee 2010)</span>. Recently, Reinforcement Learning has become more and more the focus of interest. The three following classes of machine learning are classically described in the literature:</p>
<ul>
<li>
<em>Supervised learning</em>: These algorithms (e. g., logistic regression, SVM, DT, RF) learn from a training dataset of labeled and annotated data (e. g., “positive” and “negative”). It is used for building a generalized model of all data. These algorithms use error or reward signals to evaluate the quality of a solution found <span class="citation">(Bischl et al. 2010, <span class="citation">Greene et al. (2014)</span>, <span class="citation">Igual and Seguí (2017)</span>)</span>.</li>
<li>
<em>Unsupervised learning</em>: Algorithms, such as k-means clustering, kernel density estimation, LDA or PCA learn from training datasets of unlabeled or non-annotated data to find hidden structures according to geometric or statistical criteria <span class="citation">(Bischl et al. 2010, <span class="citation">Greene et al. (2014)</span>, <span class="citation">Igual and Seguí (2017)</span>)</span>.</li>
<li>
<em>Reinforcement Learning</em>: The algorithms learn by reinforcement from <code>criticism</code>. The criticisms inform the algorithm about the quality of the solution found. But the criticism says nothing about how to improve. These algorithms iteratively search the improved solution in the entire solution space <span class="citation">(Bischl et al. 2010, <span class="citation">Igual and Seguí (2017)</span>)</span>.</li>
</ul>
<p>Decision trees are a classic approach to machine learning <span class="citation">(Quinlan 1986)</span>. Here relatively simple algorithms and simple tree structures are used to create a model.  offers several packages like  <span class="citation">(Hothorn, Hornik, and Zeileis 2006)</span> and  <span class="citation">(Therneau, Atkinson, and Ripley 2017)</span> for creating decision trees. Graphical user interface like  <span class="citation">(Williams 2009)</span> offer convenient user interfaces for data mining with . Applications of decision trees are shown in later chapters.</p>
<p>Binomial logistic regression is used in data science and machine learning to gain knowledge about a binary relationship. In specific, Binomial logistic regression can be used to fit a regression model, <span class="math inline">\(y = f(x)\)</span> if <span class="math inline">\(y\)</span> is a categorical variable with two states (e. g., negative, positive). Thus, binary variables have exactly two values (negative <span class="math inline">\(\rightarrow 0\)</span>, positive <span class="math inline">\(\rightarrow 1\)</span>). Typically, this model is used for predicting <span class="math inline">\(y\)</span> with <span class="math inline">\(n\)</span> predictors <span class="math inline">\(x_{i1}, \ldots, x_{k1}, (i = 1, \ldots, n)\)</span>. The predictors can be a mixture of continuous and categorical. The logit model is a robust and versatile classification method that can be used to explain a dependent binary variable. Their codomain of real numbers is limited to [0,1]. Probabilities can therefore be utilized. Logistical distribution function <span class="math inline">\(F(\eta)\)</span>, also known as the response function, is strictly monotone increasing and limited to this range.</p>
<p><span class="math inline">\(\eta_{i}\)</span> establishes the link between the probability of the occurrence and the independent variables. For this reason, <span class="math inline">\(\eta_{i}\)</span> is referred to as a link function. The distribution function of the normal distribution is an alternative to the logistical distribution function. By using the normal distribution, the Probit model is obtained. However, since this is more difficult to interpret, it is less widely used in practice. Since probabilities are used, it is possible to make a prediction about the probability of occurrence of an event. When analyzing amplification curves, a diagnosis can be made whether a reaction was unsuccessful (0) or successful (1). For the prediction independent metric variables are used. The metric variables have interpretable distances with a defined order. Their codomain is [-<span class="math inline">\(\infty\)</span>,<span class="math inline">\(\infty\)</span>]. The logistic distribution function on the independent variables can be used to determine the probability for <span class="math inline">\(Y_{i} = 0\)</span> or <span class="math inline">\(Y_{i} = 1\)</span>. A logistic regression model can be formulated as follows:</p>
<p><span class="math inline">\(F(\eta)=\frac{1}{1+exp(-\eta)}\)</span></p>
<p>The logistic regression analysis is based on the maximum-likelihood estimation (MLE). In contrast to linear regression, the probability for <span class="math inline">\(Y=1\)</span> is not modeled from explanatory variables. Rather, the logarithmic chance (logit) is used for the occurrence of <span class="math inline">\(Y=1\)</span>. The term <em>chance</em> refers to the ratio of the probability of occurrence of an event (e. g., amplification curve is positive) and the counter-probability (e. g., amplification curve is negative) of an event.</p>
<p>In the ideal case, this should achieve a high degree of objectivity and reproducibility. It is not always possible to justify this ideal, because the algorithms can be biased as the human. One reason is that humans design the algorithms and curate the dataset used for the learning. In particular, datasets can be biased if the human expert excludes seemingly problematic data.</p>
<p>The model should then be able to bring new unknown data into a meaningful context. The selected features have a significant influence on the accuracy of the model. In machine learning, variables are features that are used to train a model <span class="citation">(Saeys, Inza, and Larranaga 2007)</span>. Therefore, it is important to identify or generate new features potential features and to test them intensively. Regarding amplification curves, only a few features have been described in the literature so far. They are described in the following sections. Dedicated applications and descriptions of features in the peer-reviewed literature is not described.</p>
<p>Since machine learning algorithm for the analysis of amplification curve data were not available in the literature, it was necessary to speculate, which characteristics should be extracted by the processing algorithm and broken down into characteristic vectors. The number of proposed features that can be created with the algorithms of the  package was presumably the most extensive collection at the time of first release in summer 2017. Previously, only a few characteristics of amplification curves were described in the literature. Thus, it would be too few to use them extensively for machine learning with qPCR data. An application of those for machine learning could also not be found.</p>
<p>The algorithms of machine learning consist of several steps including careful data pre-processing and quality management. In a first step, relatively large datasets of known characteristic vectors have to be collected, measured and calculated as raw data. In a second step, these characteristics are used to classify unknown feature vectors using the machine learning algorithm. For example, the amplification curves would have to be divided into training data and test data from the entire dataset at random.</p>
</div>
<div id="relevance-of-amplification-curve-data-analysis" class="section level3">
<h3 class="hasAnchor">
<a href="#relevance-of-amplification-curve-data-analysis" class="anchor"></a>Relevance of Amplification Curve Data Analysis </h3>
<p> is an  package for the analysis of sigmoid curves. Data with sigmoid curves are common in many biological experiments. A widely used bioanalytical method is the quantitative real-time PCR (qPCR). qPCRs are applied in human diagnostics, life sciences and forensics <span class="citation">(Martins et al. 2015, <span class="citation">Sauer, Reinke, and Courts (2016)</span>)</span>.</p>
<p>qPCRs are performed in thermo-cyclers, which are equipped with a real-time monitoring technology. There are numerous manufactures, which produce thermo-cyclers as commercial products or as part of scientific projects. An example for a thermo-cycler that originated in scientific project is the VideoScan technology <span class="citation">(Rödiger et al. 2013)</span>.</p>
<p>Predefined temperatures can be set in thermo-cyclers to amplify DNA segments using the polymerase chain reaction (PCR). Most of the thermo-cyclers have a thermal block with wells at certain positions. Reaction vessels containing the PCR mix are inserted into these wells. There are also thermo-cyclers that use capillary tubes (e. g., Roche Light Cycler 1.5). The capillaries are heated and cooled by air. The thermo cycler raises and lowers the temperature in the reaction vessels in discrete, pre-programmed steps so that the PCR reaction can take place. The instruments with a real-time monitoring function sensors to measure changes of the fluorescence intensity in the reaction vessel. All thermo-cycler systems have software that processes and outputs the measured data. Plots of the fluorescence observations versus cycle number obtained from two different qPCR systems is shown in A and B. The thermo-cyclers produce different amplification curve shapes even with the same sample material and PCR mastermix because of their technical design, sensors and software. These factors need to be considered during the development of analysis algorithms.</p>
<p>Sigmoid functions are non-linear, real-valued, have a S-shaped curvature () and are are differentiable (e. g., first derivative maximum, with one local minimum and one local maximum). For this purpose, a sigmoid function can fitted to the dataset. With the model obtained, predictions can be made. For example, the position of the second derivative maximum can be calculated from this (). In the context of amplification curves, the second derivative maximum is commonly used to describe the relationship between the cycle number and the PCR product formation ().</p>
<div class="figure">
<img src="PCRedux_files/figure-html/unnamed-chunk-2-1.png" alt="\label{figure_sigmoid_cuve} Amplification curve data from an iQ5 (Bio-Rad) thermo-cycler and a high throughput experiment in the Biomark HD (Fluidigm). A) The `C127EGHP` dataset (\texttt{chipPCR} package, [@roediger2015chippcr]) with 64 amplification curves was produced in conventional thermo-cycler with a 8 x 12 PCR grid. B) The `htPCR` dataset (\texttt{qpcR} package, [@Ritz2008]), which contains 8858 amplification curves, was produced in a 95 x 96 PCR grid. Only 200 amplification curves are shown. In contrast to `A)` have all amplification curves in `B)` an off-set (intercept) of circa 0.25 RFU. C) Model function of a one-parameter sigmoid function. D) Model function of a sigmoid function with an intercept $n$ = 0.2 RFU. E) Model function of a sigmoid function with an intercept ($n$ ~ 0.25 RFU) and a square portion $m * x^{2}$. F) Model function of a sigmoid function with an intercept ($n$) and a square portion of $m * x^{2}$ and additional noise $\epsilon$ (normally distributed)." width="700"><p class="caption">
 Amplification curve data from an iQ5 (Bio-Rad) thermo-cycler and a high throughput experiment in the Biomark HD (Fluidigm). A) The <code>C127EGHP</code> dataset ( package, <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015)</span>) with 64 amplification curves was produced in conventional thermo-cycler with a 8 x 12 PCR grid. B) The <code>htPCR</code> dataset ( package, <span class="citation">(Ritz and Spiess 2008)</span>), which contains 8858 amplification curves, was produced in a 95 x 96 PCR grid. Only 200 amplification curves are shown. In contrast to <code>A)</code> have all amplification curves in <code>B)</code> an off-set (intercept) of circa 0.25 RFU. C) Model function of a one-parameter sigmoid function. D) Model function of a sigmoid function with an intercept <span class="math inline">\(n\)</span> = 0.2 RFU. E) Model function of a sigmoid function with an intercept (<span class="math inline">\(n\)</span> ~ 0.25 RFU) and a square portion <span class="math inline">\(m * x^{2}\)</span>. F) Model function of a sigmoid function with an intercept (<span class="math inline">\(n\)</span>) and a square portion of <span class="math inline">\(m * x^{2}\)</span> and additional noise <span class="math inline">\(\epsilon\)</span> (normally distributed).
</p>
</div>
<p>The analysis of sigmoid data (e. g., quantitative PCR) it is a manageable task if the data volume is low, or dedicated analysis software is available. An example such a scenario (low number of amplification curves) is shown in A. All 65 curves exhibit a sigmoid curve shape. In contrast, the vast number of amplification curves in B is barely manageable with a reasonable effort by simple visual inspection. These data originate from a high-throughput experiment that encompasses in total 8858 amplification curves. Moreover, a manual analysis of the data is time-consuming and prone to errors.</p>
<p>During the setup of a qPCR assay, a manual analysis is a justified and reasonable approach to get acquainted with the characteristics and challenges of the qPCR data. At least hypothetically, it can hardly be denied that the trained human expert can best interpret the dataset. In particular, artifacts and outliers in a series of measurements can usually be readily identified by humans. When large amounts of data need to be processed, however, manual analysis is unfavorable. In addition, the objectivity of an expert can be questioned. It is an open secret that data from quantitative real-time PCRs are occasionally subject to problematic post-processing. In particular, the reproducible and objective analysis of the amplification curve data exposes challenges to inexperienced users. Even among peers is not uncommon that they <code>judge</code> (classify) results differently. An example on this problem is given in .</p>
</div>
<div id="software-for-the-analysis-of-amplification-curve-data" class="section level3">
<h3 class="hasAnchor">
<a href="#software-for-the-analysis-of-amplification-curve-data" class="anchor"></a>Software for the Analysis of Amplification Curve Data </h3>
<p>There are several open source and closed source software tools, which can be used for the analysis of qPCR data <span class="citation">(Pabinger et al. 2014)</span>. A large proportion of the algorithms is implemented in the  statistical computing language. However, more dedicated literature is available from peer-reviewed publications and textbooks. The software packages deal for example with</p>
<ul>
<li>missing values and non-detects <span class="citation">(McCall et al. 2014)</span>,</li>
<li>noise and artifact removal <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015, <span class="citation">Rödiger et al. (2015)</span>, <span class="citation">Spiess et al. (2015)</span>, <span class="citation">Spiess et al. (2016)</span>)</span>,</li>
<li>inter run calibration <span class="citation">(Jan M. Ruijter et al. 2015)</span>,</li>
<li>normalization <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015, <span class="citation">Jan M. Ruijter et al. (2013)</span>, <span class="citation">Feuer et al. (2015)</span>, <span class="citation">Matz, Wright, and Scott (2013)</span>)</span>,</li>
<li>quantification cycle estimation <span class="citation">(Ritz and Spiess 2008, <span class="citation">Jan M. Ruijter et al. (2013)</span>)</span>,</li>
<li>amplification efficiency estimation <span class="citation">(Ritz and Spiess 2008, <span class="citation">Jan M. Ruijter et al. (2013)</span>)</span>,</li>
<li>data exchange <span class="citation">(Lefever et al. 2009, <span class="citation">Perkins et al. (2012)</span>, <span class="citation">Rödiger et al. (2017)</span>)</span>,</li>
<li>relative gene expression analysis <span class="citation">(Dvinge and Bertone 2009, <span class="citation">Pabinger et al. (2009)</span>, <span class="citation">Neve et al. (2014)</span>)</span> and</li>
<li>data analysis pipelines <span class="citation">(Pabinger et al. 2009, <span class="citation">Ronde et al. (2017)</span>, <span class="citation">Mallona, Weiss, and Egea-Cortines (2011)</span>, <span class="citation">Mallona et al. (2017)</span>)</span>.</li>
</ul>
<p>All softwares assume that the amplification resemble a sigmoid curve shape (ideal positive amplification reaction), or a flat low line (ideal negative amplification reaction). For example, <span class="citation">Ritz and Spiess (2008)</span> published the   package that contains functions to fit several multi-parameter models. This includes the five-parameter Richardson function <span class="citation">(Richards 1959)</span>, which is often used for the analysis of qPCR data.</p>
<p>Researchers have found many solutions to challenges that were daunting the users of the qPCR methodology in the past. For example selected qPCR systems have a periodicity in the amplification curve data <span class="citation">(Spiess et al. 2016)</span>. Presence a periodicity exposes the risk of introducing artificially shifts in the Cq values. Another commonly employed pre-processing step of qPCR is smoothing and filtering. Both approaches cause alterations to the raw data that affects both the estimation of the Cq value and the amplification efficiency. The particular the cycle threshold method (Ct method) () is affected by these factors <span class="citation">(Spiess et al. 2015, <span class="citation">Spiess et al. (2016)</span>)</span>. Provided that such challenges are addressed, many algorithms for the processing of the positive amplification curves are available.</p>
<p>Most software packages do not make a classification if an amplification curve. For example, a classification could be if the amplification curve is negative or positive. An other classification could indicate whether the quality of the amplification curve is poor (much noise) or good (low noise). Specialized software that can distinguish the amplification curves automatically is needed. A classification of amplification curves is needed for later data processing steps. For example, the  method by <span class="citation">J M Ruijter et al. (2009)</span> requires a decision, if an amplification curve is positive or negative. The  package <span class="citation">(Ritz and Spiess 2008)</span> contains an amplification curve test via the <code><a href="http://www.rdocumentation.org/packages/qpcR/topics/modlist">modlist()</a></code> function. The parameter <code>check="uni2"</code> offers an analytical approach, as part of a method for the kinetic outlier detection. It checks for a sigmoid structure of the amplification curve. Then it tests for the location of the first derivative maximum and the second derivative maximum. However, multi-parameter functions fit “successful” in most cases including noise and give false positive results. This will be shown on later sections.</p>
<p>Sometimes it is difficult even for a human expert to classify the amplification curves unambiguously and reproducible. To illustrate this an example for the analysis and classification of the <code>htPCR</code> dataset is given in .</p>
<p>A bottleneck of qPCR data analysis is the lack of features that can be used to build classifiers for amplification curve data. A classifier herein refer to a vector of features that can be used to distinguish the amplification curves by their shape only.</p>
<p>One reason for this is the lack of features that are known for amplification curve data. Only few features for amplification curves are described in the literature. An example example is the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/amptester">amptester()</a></code> function, which is part of the  package <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015)</span>. This function uses static thresholds and frequentist inference to identify amplification curves that exceed the threshold. These are then classified as positive. However, it can also lead to false-positive classifications as exemplified in .</p>
</div>
<div id="principles-of-amplification-curve-data-analysis" class="section level3">
<h3 class="hasAnchor">
<a href="#principles-of-amplification-curve-data-analysis" class="anchor"></a>Principles of Amplification Curve Data Analysis </h3>
<p>The shape of a positive amplification curve follows in most cases a sigmoid shape. The curvature of the amplification curve can be used as a quality measure. For example, fragmentation, inhibitors and sample material handling errors during the extraction can be identified. The kinetic of fluoresce emission is proportional to the quantity of the synthesized DNA. Typical amplification curves have three phases.</p>
<ol style="list-style-type: decimal">
<li>
<em>Ground phase</em>: This phase occurs during the first cycles of the PCR. The fluorescence emission is in most cases flat. During the ground phase, only a weak fluorescence signal is generated that cannot be detected by the sensor system. This is often referred to as baseline or background signal. Fragmentation, inhibitors and sample handling errors would result in a prolonged ground phase. Apparently, there is only a phase shift or no signal at all. This is primarily due to the limited sensitivity of the instrument. Even in a perfect PCR reaction (double amplification per cycle), qPCR instruments cannot detect the fluorescence signal from the amplification. In these early cycles, the fluorescence signals only produce a fluorescence background signal. The PCR product signal is an insignificantly small component of the total signal. Nevertheless, this phase may indicate some typical properties. For example, the increase and signal variation can be characteristic of the qPCR system or probe system. In many instruments, this phase is used to determine the Ct threshold (a statistically relevant increase outside the noise range). A signal that is far enough above this threshold is considered as coming from the amplicon. It is assumed that this early cycle phase is flat in the amplification curve. In some qPCR systems a flat amplification curve is expected in this phase. Slight deviations from this trend are presumed to be due to changes (e. g., disintegration of probes) in the fluorophores. Background correction algorithms are often used here to ensure that flat amplification curves without slope are generated. This can lead to errors and inevitably leads to a loss of information via the waveform of the raw data <span class="citation">(Nolan, Hands, and Bustin 2006)</span>.</li>
<li>
<em>Exponential phase</em>: This phase follows the ground phase and is also called <em>log phase</em>. This phase is characterized by a strong increase of the emitted fluorescence. In this phase, the amount doubles in each cycle under ideal conditions. The amount of the synthesized fluorescent labeled PCR product is high enough to be detected by the sensor system. This phase is used for the calculation of the quantification point (Cq) and for the calculation of the curve specific amplification efficiency. Fragmentation, inhibitors and sample handling errors would decrease the slop of the amplification curve <span class="citation">(Spiess, Feig, and Ritz 2008, <span class="citation">Ritz and Spiess (2008)</span>)</span>.</li>
<li>
<em>Plateau phase</em>: This phase follows the exponential phase. The cause for this lies in the exploitation of the limited resources (incl. primers, nucleotides, enzyme activity) in the reaction vessel. This limits the amplification reaction, so that the theoretical maximum amplification efficiency (doubling per cycle) no longer prevails. This turning point and the progressive limitation of resources finally leads to a plateau. In the plateau phase, there is sometime a signal decrease called <em>hook effect</em> <span class="citation">(Isaac 2009)</span>.</li>
</ol>
<p>If the amplification curve has only a slight positive slope and no perceptible exponential phase, it can be assumed that the amplification reaction did not occur. Causes may include poor specificity of the PCR primers, degraded sample material, degraded probes or detector problems. Such a curve can also occur if non-specific PCR products are created at different points in time. In this case, the superimposed signals can generate such a signal progression. If there is a lot of start DNA (detectable amplification in the first cycles) and the instrument software makes a background correction, amplification curves with a strongly negative trend can be erroneously generated.</p>
<p>Such phases can be roughly considered as regions of interest (ROI). As an example, the  is in the head area, while the  is in the tail area. The  is located between these two ROIs.</p>
<div class="figure">
<img src="PCRedux_files/figure-html/amplification_curve_ROI-1.png" alt="Regions of interest in amplification curves. A) In general, the fluorescence emitted (RFU, relative fluoresce units) by the reporter dye (e.g, SYBR Green, EvaGreen) is plotted against cycle number. The amplification curve data was taken from the `testdat` dataset. More generally, amplification curves can be divided into three regions of interest. These are the ground phase, exponential phase and plateau phase. `top`, takeoff point. `tdp`, takedown point. `sd\_bg` is the standard deviation within the ground phase. The exponential region (red dots) can be used to determine the Cq values and estimates of amplification efficiency. The straight red line is the regression line of a linear model. In principle, after further processing steps (e.g., logarithmic), slopes in this range can be determined. B) PCRs without amplification reaction are usually characterized by a flat (non-sigmoid) signal. C) The exponential phase of PCR reactions may vary considerably. Ideally, the slopes are the same for all reactions. This would be synonymous with the same amplification efficiency in all reactions. However, in practice, amplification curves with different increases are usually found. In particular, amplification curves that become detectable in later cycles often have lower increases." width="768"><p class="caption">
Regions of interest in amplification curves. A) In general, the fluorescence emitted (RFU, relative fluoresce units) by the reporter dye (e.g, SYBR Green, EvaGreen) is plotted against cycle number. The amplification curve data was taken from the <code>testdat</code> dataset. More generally, amplification curves can be divided into three regions of interest. These are the ground phase, exponential phase and plateau phase. <code>top</code>, takeoff point. <code>tdp</code>, takedown point. <code>sd\_bg</code> is the standard deviation within the ground phase. The exponential region (red dots) can be used to determine the Cq values and estimates of amplification efficiency. The straight red line is the regression line of a linear model. In principle, after further processing steps (e.g., logarithmic), slopes in this range can be determined. B) PCRs without amplification reaction are usually characterized by a flat (non-sigmoid) signal. C) The exponential phase of PCR reactions may vary considerably. Ideally, the slopes are the same for all reactions. This would be synonymous with the same amplification efficiency in all reactions. However, in practice, amplification curves with different increases are usually found. In particular, amplification curves that become detectable in later cycles often have lower increases.
</p>
</div>
<p>Numerous qPCR systems do not display the raw data of the amplification curves on the screen. Instead, the raw data is usually processed by the instrument software to remove fluorophore-specific effects and background noise. The ordinate often does not display absolute fluorescence, but rather the change in fluorescence per cycle. Smoothing algorithms may also have been used <span class="citation">(Spiess et al. 2015)</span>. When using the  package, it is therefore advisable to clarify beforehand, which processing steps the amplification curves have been subjected to until data export. Failure to do so may result in misinterpretations and incorrect models <span class="citation">(Nolan, Hands, and Bustin 2006, <span class="citation">Rödiger et al. (2015)</span>, <span class="citation">Rödiger, Burdukiewicz, and Schierack (2015)</span>, <span class="citation">Spiess et al. (2015)</span>)</span>.</p>
<p>The most important measurement from qPCRs is the cycle of quantification (Cq), which signifies at which PCR cycle the fluorescence exceeds a <code>threshold value</code>. There is an ongoing debate as to what a significant and robust threshold value is since there are several mathematical methods to calculate the Cq. The classical threshold value (cycle threshold, Ct) is a straight horizontal line, which intersects with the quasi-linear phase in the exponential amplification phase of the PCR. Another Cq method uses the maximum of second derivative (SDM) <span class="citation">(Rödiger et al. 2015)</span>.  illustrates the calculation of Cq values and Ct values. The threshold based method is claimed to be a simple yet effective approach. This method requires that amplification curves are properly base-lined prior to the analysis. This is not always desirable. An overview and performance comparison is given in <span class="citation">Jan M. Ruijter et al. (2013)</span>.</p>
<div class="figure">
<img src="PCRedux_files/figure-html/figure_quntifcation_points-1.png" alt="Commonly used methods for the analysis of quantification points. A) Linear plot of an amplification curve with a typical sigmoid shape. The Grey horizontal line is the threshold as determined by the \textit{68-95-99.7 rule} from the fluoresce emission of cycle 1 to 10. The black horizontal line is the user defined threshold in the log-linear range of the amplification curve. The Ct is calculated from the intersection of the horizontal line and a quadratic polynomial fitted in to the amplification curve (see @roediger2015chippcr for details). B) The Amplification curve plot with a logarithmic ordinate visualizes the linear phase. C) Analysis of the amplification curve by fitting with a five parameter model (black line) (\autoref{l5}). The red line is the first derivative of the amplification curve, with the maximum at 17.59 cycles. The maximum is used in selected system as Cq value and referred to as first derivative maximum (`cpD1`). The green line is the derivative of the amplification curve, with the maximum at 15.68 cycles a minimum approximately at 19.5 cycles. The maximum is used in selected system as Cq value and referred to as second derivative maximum (`cpD2`). The blue line is the amplification efficiency that is estimated from the trajactory of the exponential region. The `Eff` value 1.795 means that the amplification efficiency is approximately 89%. `cpDdiff` is the difference between the Cq values calculated from the first and the second derivative maximum ($cpDdiff = |cpD1 - cpD2|$) from the fitted model." width="768"><p class="caption">
Commonly used methods for the analysis of quantification points. A) Linear plot of an amplification curve with a typical sigmoid shape. The Grey horizontal line is the threshold as determined by the  from the fluoresce emission of cycle 1 to 10. The black horizontal line is the user defined threshold in the log-linear range of the amplification curve. The Ct is calculated from the intersection of the horizontal line and a quadratic polynomial fitted in to the amplification curve (see <span class="citation">Rödiger, Burdukiewicz, and Schierack (2015)</span> for details). B) The Amplification curve plot with a logarithmic ordinate visualizes the linear phase. C) Analysis of the amplification curve by fitting with a five parameter model (black line) (). The red line is the first derivative of the amplification curve, with the maximum at 17.59 cycles. The maximum is used in selected system as Cq value and referred to as first derivative maximum (<code>cpD1</code>). The green line is the derivative of the amplification curve, with the maximum at 15.68 cycles a minimum approximately at 19.5 cycles. The maximum is used in selected system as Cq value and referred to as second derivative maximum (<code>cpD2</code>). The blue line is the amplification efficiency that is estimated from the trajactory of the exponential region. The <code>Eff</code> value 1.795 means that the amplification efficiency is approximately 89%. <code>cpDdiff</code> is the difference between the Cq values calculated from the first and the second derivative maximum (<span class="math inline">\(cpDdiff = |cpD1 - cpD2|\)</span>) from the fitted model.
</p>
</div>
<p>In all cases the Cq value can be used to calculate the concentration of target sequence in a sample (low Cq high target concentration). In contrast, negative or ambiguous amplification curves loosely resemble noise. This noise may appear linear or exhibit a curvature (). Many factors, such as the sample quality, qPCR chemistry, and technical problems (e. g., sensor errors) contribute to various curve shapes. A common phenomenon of amplification curve shapes is the ‘hook effect’ <span class="citation">(Barratt and Mackay 2002, <span class="citation">Jan M. Ruijter et al. (2014)</span>)</span>. This however, may result in faulty interpretation of the amplification curves.</p>
<div class="figure">
<img src="PCRedux_files/figure-html/amplification_curve_shapes-1.png" alt="Amplification curves of the `RAS002` dataset. All amplification curves of the `RAS002` dataset were manually classified (`negative`,`positive`). A) The negative amplification curves have no sigmoid curve progression. Two groups with different signal levels form the amplification curves. B) All positive amplification curves have a sigmoid curve shape and a similar ground signal. C) The density function of the RFU values from the first 15 PCR cycles shows a bimodal distribution. Based on these data, it is easy to divide them into two groups. Both groups' density functions appear to be symmetrical. D) The density function from the RFU values of the first 15 PCR cycles shows a monomodal distribution. It seems that the density function of the RFU values is left-skewed." width="700"><p class="caption">
Amplification curves of the <code>RAS002</code> dataset. All amplification curves of the <code>RAS002</code> dataset were manually classified (<code>negative</code>,<code>positive</code>). A) The negative amplification curves have no sigmoid curve progression. Two groups with different signal levels form the amplification curves. B) All positive amplification curves have a sigmoid curve shape and a similar ground signal. C) The density function of the RFU values from the first 15 PCR cycles shows a bimodal distribution. Based on these data, it is easy to divide them into two groups. Both groups’ density functions appear to be symmetrical. D) The density function from the RFU values of the first 15 PCR cycles shows a monomodal distribution. It seems that the density function of the RFU values is left-skewed.
</p>
</div>
<p>This means that the amplification curve shape, the amplification efficiency and the Cq value are prerequisites to judge the outcome of a qPCR reaction. In all phases of PCR the curves should be smooth. Possible peaks in the curves may be due to unstable light sources from the instrument or problems during sample preparation, such as the presence of bubbles in the reaction vessel.</p>
<p>An important step in the qPCR workflow is data analysis. Progress has been made in qPCR data analysis, primarily due to the availability of sophisticated data analysis pipelines and software packages (e. g., <span class="citation">Jan M. Ruijter et al. (2013)</span>, <span class="citation">Jan M. Ruijter et al. (2015)</span>, <span class="citation">Rödiger et al. (2015)</span>, <span class="citation">Spiess et al. (2015)</span>, <span class="citation">Spiess et al. (2016)</span>). At this stage amplification curve <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015)</span> and melting curve pre-processing <span class="citation">(Rödiger, Böhm, and Schimke 2013)</span> needs to be performed to continue next with the feature extraction from the curvatures. Several studies have been done, which discuss the pre-processing and post-processing of qPCR data <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015, <span class="citation">Spiess et al. (2015)</span>, <span class="citation">Spiess et al. (2016)</span>)</span>. In this work the focus is on amplification curve data. Amplification curves can be difficult to interpret and analyze if the curvature deviates from the ideal sigmoid shape, or the volume of curve data is to large for an economic manual analysis. Moreover, amplification curves may look acceptable for an inexperienced use but unacceptable for an expert. Therefore, there is a need for method of statistical interrogation and objective interpretation of results.</p>
<p>The quantification of nucleic acids by curve parameters like the quantification point (Cq) and the amplification efficiency (AE) is only meaningful if the kinetic of the amplification curve follows a sigmoid structure according to the model the qPCR <span class="citation">(Jan M. Ruijter et al. 2013, <span class="citation">Jan M. Ruijter et al. (2014)</span>, <span class="citation">Ritz and Spiess (2008)</span>)</span>. In qPCRs is sigmoid shape is characterized by a baseline region, an exponential region and a (maximum) plateau phase. The magnitude of the raw fluorescence and the shape of the amplification curve vary naturally between detection probe systems and devices. Therefore, it is challenging identifying negative curves which appear to be positive but just an artifact of scaling.</p>
<p>Most assays have an intrinsic property, which can be used to decide if an amplification reaction is positive, negative or ambiguous. Melting curve analysis belongs to the commonly used approaches <span class="citation">(Rödiger, Böhm, and Schimke 2013)</span>. For example qPCRs monitored with unspecific dyes (e. g., EvaGreen) use melting curve analysis is a post-processing method to identify PCR reactions which contain DNA (positive). Some detection probe systems like hydrolysis probes do not permit such methods.</p>
<p>A typical situation is that results samples may positive, negative or ambiguous. The later are most problematic because both outcomes (positive and negative) might be true. However, in most cases the user is interested in an automatic distinction between positive and negative samples. This is import in screening applications.</p>
<p>Provided that the rules are strict and transparent, such a routine can be used for quality management. This is also in conformance with the philosophy that software in research and diagnostics should be a foundation for reproducible research <span class="citation">(Rödiger et al. 2015)</span>.</p>
<p>The Ct method appears to be the most widely used method despite the fact that this method was shown to be unreliable <span class="citation">(Jan M. Ruijter et al. 2013, <span class="citation">Spiess et al. (2015)</span>, <span class="citation">Spiess et al. (2016)</span>)</span>. Presumably this due to the familiarity of users with this approach since it is also known from chemical analysis procedures or basic calculus. Another reason might be that the Ct method is easy to implement and to understand.</p>
<p>This kind of calculation strongly dependents on the user, who has to adjust the threshold level manually. Thus, the Ct method is not stable in predictions if several users are given the same dataset to be analyzed. Moreover, the Ct method makes the assumption that the amplification efficiency (~ slope in the log-linear phase) is equal across all amplification curves compared <span class="citation">(Jan M. Ruijter et al. 2013)</span>. Evidently, this is not always case as exemplified in C.</p>
<p>Another approach is to use non-linear model to fit the amplification curve. For example, five-parameter Richardson functions (, <span class="citation">Richards (1959)</span>) are often used <span class="citation">(Spiess et al. 2015)</span>.</p>
<blockquote>
<p><strong>A comment on noise in sigmoid amplification curves</strong>: Noise in amplification curves can have very different causes. Among them are incorrectly assigned dye detectors, errors during the calibration of dyes for the instrument, errors during the preparation of the PCR master mix, sample degradation, lack of a sample in the PCR, too much sample material in the PCR mix or a low detection probe concentration.</p>
</blockquote>

</div>
</div>
<div id="development-implementation-and-installation" class="section level2">
<h2 class="hasAnchor">
<a href="#development-implementation-and-installation" class="anchor"></a>Development, Implementation and Installation </h2>
<p> is an open source software package for the statistical computing language . This software is published under the terms of the <a href="https://opensource.org/licenses/MIT">MIT license</a>.  contains function for the calculation of features from amplification curves and classified datasets for machine learning applications.</p>
<p>Reproducibility is a foundation of research. All technical and experimental aspects should be performed under principles that follow good practices of reproducible research. Numerous authors addressed the matter for experimental design and data report. Examples are the <em>Minimum Information for Publication of Quantitative PCR Experiments</em> guidelines (MIQE) and the <em>Real-time PCR Data Markup Language</em> (RDML). MIQE is a recommended standard of the minimum information for publication of quantitative real-time PCR experiments guidelines and RDML is a data exchange format <span class="citation">(S. A. Bustin 2014, <span class="citation">S. Bustin (2017)</span>, <span class="citation">Rödiger et al. (2015)</span>, <span class="citation">Rödiger et al. (2017)</span>, <span class="citation">Wilson et al. (2017)</span>)</span>. Both MIQE and RDML, are widely used to preform quantitative real-time PCRs <span class="citation">(Pabinger et al. 2014)</span>.</p>
<p>The development of scientific software is a complex process. In particular, if the development is carried out by teams who work in different time zones and where no face-to-face meetings a possible. End users need releases with stable software that delivers reproducible results. Developers need well documented software the adopt the software according to their needs.</p>
<p>Under the umbrella  and , several principles were proposed to deliver high quality software, which meet the needs of end users and developers. This includes version control, collaborative editing, unit testing and continuous integration<span class="citation">(Lanubile et al. 2010, <span class="citation">Myers et al. (2004)</span>, <span class="citation">Rödiger et al. (2015)</span>)</span>. The following paragraphs describe methods implemented in the PCRedux package to ensure high software quality.</p>
<div id="version-control-and-continuous-integration" class="section level3">
<h3 class="hasAnchor">
<a href="#version-control-and-continuous-integration" class="anchor"></a>Version Control and Continuous Integration </h3>
<p>The development of the  package started 2017 with the submission of a functional, yet immature source code, to GitHub (GitHub, Inc.). GitHub is a web-based version control repository hosting service. Both distributed version control and source code management are based on Git. <span class="citation">(Lanubile et al. 2010)</span>. Additional functionality of GitHub includes the administration of access management, bug tracking, moderation of feature requests, task management, some metrics for the software development, and wikis. The source code of  is available at:</p>
<blockquote>

</blockquote>
<p>In continuous integration development team members commit and integrate their contributions several times a day. Team members may include coders, artists and translators. An automated build and test system verifies each integration and gives the development team members a timely feedback about the effect of their commit. In contrast to deferred integration leads this to a reduced number of integration problems and less workload because most erros are solved shortly after they were integrated <span class="citation">(Myers et al. 2004)</span>.</p>
<p>TrivsCI was chosen as continues integration service for . The TravisCI server communicates with the GitHub version control system and manages the  package building process. Currently the continuous interaction is available for the  releases ,  and . The history of the build tests are available at</p>
<blockquote>

</blockquote>
</div>
<div id="naming-convention-and-literate-programming" class="section level3">
<h3 class="hasAnchor">
<a href="#naming-convention-and-literate-programming" class="anchor"></a>Naming Convention and Literate Programming </h3>
<p>The  software is provided as an  (<span class="math inline">\(\geq\)</span> v. 3.3.3) package.  is written as  object system.  has characteristics of object orientated programming but eases the development due to the use of the naming conventions <span class="citation">(Brito 2008)</span>. In most places function and parameter names are written as underscore separated (underscore<span class="math inline">\(\_\)</span>sep), which is a widely used style in  packages <span class="citation">(Bååth 2012)</span>. This convention had to be violated in coding sections where functionality from other packages was used.</p>
<p>Literate programming, as proposed by <span class="citation">Knuth (1984)</span>, is a concept where the logic of the source code and documentation is integrated in a single file. Markup conventions (e. g., ‘#’) tell in literate programming how to typeset the documentation. This produces outputs in a typesetting language such as the lightweight markup language <strong>Markdown</strong>, or the document preparation system .</p>
<p>The ,  and  packages were used to write the documentation in-line with code for the  package.</p>
</div>
<div id="installation-of-the-package" class="section level3">
<h3 class="hasAnchor">
<a href="#installation-of-the-package" class="anchor"></a>Installation of the  Package </h3>
<p>The development version of the package can be installed using the The developer version of the package can be installed using the  package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Install devtools, if not already installed.</span>
<span class="kw">install.packages</span>(<span class="st">"devtools"</span>)

<span class="kw">library</span>(devtools)
<span class="kw"><a href="http://www.rdocumentation.org/packages/devtools/topics/install_github">install_github</a></span>(<span class="st">"devSJR/PCRedux"</span>)</code></pre></div>
<p> is available as stable version from the omprehensive  rchive etwork (CRAN) at . Package published at CRAN undergo intensive checking procedures. In addition, CRAN tests whether the package can be built for common operating systems and whether all version dependencies are solved. To install  first install  (<span class="math inline">\(\geq\)</span> v. 3.3.3). Then start  and type in the prompt:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Select your local mirror</span>
<span class="kw">install.packages</span>(<span class="st">"PCRedux"</span>)</code></pre></div>
<p>The  package should just install. If this fails make sure you that write access is permitted to the destination directory.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The following command points to the help for download and install of packages</span>
<span class="co"># from CRAN-like repositories or from local files.</span>
?<span class="kw">install.packages</span>()</code></pre></div>
<p>If this fails try to follow the instructions given by <span class="citation">De Vries and Meys (2012)</span>.</p>
<blockquote>
<p>R CMD check</p>
</blockquote>
<p>Results from CRAN check can be found at</p>
<blockquote>
<p>.</p>
</blockquote>
</div>
<div id="unit-testing-of-the-package" class="section level3">
<h3 class="hasAnchor">
<a href="#unit-testing-of-the-package" class="anchor"></a>Unit Testing of the  Package </h3>
<p>Modules testing, better known as unit testing, is an approach to simplify the refactoring of source code during software development. The goal is to minimize errors and regressions. It is also intended to ensure that the numerical results from the calculations are reproducible and of high quality. An unintended behavior of the software should be detected at the latest during the package building process. Please note that Unit Testing is not a guarantee for error-free software <span class="citation">(Myers et al. 2004)</span>.</p>
<p>The basic concept is to use checkpoints to check whether the software performs calculations and data transformations correctly for all builds. For this, numerous (logical) queries have to be defined by the developer in advance. They are refereed to . It should be ensured that as many errors as possible are covered. A logical query can be, for example, whether the calculation has a numeric or Boolean value as output. If the data type is incorrect during output, this is a sufficient termination criterion. Or it can be checked whether the length of the result vector is correct after the calculation. There are different approaches for unit tests in . This also includes testing of units from the packages , ,  and . (<span class="citation">Wickham (2011)</span>).</p>
<p>The package  was used in  because it could be well implemented and its maintenance is relatively simple. The logic is that an  defines how the result, class or error in the corresponding unit (e. g., function) should behave. Unit tests can be found in the <code>/test/testthat</code> subdirectory of the  package. The unit tests always run automatically during the creation of the package. The following is an example of the function <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code>. The details of how <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code> works are detailed in the  section. The function <code>test_that()</code>, from the  package, is given several . The <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code> function when processing the amplification curves check whether:</p>
<ul>
<li>an object of the class <em>fdata</em> is created (see <span class="citation">Febrero-Bande and Oviedo de la Fuente (2012)</span> for details of the class <em>fdata</em>),</li>
<li>the parameter <code>rangeval</code> has a length of two,</li>
<li>is the second value of parameter <code>rangeval</code> 49 (last cycle number) and *whether the object structure of the function <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code> does not change if the parameter <code>preprocess=TRUE</code> is set.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PCRedux)

<span class="kw">context</span>(<span class="st">"qPCR2fdata"</span>)

<span class="kw">test_that</span>(<span class="st">"qPCR2fdata gives the correct dimensions and properties"</span>, {
  <span class="kw">library</span>(qpcR)
  res_fdata &lt;-<span class="st"> </span><span class="kw"><a href="../reference/qPCR2fdata.html">qPCR2fdata</a></span>(testdat)
  res_fdata_preprocess &lt;-<span class="st"> </span><span class="kw"><a href="../reference/qPCR2fdata.html">qPCR2fdata</a></span>(testdat, <span class="dt">preprocess =</span> <span class="ot">TRUE</span>)

  <span class="kw">expect_that</span>(res_fdata, <span class="kw">is_a</span>(<span class="st">"fdata"</span>))
  <span class="kw">expect_that</span>(<span class="kw">length</span>(res_fdata<span class="op">$</span>rangeval) <span class="op">==</span><span class="st"> </span><span class="dv">2</span> <span class="op">&amp;&amp;</span>
<span class="st">    </span>res_fdata<span class="op">$</span>rangeval[<span class="dv">2</span>] <span class="op">==</span><span class="st"> </span><span class="dv">49</span>, <span class="kw">is_true</span>())

  <span class="kw">expect_that</span>(res_fdata_preprocess, <span class="kw">is_a</span>(<span class="st">"fdata"</span>))
  <span class="kw">expect_that</span>(<span class="kw">length</span>(res_fdata_preprocess<span class="op">$</span>rangeval) <span class="op">==</span><span class="st"> </span><span class="dv">2</span> <span class="op">&amp;&amp;</span>
<span class="st">    </span>res_fdata_preprocess<span class="op">$</span>rangeval[<span class="dv">2</span>] <span class="op">==</span><span class="st"> </span><span class="dv">49</span>, <span class="kw">is_true</span>())
})</code></pre></div>
<p>Similar unit tests were implemented for all functions of the  package. The coverage by  package can be calculated by the <code>package_coverage()</code> function from the  package or visual analyzed at</p>
<blockquote>
<p>.</p>
</blockquote>

</div>
</div>
<div id="technologies-for-amplification-curve-classification-and-classified-amplification-curves" class="section level2">
<h2 class="hasAnchor">
<a href="#technologies-for-amplification-curve-classification-and-classified-amplification-curves" class="anchor"></a>Technologies for Amplification Curve Classification and Classified Amplification Curves</h2>
<p>An extensive literature research showed that in the field of qPCR there are no openly accessible datasets. Open Data is meant in the sense that data are freely available, free of charge, free to use and that data can be republished, without restrictions from copyright, patents or other mechanisms of control <span class="citation">(Kitchin 2014)</span>. Furthermore, only a few attributes of amplification curves are discussed among peers. These include:</p>
<ul>
<li>the signal height and the slope in the baseline region (gradient and intersection),</li>
<li>the starting point of amplification,</li>
<li>the Cq value and amplification efficiency, and</li>
<li>the signal level including the slope of the plateau phase (slope, intercept).</li>
</ul>
<p>However, these alone are presumably not enough to describe amplification curves sufficiently. Furthermore, there are no references to further algorithms that can be used to calculate additional features from amplification curves. All these facts make further studies on machine learning and modeling difficult. A feature can be described as an entity that characterizes an object. The number of features should be large enough to describe the object accurately and small enough not to interfere with the learning process with redundant or information.</p>
<p>Bellman coined the so-called <em>Curse of Dimensionality</em> in 1961, when he dealt with adaptive control processes. It vague describes the practical difficulties encountered in high-dimensional analysis and estimation. It states that for a given sample size, there is a maximum number of features from which the performance of an algorithm degrades rather than improves. As a consequence, many data mining algorithms fail when the dimensionality is high, because the data points are sparsely populated and far apart <span class="citation">(Herrera et al. 2016)</span>.</p>
<p>Therefore, a large number of records with amplification curves and their classification (negative, ambiguous, positive) were included in the  package. Another objective was the development of new algorithms and the transfer of algorithms from other domains (e. g., from digital image processing) to qPCR datasets. A central goal was therefore to develop attributes to enable the classification of amplification curves in categories such as positive, negative and ambiguous.</p>
<div id="classified-amplification-curves" class="section level3">
<h3 class="hasAnchor">
<a href="#classified-amplification-curves" class="anchor"></a>Classified Amplification Curves</h3>
<p>It is worth noting that the classifications of amplification curves in  were made on the basis of empirical values. For the amplification curves, only an assessment was made to see if the curves are approximately sigmoid or resemble a negative amplification reaction with a flat curve shape. Consequently, this does not answer the question of if a specific amplification product has been synthesized, if a contamination has been amplified or if only primer-dimers have been amplified. To answer this question, other methods such as melting curve analysis should be used.</p>
<p>Amplification curves from different sources had to be classified manually. Amplification curves from the , ,  and  packages were classified with the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/humanrater">humanrater()</a></code>, as described in <span class="citation">Rödiger, Burdukiewicz, and Schierack (2015)</span> and with the <code><a href="../reference/tReem.html">tReem()</a></code> function from the  package. The  describes approaches that can be used to classify amplification curves.</p>
<p>Data preparation is an important step, that includes data cleansing, data transformation and data integration <span class="citation">(Herrera et al. 2016)</span>. The  package <span class="citation">(Seibelt 2017)</span> can used to analyze the distribution form and variables in records for anomalies such as missing values, zeros, infinite values and their categories. The <code>anomalies()</code> function from the  package can be used to search for anomalies (including missing values (NA), zero values (Zero), blank strings (Blank) and infinite numbers (Inf)). Users of the  package should use such tools before continuing to work with the records. Although most records in the  package have the same data structure, some records contain missing values or have different dimensions (compare data from ). For example, the dataset <code>C127EGHP</code> spans a matrix of 40 x 66 (35 cycles x observations (65 amplification curves)), while the <code>htPCR</code> dataset comprises a matrix of 35 x 8859.</p>
<p>Raw data were exported as comma separated values from the thermo-cyclers. Some records have been exported from the devices using the  package and transformed into RDML format. A detailed description can be found in <span class="citation">Rödiger et al. (2017)</span>. The Real-time PCR Data Markup Language (RDML) is data exchange format for quantitative Real-Time PCR Experiments. RDML is a human readable file format and is based on XML (eXtensible Markup Language) and was created to enable the exchange of data across different information systems <span class="citation">(Lefever et al. 2009)</span>. The following code section describes the import of an RDML file from the  package. The RDML file contains amplification curve data of a duplex qPCR (HPV 16 &amp; HPV 18) performed in the CFX96 (Bio-Rad).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(RDML)
<span class="co"># Load the RDML package and use its functions to import the amplification curve</span>
<span class="co">#  data</span>
<span class="kw">library</span>(RDML)
filename &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/devtools/topics/system.file">system.file</a></span>(<span class="st">"RAS002.rdml"</span>, <span class="dt">package =</span> <span class="st">"PCRedux"</span>)
raw_data &lt;-<span class="st"> </span>RDML<span class="op">$</span><span class="kw"><a href="http://www.rdocumentation.org/packages/RDML/topics/new-method">new</a></span>(<span class="dt">filename =</span> filename)</code></pre></div>
<p>The further processing of the amplification data took place as described in <span class="citation">Rödiger, Burdukiewicz, and Schierack (2015)</span>, <span class="citation">Rödiger et al. (2015)</span>, <span class="citation">Spiess et al. (2015)</span> and <span class="citation">Spiess et al. (2016)</span>. An introduction to the use of  for the analysis of melting curves ( package, <span class="citation">(Rödiger, Böhm, and Schimke 2013)</span>) and the calculation of Cq values ( package, <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015)</span>) is shown in detail in <span class="citation">Rödiger et al. (2015)</span>. Unless otherwise stated, the Cq values were determined using the second maximum derivative method.</p>

<p>The following example shows the export of the <code>RAS002.rdml</code> file from the RDML format to the csv format.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Export the RDML data from the PCRedux package as the objects RAS002 and RAS003.</span>
<span class="kw">library</span>(RDML)
<span class="kw">library</span>(PCRedux)
<span class="kw">library</span>(magrittr)
<span class="kw">suppressMessages</span>(<span class="kw">library</span>(data.table))

RAS002 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(RDML<span class="op">$</span><span class="kw"><a href="http://www.rdocumentation.org/packages/RDML/topics/new-method">new</a></span>(<span class="kw">paste0</span>(
    <span class="kw">path.package</span>(<span class="st">"PCRedux"</span>),
                                     <span class="st">"/"</span>, <span class="st">"RAS002.rdml"</span>
))<span class="op">$</span><span class="kw"><a href="http://www.rdocumentation.org/packages/RDML/topics/GetFData-function">GetFData</a></span>())

<span class="co"># The obbject RAS002 can be stored in the working directory as CSV file with</span>
<span class="co"># the name RAS002_amp.csv.</span>
<span class="kw">write.csv</span>(RAS002, <span class="st">"RAS002_amp.csv"</span>, <span class="dt">row.names =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p>Selected amplification cure datasets were stored in the RDML format as described in <span class="citation">(Rödiger et al. 2015, <span class="citation">Rödiger et al. (2017)</span>)</span>.</p>
<table class="table">
<thead><tr class="header">
<th>RDML data file</th>
<th>Device</th>
<th>Target gene</th>
<th>Detection chemistry</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>RAS002.rdml</td>
<td>CFX96</td>
<td>HPV16, HPV18, HPRT1</td>
<td>Taqman</td>
</tr>
<tr class="even">
<td>RAS003.rdml</td>
<td>CFX96</td>
<td>HPV16, HPV18, HPRT1</td>
<td>Taqman</td>
</tr>
<tr class="odd">
<td>hookreg.rdml</td>
<td>Bio-Rad</td>
<td>various</td>
<td>Taqman, DNA binding dyes</td>
</tr>
</tbody>
</table>
<p>32HCU: VideoScan (Attomol GmbH), CFX96: Bio-Rad.</p>
<p>Table_human_rated.xlsx</p>
</div>
<div id="graphical-user-interfaces-for-amplification-curve-classification" class="section level3">
<h3 class="hasAnchor">
<a href="#graphical-user-interfaces-for-amplification-curve-classification" class="anchor"></a>Graphical User Interfaces for Amplification Curve Classification</h3>
<p>For machine learning and method validation it was important to classify the amplification curves individually. However, the availability of comprehensively annotated datasets of amplification curves was a bottleneck so far. In <span class="citation">Rödiger, Burdukiewicz, and Schierack (2015)</span> the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/humanrater">humanrater()</a></code> function was introduced. This function was developed to assist the human expert during the classification of amplification curves and melting curves. The human expert has to define classes (e. g., negative (“n”), ambiguous (“a”), positive (“p”)) which get assigned to an amplification curve after expert has entered the class in input mask. All amplification curve datasets listed in  were classified in interactive, semi-blinded sessions. <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/humanrater">humanrater()</a></code> was set to randomly select individual amplification curves. All classifications were done in at least three repeats. The classification of the <code>htPCR</code> dataset (B) was done in total eight times (see ) because most of the amplification curves are neither unequivocal classifiable as positive or negative.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Suppress messages and load the packages for reading the data of the classified</span>
<span class="co"># amplification curves.</span>
<span class="kw">suppressMessages</span>(<span class="kw">library</span>(data.table))
<span class="kw">library</span>(PCRedux)

<span class="co"># Load the decision_res_htPCR.csv dataset from a csv file.</span>
filename &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/devtools/topics/system.file">system.file</a></span>(<span class="st">"decision_res_htPCR.csv"</span>, <span class="dt">package =</span> <span class="st">"PCRedux"</span>)
decision_htPCR &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/fread">fread</a></span>(filename, <span class="dt">data.table =</span> <span class="ot">FALSE</span>)

<span class="co">#</span>
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">4</span>))
<span class="cf">for</span> (i <span class="cf">in</span> 2L<span class="op">:</span><span class="dv">9</span>) {
  data_tmp &lt;-<span class="st"> </span><span class="kw">table</span>(<span class="kw">as.factor</span>(decision_htPCR[, i]))

  <span class="kw">barplot</span>(data_tmp, <span class="dt">col =</span> <span class="kw">adjustcolor</span>(<span class="st">"grey"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.5</span>),
      <span class="dt">xlab =</span> <span class="st">"Class"</span>, <span class="dt">ylab =</span> <span class="st">"Counts"</span>)
  <span class="kw">text</span>(<span class="kw">c</span>(<span class="fl">0.7</span>, <span class="fl">1.9</span>, <span class="fl">3.1</span>), <span class="kw">rep</span>(<span class="kw">quantile</span>(data_tmp, <span class="fl">0.25</span>), <span class="dv">3</span>), data_tmp, <span class="dt">srt =</span> <span class="dv">90</span>)
  <span class="kw">mtext</span>(LETTERS[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>], <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)
}</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/figure_curve_classification-1.png" alt="Classification of amplification curves. The availability of classified amplification curves is an important prerequisite for the development of methods based on monitored learning. Amplification curves (n = 8858) from the `htPCR` dataset (\texttt{qpcR} package) were classified in total eight time at different time points by a human eight times with the classes ambiguous (a), positive (y) or negative (n). The classification is subject to the subjectivity of the human expert, classified with the humanrater() function. Consequently, the amplification curves were selected randomly so that systematic errors in classification should be minimized. With this example, it becomes evident that even with the same dataset, different class assignments can occur. While in the first three rounds (A-C) only a few amplification curves were classified as negative. Their proportion is increased nearly tenfold (D-H) in subsequent classifications." width="700"><p class="caption">
Classification of amplification curves. The availability of classified amplification curves is an important prerequisite for the development of methods based on monitored learning. Amplification curves (n = 8858) from the <code>htPCR</code> dataset ( package) were classified in total eight time at different time points by a human eight times with the classes ambiguous (a), positive (y) or negative (n). The classification is subject to the subjectivity of the human expert, classified with the humanrater() function. Consequently, the amplification curves were selected randomly so that systematic errors in classification should be minimized. With this example, it becomes evident that even with the same dataset, different class assignments can occur. While in the first three rounds (A-C) only a few amplification curves were classified as negative. Their proportion is increased nearly tenfold (D-H) in subsequent classifications.
</p>
</div>
<p>The <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/humanrater">humanrater()</a></code> function<span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015)</span> was developed with the aim that amplification curves are taken individually (randomly) from the datasets and presented by a human expert for classification. On the basis of his or her knowledge, the human expert is then able to undertake a classification. This approach is well suited and has been applied to classify a variety of amplification curves during the development of the  package. This methodological approach can, however, be very time-consuming, depending on the size of the dataset. In addition, this approach can also be tiring for large datasets, especially when the amplification curves are very similar. A high similarity between amplification curves exists, for example, in replicates and negative controls.</p>
<p>In theory, the similarity between the amplification curves can be used to form groups with very similar curves. The amplification curves in the groups can then be classified together in one run. In this way, a higher throughput can be achieved for classification. This approach has not yet been described for the analysis of qPCR data in the literature.</p>
<p>The <code><a href="../reference/tReem.html">tReem()</a></code> function was developed to perform a curve-shape based classification. Two algorithms have been integrated in the <code><a href="../reference/tReem.html">tReem()</a></code> function to quantify the similarity between amplification curves. The interface of the <code><a href="../reference/tReem.html">tReem()</a></code> function is similar to that of the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/humanrater">humanrater()</a></code> function. The function <code><a href="../reference/tReem.html">tReem()</a></code> needs a data structure where the first column contains the qPCR cycles and all other columns contain the amplification curves. After a chain of processing steps, the <code><a href="../reference/tReem.html">tReem()</a></code> function presents the human expert with a series of plots with a single amplification curve (no similarity to other curves) or groups of amplification curves (within a group there is a high similarity). The corresponding classes can then be assigned to the groups of amplification curves by the human expert using an input mask.</p>
<p>In the first method (standard), the correlation coefficients (<em>r</em>) are determined in pairs according to Pearson for all combinations of amplification curves. The correlation calculation is used to describe the strength of the correlation between the two variables in a statistical measure. Consequently, the correlation coefficient <em>r</em> can be regarded as a distance between the amplification curves. <em>r</em> is a dimensionless value and only takes values between -1 and 1. If <em>r = -1</em>, there is a maximum reciprocal relationship. If <em>r = 0</em> there is no correlation between the two variables. If <em>r = 1</em>, there is a maximum rectified correlation.</p>
<p>In the second method, the Hausdorff distance is used to determine the similarity between amplification curves. The Hausdorff distance is the “the maximum of the distances from a point in any of the sets to the nearest point in the other set” <span class="citation">(Rote 1991, <span class="citation">Herrera et al. (2016)</span>)</span>. The amplification curves are converted within the <code><a href="../reference/tReem.html">tReem()</a></code> function using the <code>qPCR2data()</code> function.</p>
<p>Both methods process the distances in the same steps. This involves the calculation of the distance matrix using the Euclidean distances of all distance measures to determine the distance between the lines of the data matrix. This is used to perform a hierarchical cluster analysis. In the last step, the cluster is divided into groups based on a user-defined <em>k</em> value. For example, two groups are created for <em>k = 2</em>. If the amplification curves are very different, a larger <em>k</em> should be used.</p>
<p>As a rule, the grouping of the amplification curves using the Pearson correlation coefficient as a distance measure is faster than the Hausdorff distance. Nevertheless, it is up to the user to find the optimal method for his task.</p>
<p>Ideally, only a few iterations are necessary to complete the classification of a dataset. However, a prerequisite for this is that the amplification curves are similar.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Classify amplification curve data by correlation coefficients (r)</span>
<span class="kw">library</span>(qpcR)
<span class="kw"><a href="../reference/tReem.html">tReem</a></span>(testdat[, <span class="dv">1</span><span class="op">:</span><span class="dv">15</span>], <span class="dt">k =</span> <span class="dv">3</span>)</code></pre></div>

</div>
</div>
<div id="functions-of-the-package" class="section level2">
<h2 class="hasAnchor">
<a href="#functions-of-the-package" class="anchor"></a>Functions of the  Package </h2>
<p>The  package contains functions for analyzing amplification curves. In the following, these are distinguished into helper functions () and analysis functions ().</p>
<p>The helper functions can be used to manually classify amplification curves, convert them into other data formats or to visualize data structures.</p>
<p>The analysis functions are used to calculate specific characteristic values (features) from the amplification curves. For example, these are slopes, turning points and change points.</p>
<div id="helper-functions-of-the-package" class="section level3">
<h3 class="hasAnchor">
<a href="#helper-functions-of-the-package" class="anchor"></a>Helper Functions of the  Package </h3>
<div id="decision_modus---a-function-to-get-a-decision-modus-from-a-vector-of-classes" class="section level4">
<h4 class="hasAnchor">
<a href="#decision_modus---a-function-to-get-a-decision-modus-from-a-vector-of-classes" class="anchor"></a><code><a href="../reference/decision_modus.html">decision_modus()</a></code> - A Function to Get a Decision (Modus) from a Vector of Classes </h4>
<p>Many approaches to machine learning exist. The subject is very rich. One method is supervised machine learning, where the goal is to derive a property from user-defined (classified) training data. Classified training data can be created by one or more individuals. Categories such as negative, ambiguous or positive are assigned depending on the form of the amplification curve, similar to what was described in  and  and on the opinion of the individual(s).</p>
<p>For example, the amplification curves in () were taken from the <code>htPCR</code> dataset (see B). Assuming that the classification of the amplification curves is delegated to different users, it is likely that the amplification curve (P06.W47, ) are considered ambiguous or even positive (positive <span class="math inline">\(\leftrightarrow\)</span> ambivalent) by the users. A classification experiment was carried out for the complete <code>htPCR</code> dataset. For this purpose, the amplification curves were classified at different time points as described in <span class="citation">Rödiger, Burdukiewicz, and Schierack (2015)</span>.</p>
<p> shows from a total of 8858 amplification curves the first 25 lines classified as negative (<em>conformity=TRUE</em>) and the first 25 lines classified as positive. In total, the curves were classified eight times (<code>test.result.1</code> <span class="math inline">\(\ldots\)</span> <code>test.result.8</code>), resulting in a whole of 70864 individually analyzed amplification curves for this dataset. All the raw data is included in the CSV file.</p>

<p>This example shows that the amplification curves have been classified differently in 94.5% of the cases (e. g., line 1 “P01. W01”). While for other amplification curves all classifications were the same (e. g., line 8856 “P95. W94”).</p>
<p>For the systematic statistical analysis of classification datasets, the <code><a href="../reference/decision_modus.html">decision_modus()</a></code> function has been developed. This allows the most common decision (mode) to be determined. This feature is useful if you want to consolidate large collections of different decisions into a single decision.</p>
<p>Observed:“a”, “a”, “a”, “a”, “a”, “n”, “n”, “n” <span class="math inline">\(\rightarrow\)</span> frequencies 5 x “a”, 3 x “n” <span class="math inline">\(\rightarrow\)</span> mode:“a”</p>
<p>Since the class names are known, they only have to be interpreted by the user (e. g., “a”,“n”,“y” -&gt; “ambivalent”,“negative”,“positive”).</p>
<p>The <code><a href="../reference/decision_modus.html">decision_modus()</a></code> function was applied to the record <code>decision_res_htPCR.csv</code> with all classification rounds (columns 2 to 9) and the mode was determined for each amplitude curve.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Use decision_modus() to go through each row of all classification done by</span>
<span class="co"># a human.</span>

dec &lt;-<span class="st"> </span><span class="kw">lapply</span>(1L<span class="op">:</span><span class="kw">nrow</span>(decision_res_htPCR), <span class="cf">function</span>(i) {
  <span class="kw"><a href="../reference/decision_modus.html">decision_modus</a></span>(decision_res_htPCR[i, <span class="dv">2</span><span class="op">:</span><span class="dv">9</span>])
}) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()

<span class="kw">names</span>(dec) &lt;-<span class="st"> </span>decision_res_htPCR[, <span class="dv">1</span>]

<span class="co"># Show statistic of the decisions</span>
<span class="kw">summary</span>(dec)</code></pre></div>
<pre><code>##    a    n    y 
## 1847 4847 3343</code></pre>
<div class="figure">
<img src="PCRedux_files/figure-html/htPCR_nap-1.png" alt="Visual presentation of negative, ambiguous and positive amplification curves. A) Comparison of amplification curves. Examples of a negative (black), ambiguous (red) and positive (green) amplification curve were selected from the `htPCR` dataset (\texttt{qpcR} package, @Ritz2008). The negative amplification curve is not sigmoid and shows a strong positive trend. The ambiguous amplification curve approaches a sigmoid from, but shows a positive slope in the background (cycle 1 $\rightarrow$ 5). The positive amplification curve is sigmoid. It begins in the background phase (cycle 1 $\rightarrow$ 5) with a flat baseline, and shortly thereafter the exponential phase follows (cycle 5 $\rightarrow$ 25) followed by a plateau phase (cycle 26 $\rightarrow$ 35). B) Summary of frequencies of all classes of the `htPCR` record. negative, black; ambiguous, red; positive, green." width="1056"><p class="caption">
Visual presentation of negative, ambiguous and positive amplification curves. A) Comparison of amplification curves. Examples of a negative (black), ambiguous (red) and positive (green) amplification curve were selected from the <code>htPCR</code> dataset ( package, <span class="citation">Ritz and Spiess (2008)</span>). The negative amplification curve is not sigmoid and shows a strong positive trend. The ambiguous amplification curve approaches a sigmoid from, but shows a positive slope in the background (cycle 1 <span class="math inline">\(\rightarrow\)</span> 5). The positive amplification curve is sigmoid. It begins in the background phase (cycle 1 <span class="math inline">\(\rightarrow\)</span> 5) with a flat baseline, and shortly thereafter the exponential phase follows (cycle 5 <span class="math inline">\(\rightarrow\)</span> 25) followed by a plateau phase (cycle 26 <span class="math inline">\(\rightarrow\)</span> 35). B) Summary of frequencies of all classes of the <code>htPCR</code> record. negative, black; ambiguous, red; positive, green.
</p>
</div>
<p>Another usage mode <code><a href="../reference/decision_modus.html">decision_modus()</a></code> function is to set the parameter <code>max_freq=FALSE</code>. That option specifies the number of all classifications.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PCRedux)
<span class="co"># Decisions for observation P01.W06</span>
res_dec_P01.W06 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/decision_modus.html">decision_modus</a></span>(decision_res_htPCR[
  <span class="kw">which</span>(decision_res_htPCR[[<span class="st">"htPCR"</span>]] <span class="op">==</span><span class="st"> "P01.W06"</span>),
  2L<span class="op">:</span><span class="dv">9</span>
], <span class="dt">max_freq =</span> <span class="ot">FALSE</span>)
<span class="kw">print</span>(res_dec_P01.W06)</code></pre></div>
<pre><code>##   variable freq
## 1        a    3
## 2        n    5</code></pre>
<p>This amplification curve <code>P01. W06</code> was classified as a=3 times and as n=5 times. Therefore, the decision would turn into a <code>negative</code> decision.</p>
</div>
<div id="visdat_pcrfit---a-function-to-visualize-the-content-of-data-from-an-analysis-with-the-pcrfit_single-function" class="section level4">
<h4 class="hasAnchor">
<a href="#visdat_pcrfit---a-function-to-visualize-the-content-of-data-from-an-analysis-with-the-pcrfit_single-function" class="anchor"></a><code><a href="../reference/visdat_pcrfit.html">visdat_pcrfit()</a></code> - A Function to Visualize the Content of Data From an Analysis with the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> Function </h4>
<p>In all data science projects it is important to look at a new dataset to gain an insight into what is contained therein and which potential problems might emerge during the further analysis. The <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function uses various algorithms to calculate values that are returned as factors (e. g., adapted model) or numbers (e. g., Cq value). Contrary to what the user expects, it is also possible that the algorithms cannot calculate certain values and that missing values (NA) are output instead. This may occur if the amplification curves have an unusual characteristic. In the analysis of large datasets, this can be a major problem that could be detected in advance.</p>
<p>The <code><a href="../reference/visdat_pcrfit.html">visdat_pcrfit()</a></code> function makes use of the <code>vis_dat</code> function from the  package by <span class="citation">N. Tierney (2017)</span> to create heatmap-like visualizations. The Heatmapt displays each amplification curve line by line and reads from top to bottom. The characteristics are presented column by column. In principle, the structure of the output is the same as for the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function.</p>
<p>The observations “A01”, “A02”, “A04” and “B04” from the <code>C126EG685</code> of the  package were analyzed with the <code><a href="../reference/encu.html">encu()</a></code> function. Finally, the data can be visualized with the <code><a href="../reference/visdat_pcrfit.html">visdat_pcrfit()</a></code> function. In this example the static plot is shown (). It is also possible to run the function interactively by setting the parameter <code>interactive=TRUE</code>. In this case starts an interactive, browser-based charting library that uses ECMA Script. The interactive plot are rendered entirely locally, through a HTML widgets framework</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate curve features of an amplification curve dataset.</span>
<span class="co"># Use the C126EG685 dataset from the chipPCR package and analyze the observations</span>
<span class="co"># A01, A02, A04 and B05.</span>

<span class="kw">library</span>(chipPCR)

res &lt;-<span class="st"> </span><span class="kw"><a href="../reference/encu.html">encu</a></span>(C126EG685[, <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">17</span>)])</code></pre></div>
<pre><code>## N:36, idsize:36, idval1:1, idval22:22
## mm: 1, nn2: 36, N:36, cumksize.size: 36
## N:36, idsize:36, idval1:1, idval22:22
## mm: 1, nn2: 36, N:36, cumksize.size: 36
## N:36, idsize:36, idval1:1, idval22:22
## mm: 1, nn2: 36, N:36, cumksize.size: 36
## N:36, idsize:36, idval1:1, idval22:22
## mm: 1, nn2: 36, N:36, cumksize.size: 36</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Show all results in a plot. Note that the interactive parameter is set to</span>
<span class="co"># FALSE.</span>

<span class="kw"><a href="../reference/visdat_pcrfit.html">visdat_pcrfit</a></span>(res, <span class="dt">type =</span> <span class="st">"all"</span>, <span class="dt">interactive =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/visdat_pcrfit_plot-1.png" alt="Application of ``visdat\_pcrfit()`` for the visualization of the data structure after an analysis by ``pcrfit\_single()``. The amplification curves (A01 = 1, A02 = 2, A04 = 3, B04 = 4) from the `C126EG685` dataset were analyzed with the ``pcrfit\_single()`` function and then visualized with the ``visdat\_pcrfit()`` function. For each observation, the classes (factor, integer, logical, numeric, NA) are presented. For the observations 2 and 4 the parameter `loglin\_slope` could not be calculated (returned NA)." width="700"><p class="caption">
Application of <code>visdat\_pcrfit()</code> for the visualization of the data structure after an analysis by <code>pcrfit\_single()</code>. The amplification curves (A01 = 1, A02 = 2, A04 = 3, B04 = 4) from the <code>C126EG685</code> dataset were analyzed with the <code>pcrfit\_single()</code> function and then visualized with the <code>visdat\_pcrfit()</code> function. For each observation, the classes (factor, integer, logical, numeric, NA) are presented. For the observations 2 and 4 the parameter <code>loglin\_slope</code> could not be calculated (returned NA).
</p>
</div>
</div>
<div id="performer---performance-analysis-for-binary-classification" class="section level4">
<h4 class="hasAnchor">
<a href="#performer---performance-analysis-for-binary-classification" class="anchor"></a><code><a href="../reference/performeR.html">performeR()</a></code> - Performance Analysis for Binary Classification </h4>
<p>Statistical modeling and machine learning can be powerful but expose a risk to the user by introducing an unexpected bias. This may lead to an overestimation of the performance. The assessment of the performance by the sensitivity and specificity is fundamental to characterize the performance of a classifier or screening test <span class="citation">(G. James et al. 2013)</span>. Sensitivity is the percentage of true decisions that are identified and specificity is the percentage of negative decision that are correctly identified.</p>
<p>An example for the application of the <code><a href="../reference/performeR.html">performeR()</a></code> function is shown in .</p>
<p>Abbreviations: TP, true positive; FP, false positive; TN, true negative; FN, false negative</p>
<table class="table">
<colgroup>
<col width="47%">
<col width="52%">
</colgroup>
<thead><tr class="header">
<th>Measure</th>
<th>Formula</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Sensitivity - TPR, true positive rate</td>
<td><span class="math inline">\(TPR=\frac{TP}{TP + FN}\)</span></td>
</tr>
<tr class="even">
<td>Specificity - SPC, true negative rate</td>
<td><span class="math inline">\(SPC=\frac{TN}{TN + FP}\)</span></td>
</tr>
<tr class="odd">
<td>Precision - PPV, positive predictive value</td>
<td><span class="math inline">\(PPV=\frac{TP}{TP + FP}\)</span></td>
</tr>
<tr class="even">
<td>Negative predictive value - NPV</td>
<td><span class="math inline">\(NPV=\frac{TN}{TN + FN}\)</span></td>
</tr>
<tr class="odd">
<td>Fall-out, FPR, false positive rate</td>
<td><span class="math inline">\(FPR=\frac{FP}{FP + TN}=1 - SPC\)</span></td>
</tr>
<tr class="even">
<td>False negative rate - FNR</td>
<td><span class="math inline">\(FNR=\frac{FN}{TN + FN}=1 - TPR\)</span></td>
</tr>
<tr class="odd">
<td>False discovery rate - FDR</td>
<td><span class="math inline">\(FDR=\frac{FP}{TP + FP}=1 - PPV\)</span></td>
</tr>
<tr class="even">
<td>Accuracy - ACC</td>
<td><span class="math inline">\(ACC= \frac{(TP + TN)}{(TP + FP + FN + TN)}\)</span></td>
</tr>
<tr class="odd">
<td>F1 score - F1</td>
<td><span class="math inline">\(F1=\frac{2TP}{(2TP + FP + FN)}\)</span></td>
</tr>
<tr class="even">
<td>Matthews correlation coefficient - MCC</td>
<td><span class="math inline">\(MCC=\frac{(TP*TN - FP*FN)}{\sqrt{(TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)}}\)</span></td>
</tr>
<tr class="odd">
<td>Likelihood ratio positive - LRp</td>
<td><span class="math inline">\(LRp=\frac{TPR}{1-SPC}\)</span></td>
</tr>
<tr class="even">
<td>Cohen’’s kappa (binary classification)</td>
<td><span class="math inline">\(\kappa=\frac{p_{0}-p_{c}}{1-p_{0}}\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="qpcr2fdata---a-helper-function-to-convert-amplification-curve-data-to-the-fdata-format" class="section level4">
<h4 class="hasAnchor">
<a href="#qpcr2fdata---a-helper-function-to-convert-amplification-curve-data-to-the-fdata-format" class="anchor"></a><code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code> - A Helper Function to Convert Amplification Curve Data to the <code>fdata</code> Format </h4>
<p><code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code> is a helper function to convert qPCR data to the functional <code>fdata</code> class as published by <span class="citation">Febrero-Bande and Oviedo de la Fuente (2012)</span>. This function prepares the data for further analysis, which includes utilities for functional data analysis. For example, it this can be used to determine the similarity measures between amplification curves shapes by the Hausdorff distance. Similarity herein refers to the difference in spatial location of two  (e. g., amplification curves). Objects with a close distance are presumably more similar. For single objects (e. g., points) one can use a vector distance, such as the Euclidean distance. The Hausdorff distance is an approximation of a shape metrics to define similarity measures between shapes. <span class="citation">(Charpiat, Faugeras, and Keriven 2003)</span>. Several variants of the Hausdorff distance have been described (e. g., Minimal Hausdorff distance, Average Hausdorff distance, -th ranked Hausdorff distance) <span class="citation">(Herrera et al. 2016)</span>.</p>
<p>The <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code> function takes a dataset containing the amplification cycles (first column) and the fluorescence amplitudes (subsequent columns) as input. Noise and missing values may affect the analysis adversely. Therefore, an instance of the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/CPP">CPP()</a></code> function ( package <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015)</span>) was integrated in <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code>. If  in <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code>, then all curves are smoothed (Savitzky-Golay smoother), missing values are imputated and outliers in the ground phase get removed as described in <span class="citation">Rödiger, Burdukiewicz, and Schierack (2015)</span>. The non-smoothed amplification curves (A) have slightly more noise than the smoothed amplification curves (C).</p>
<p>The following example illustrates the usage for the <code>testdat</code> dataset. Hierarchical cluster analysis is widely applied in data analysis. This method uses the elements of a proximity matrix to generate a dendrogram. The dendrogram can can be used to further analyze the clusters. Although there are methods to determine the number of clusters  in the present workflow the number of clusters was determined visually <span class="citation">(Cook and Swayne 2007)</span>.</p>
<p>Since the distance based on the Hausdorff metric was already done the next steps involved the <code>cutree()</code> function from the  package to split the dendrogram into smaller junks. <em>A priori</em> was defined that two classes ( &amp; ) are expected. Therefore, the  parameter was set to =2 in the <code>cutree()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate the Hausdorff distance of the amplification curves</span>
<span class="co"># cluster the curves.</span>
<span class="co"># Load additional packages for data and pipes.</span>
<span class="co"># options(warn = -1)</span>
<span class="kw">library</span>(qpcR)
<span class="kw">library</span>(chipPCR)
<span class="kw">suppressMessages</span>(<span class="kw">library</span>(fda.usc))
<span class="kw">library</span>(magrittr)

<span class="co"># Convert the qPCR dataset to the fdata format</span>
<span class="co"># Use unprocessed data from the testdat dataset</span>
res_fdata &lt;-<span class="st"> </span><span class="kw"><a href="../reference/qPCR2fdata.html">qPCR2fdata</a></span>(testdat)

<span class="co"># Extract column names and create rainbow color to label the data</span>
columnames &lt;-<span class="st"> </span>testdat[<span class="op">-</span><span class="dv">1</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">colnames</span>()
data_colors &lt;-<span class="st"> </span><span class="kw">rainbow</span>(<span class="kw">length</span>(columnames), <span class="dt">alpha =</span> <span class="fl">0.5</span>)

<span class="co"># Calculate the Hausdorff distance (fda.usc) package and plot the distances</span>
<span class="co"># as clustered data.</span>

res_fdata_hclust &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/fda.usc/topics/metric.hausdorff">metric.hausdorff</a></span>(res_fdata)
res_hclust &lt;-<span class="st"> </span><span class="kw">hclust</span>(<span class="kw">as.dist</span>(res_fdata_hclust))

<span class="co"># Cluster of the unprocessed amplification curves</span>
res_cutree &lt;-<span class="st"> </span><span class="kw">cutree</span>(res_hclust, <span class="dt">k =</span> <span class="dv">2</span>)
res_cutree &lt;-<span class="st"> </span><span class="kw">factor</span>(res_cutree)
<span class="kw">levels</span>(res_cutree) &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">y =</span> <span class="st">"1"</span>, <span class="dt">n =</span> <span class="st">"2"</span>)</code></pre></div>
<p>The results of the cluster analysis led two large clusters. A deeper inspection shows that the observations are correctly assigned to a cluster of positive or negative amplification curves. Moreover, the later increase of the fluorescence is reflected in the positive cluster ().</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Plot the converted qPCR data</span>
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))
res_fdata <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">plot</span>(
    ., <span class="dt">xlab =</span> <span class="st">"Cycle"</span>, <span class="dt">ylab =</span> <span class="st">"RFU"</span>, <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">type =</span> <span class="st">"l"</span>,
    <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> data_colors
)
<span class="kw">legend</span>(
    <span class="st">"topleft"</span>, <span class="kw">paste0</span>(<span class="kw">as.character</span>(columnames), <span class="st">": "</span>, res_cutree),
       <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">col =</span> data_colors, <span class="dt">bty =</span> <span class="st">"n"</span>, <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">cex =</span> <span class="fl">0.7</span>
)
<span class="kw">mtext</span>(<span class="st">"A"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)

<span class="kw">plot</span>(res_hclust, <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">xlab =</span> <span class="st">""</span>, <span class="dt">sub=</span><span class="st">""</span>)
<span class="kw">mtext</span>(<span class="st">"B"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)
<span class="kw">rect</span>(<span class="fl">0.5</span>, <span class="fl">-3.5</span>, <span class="fl">12.25</span>, <span class="fl">0.5</span>, <span class="dt">border =</span> <span class="st">"red"</span>)
<span class="kw">text</span>(<span class="dv">7</span>, <span class="dv">1</span>, <span class="st">"negative"</span>, <span class="dt">col =</span> <span class="st">"red"</span>)
<span class="kw">rect</span>(<span class="fl">12.5</span>, <span class="fl">-3.5</span>, <span class="fl">24.5</span>, <span class="fl">0.5</span>, <span class="dt">border =</span> <span class="st">"green"</span>)
<span class="kw">text</span>(<span class="dv">14</span>, <span class="dv">1</span>, <span class="st">"positive"</span>, <span class="dt">col =</span> <span class="st">"green"</span>, <span class="dt">cex =</span> <span class="fl">0.9</span>)</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/qPCR2fdata-1.png" alt="Shape based grouping of amplification curves. Grouping of amplification curves of the `testdat` dataset via Hausdorff distance. A) The amplification curves were converted with the qPCR2fdata() function. B) Subsequent they were processed by a cluster analysis using the Hausdorff distance. Faultless differentiation was achieved between negative amplification curves (n) and positive amplification curves (y)." width="768"><p class="caption">
Shape based grouping of amplification curves. Grouping of amplification curves of the <code>testdat</code> dataset via Hausdorff distance. A) The amplification curves were converted with the qPCR2fdata() function. B) Subsequent they were processed by a cluster analysis using the Hausdorff distance. Faultless differentiation was achieved between negative amplification curves (n) and positive amplification curves (y).
</p>
</div>
<p>Clusters of the amplification curves after an analysis using the Hausdorff distance. The amplification curves of the <code>testdat</code> dataset remained as raw data or were pre-processed (smoothed). Subsequent, the amplification curves were converted by the <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code>. The converted data were subjected to a cluster analysis (Hausdorff distance). All observations were correctly assigned to cluster 1 (positive) or cluster 2 (negative).</p>
<p>This workflow can be used to cluster amplification curve data according to their shape into smaller groups of similar amplification curves. Classification tasks can be preformed in batches of amplification curves. It is worth to mention that the calculation of the distances is a computing expensive step dependent on the number of amplification curves. Other distance metric than the Hausdorff distance should also be considered. For example, <span class="citation">Luo, Lin, and Chao (2010)</span> showed how for image data how shape models using local curve segments with multiple types of distance metrics can improve the shape classification and detection results.</p>
<p>The following example illustrates the usage for the <code>HCU32_aggR.csv</code> dataset from the 32 channel VideoScan heating and cooling unit. In this experiment the bacterial gene <em>aggR</em> from <em>E. coli</em> was amplified in 32 replicate qPCR reactions. Details of the experiment are described in the manual of the  package. The ambition was to test if the 32 amplification curves of the qPCR reaction are identical. As before, the data were processed with the <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code> function and compared by the the Hausdorff distance. Ideally, the amplification curves form only few clusters.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate slope and intercept on positive amplification curve data from the</span>
<span class="co"># VideoScan 32 cavity real-time PCR device.</span>
<span class="co"># Load additional packages for data and pipes.</span>
<span class="co"># options(warn = -1)</span>
<span class="kw">library</span>(data.table)
<span class="kw">library</span>(fda.usc)
<span class="kw">library</span>(magrittr)

<span class="co"># Load the qPCR data from the HCU32_aggR.csv dataset</span>
<span class="co"># Convert the qPCR dataset to the fdata format</span>

filename &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/devtools/topics/system.file">system.file</a></span>(<span class="st">"HCU32_aggR.csv"</span>, <span class="dt">package =</span> <span class="st">"PCRedux"</span>)
data_32HCU &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/fread">fread</a></span>(filename, <span class="dt">data.table =</span> <span class="ot">FALSE</span>)

res_fdata &lt;-<span class="st"> </span><span class="kw"><a href="../reference/qPCR2fdata.html">qPCR2fdata</a></span>(data_32HCU)
<span class="co"># Extract column names and create rainbow color to label the data</span>
columnames &lt;-<span class="st"> </span>data_32HCU[<span class="op">-</span><span class="dv">1</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">colnames</span>()
data_colors &lt;-<span class="st"> </span><span class="kw">rainbow</span>(<span class="kw">length</span>(columnames), <span class="dt">alpha =</span> <span class="fl">0.55</span>)</code></pre></div>
<p>In advance the the Cq values were calculated by the following code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the qpcR package to calculate the Cq values by the second derivative</span>
<span class="co"># maximum method.</span>
<span class="co"># options(warn = -1)</span>
<span class="kw">library</span>(qpcR)

res_Cq &lt;-<span class="st"> </span><span class="kw">sapply</span>(2L<span class="op">:</span><span class="kw">ncol</span>(data_32HCU), <span class="cf">function</span>(i) {
    <span class="kw"><a href="http://www.rdocumentation.org/packages/qpcR/topics/efficiency">efficiency</a></span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/qpcR/topics/pcrfit">pcrfit</a></span>(data_32HCU, <span class="dt">cyc =</span> <span class="dv">1</span>, <span class="dt">fluo =</span> i, <span class="dt">model =</span> l6))
})

<span class="kw">data.frame</span>(
    <span class="dt">obs =</span> <span class="kw">colnames</span>(data_32HCU)[<span class="op">-</span><span class="dv">1</span>],
           <span class="dt">Cq =</span> <span class="kw">unlist</span>(res_Cq[<span class="st">"cpD2"</span>, ]), <span class="dt">eff =</span> <span class="kw">unlist</span>(res_Cq[<span class="st">"eff"</span>, ])
)

<span class="co">#        Results</span>
<span class="co">#</span>
<span class="co"># obs    Cq      eff</span>
<span class="co"># 1      A1 14.89 1.092963</span>
<span class="co"># 2      B1 15.68 1.110480</span>
<span class="co"># 3      C1 15.63 1.111474</span>
<span class="co"># ...</span>
<span class="co"># 30     F4 15.71 1.109634</span>
<span class="co"># 31     G4 15.70 1.110373</span>
<span class="co"># 32     H4 15.73 1.117827</span></code></pre></div>
<p>Next, the amplification curves (A), the differences between baseline region and plateau region (B), the correlation between the Cq value and amplification efficiency (C) and the clusters based on the Hausdorff distance ( were taken into account. In total, 32 real-time PCR reactions for the bacterial gen  were measured in the VideoScan system.</p>
<blockquote>
<p><strong>Note</strong>: The raw data has not been modified to retain all characteristics of the amplification curves.</p>
</blockquote>
<p>Some amplification curves (A) showed stronger fluctuations and therefore no ideal sigmoid curve progression. In addition, it can be seen that the amplification curves in the baseline area have a negative non-linear trend and a shift around the zero point. By contrast, the trend in the plateau region appears to be positive. This is similar to the curve shown in . The comparison of the baseline region and the plateau region showed a difference between the 32 amplification curves. The observations <code>E1</code>, <code>F1</code> and <code>H1</code> had the lowest differences between the baseline and plateau regions. The comparison of Cq values and amplification efficiency showed that most amplification curves exhibit similar behavior. Since there are 32 replicates, the similarity of the Cq values and amplification efficiencies was to be expected. However, there are also amplification curves that show a greater deviation from the median of all Cq values (C). The analysis by clustering of the Hausdorff distance did not yield any specific pattern (D).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(fda.usc)
<span class="kw">library</span>(magrittr)

<span class="co"># To save computing time, the Cq values and amplification efficiencies were </span>
<span class="co"># calculated beforehand and transferred as a hard copy here.</span>

calculated_Cqs &lt;-<span class="st"> </span><span class="kw">c</span>(
    <span class="fl">14.89</span>, <span class="fl">15.68</span>, <span class="fl">15.63</span>, <span class="fl">15.5</span>, <span class="fl">15.54</span>, <span class="fl">15.37</span>, <span class="fl">15.78</span>, <span class="fl">15.24</span>, <span class="fl">15.94</span>,
    <span class="fl">15.88</span>, <span class="fl">15.91</span>, <span class="fl">15.77</span>, <span class="fl">15.78</span>, <span class="fl">15.74</span>, <span class="fl">15.84</span>, <span class="fl">15.78</span>, <span class="fl">15.64</span>, <span class="fl">15.61</span>,
    <span class="fl">15.66</span>, <span class="fl">15.63</span>, <span class="fl">15.77</span>, <span class="fl">15.71</span>, <span class="fl">15.7</span>, <span class="fl">15.79</span>, <span class="fl">15.8</span>, <span class="fl">15.72</span>, <span class="fl">15.7</span>, <span class="fl">15.82</span>,
    <span class="fl">15.62</span>, <span class="fl">15.71</span>, <span class="fl">15.7</span>, <span class="fl">15.73</span>
)

calculated_effs &lt;-<span class="st"> </span><span class="kw">c</span>(
    <span class="fl">1.09296326515231</span>, <span class="fl">1.11047987547324</span>, <span class="fl">1.11147389307153</span>, <span class="fl">1.10308929700635</span>,
    <span class="fl">1.10012176315852</span>, <span class="fl">1.09136717687619</span>, <span class="fl">1.11871308210321</span>, <span class="fl">1.08006168654712</span>,
    <span class="fl">1.09500422011318</span>, <span class="fl">1.1078777171126</span>, <span class="fl">1.11269436700649</span>, <span class="fl">1.10628580163733</span>,
    <span class="fl">1.1082009954558</span>, <span class="fl">1.11069683827291</span>, <span class="fl">1.11074914659374</span>, <span class="fl">1.10722949813473</span>,
    <span class="fl">1.10754282514113</span>, <span class="fl">1.10098387264025</span>, <span class="fl">1.1107026749644</span>, <span class="fl">1.11599641663658</span>,
    <span class="fl">1.11388510347017</span>, <span class="fl">1.11398547396991</span>, <span class="fl">1.09410798249025</span>, <span class="fl">1.12422338092929</span>,
    <span class="fl">1.11977386646464</span>, <span class="fl">1.11212436173214</span>, <span class="fl">1.12145338871426</span>, <span class="fl">1.12180879952503</span>,
    <span class="fl">1.1080276005651</span>, <span class="fl">1.10963449004393</span>, <span class="fl">1.11037302758388</span>, <span class="fl">1.11782689816295</span>
)

<span class="co"># Plot the converted qPCR data</span>
<span class="kw">layout</span>(<span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>), <span class="dv">2</span>, <span class="dv">3</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>))
res_fdata <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">plot</span>(
    ., <span class="dt">xlab =</span> <span class="st">"Cycle"</span>, <span class="dt">ylab =</span> <span class="st">"RFU"</span>, <span class="dt">main =</span> <span class="st">"HCU32_aggR"</span>, <span class="dt">type =</span> <span class="st">"l"</span>,
    <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> data_colors
)
<span class="kw">legend</span>(
    <span class="st">"topleft"</span>, <span class="kw">as.character</span>(columnames), <span class="dt">pch =</span> <span class="dv">19</span>,
       <span class="dt">col =</span> data_colors, <span class="dt">bty =</span> <span class="st">"n"</span>, <span class="dt">ncol =</span> <span class="dv">4</span>
)
<span class="kw">mtext</span>(<span class="st">"A"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)

<span class="co"># Plot the background and plateau phase.</span>

<span class="kw">boxplot</span>(
    data_32HCU[, <span class="dv">-1</span>] <span class="op">-</span><span class="st"> </span><span class="kw">apply</span>(data_32HCU[, <span class="dv">-1</span>], <span class="dv">2</span>, min),
        <span class="dt">col =</span> data_colors, <span class="dt">las =</span> <span class="dv">2</span>, <span class="dt">main =</span> <span class="st">"Signal to noise ratio"</span>,
        <span class="dt">xlab =</span> <span class="st">"Sample"</span>, <span class="dt">ylab =</span> <span class="st">"RFU"</span>
)
<span class="kw">mtext</span>(<span class="st">"B"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)

<span class="co"># Plot the Cqs and the amplification efficiencies.</span>
<span class="co"># Determine the median of the Cq values and label all Cqs, which a less 0.1 Cqs</span>
<span class="co"># of the median or more then 0.1 Cqs of the median Cq.</span>

<span class="kw">plot</span>(
    calculated_Cqs, calculated_effs, <span class="dt">xlab =</span> <span class="st">"Cq (SDM)"</span>,
     <span class="dt">ylab =</span> <span class="st">"eff"</span>, <span class="dt">main =</span> <span class="st">"Cq vs. Amplification Efficiency"</span>,
     <span class="dt">type =</span> <span class="st">"p"</span>, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> data_colors
)

median_Cq &lt;-<span class="st"> </span><span class="kw">median</span>(calculated_Cqs)
<span class="kw">abline</span>(<span class="dt">v =</span> median_Cq)

<span class="kw">text</span>(median_Cq <span class="op">+</span><span class="st"> </span><span class="fl">0.01</span>, <span class="fl">1.085</span>, <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">tilde</span>(x))))
labeled &lt;-<span class="st"> </span><span class="kw">c</span>(
    <span class="kw">which</span>(calculated_Cqs <span class="op">&lt;</span><span class="st"> </span>median_Cq <span class="op">-</span><span class="st"> </span><span class="fl">0.1</span>),
             <span class="kw">which</span>(calculated_Cqs <span class="op">&gt;</span><span class="st"> </span>median_Cq <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span>)
)

<span class="kw">text</span>(
    calculated_Cqs[labeled], calculated_effs[labeled],
     <span class="kw">as.character</span>(columnames)[labeled]
)
<span class="kw">mtext</span>(<span class="st">"C"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)

<span class="co"># Calculate the Hausdorff distance using the fda.usc package and cluster the</span>
<span class="co"># the distances.</span>

res_fdata_hclust &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/fda.usc/topics/metric.hausdorff">metric.hausdorff</a></span>(res_fdata)
cluster &lt;-<span class="st"> </span><span class="kw">hclust</span>(<span class="kw">as.dist</span>(res_fdata_hclust))

<span class="co"># plot the distances as clustered data and label the leafs with the Cq values</span>
<span class="co"># and colored dots.</span>

<span class="kw">plot</span>(cluster, <span class="dt">main =</span> <span class="st">"Clusters of the amplification</span><span class="ch">\n</span>
<span class="st">curves as calculated by the Hausdorff distance"</span>, <span class="dt">xlab =</span> <span class="st">""</span>, <span class="dt">sub=</span><span class="st">""</span>)
<span class="kw">mtext</span>(<span class="st">"D"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/HCU32-1.png" alt="Clustering of amplification curves. The amplification curves from the 32HCU were processed with the ``qPCR2fdata()`` function and subsequent processed by a cluster analysis and Hausdorff distance analysis. A) Amplification curves were plotted from the raw data. B) Overall, the signal to noise ratios of the amplification curves were comparable between all cavities. C) The Cqs (Second Derivative Maximum) and the amplification efficiency (eff) were calculated with the ``efficiency(pcrfit())`` functions from the ``qpcR`` package. The median Cq is indicated as vertical line. Cqs larger or less than 0.1 of the Cq $\tilde{x}$ are indicated with the labels of the corresponding observation. D) The clusters according to the Hausdorff distance show no specific pattern regarding the amplification curve signals. It appears that the observations D1, E1, F1, F3, G3 and H1 deviate most from the other amplification curves." width="1056"><p class="caption">
Clustering of amplification curves. The amplification curves from the 32HCU were processed with the <code><a href="../reference/qPCR2fdata.html">qPCR2fdata()</a></code> function and subsequent processed by a cluster analysis and Hausdorff distance analysis. A) Amplification curves were plotted from the raw data. B) Overall, the signal to noise ratios of the amplification curves were comparable between all cavities. C) The Cqs (Second Derivative Maximum) and the amplification efficiency (eff) were calculated with the <code><a href="http://www.rdocumentation.org/packages/qpcR/topics/efficiency">efficiency(pcrfit())</a></code> functions from the <code>qpcR</code> package. The median Cq is indicated as vertical line. Cqs larger or less than 0.1 of the Cq <span class="math inline">\(\tilde{x}\)</span> are indicated with the labels of the corresponding observation. D) The clusters according to the Hausdorff distance show no specific pattern regarding the amplification curve signals. It appears that the observations D1, E1, F1, F3, G3 and H1 deviate most from the other amplification curves.
</p>
</div>
<p>The analysis gives an overview of the variation of the amplification curve data.</p>

</div>
</div>
<div id="amplification-curve-analysis-functions-of-the-package" class="section level3">
<h3 class="hasAnchor">
<a href="#amplification-curve-analysis-functions-of-the-package" class="anchor"></a>Amplification Curve Analysis Functions of the  package </h3>
<p>There are a number of ROIs (see ) in an amplification curve that are potentially useful for calculating characteristics for the classification of amplification curves. Amplification curves can have unique shapes and deviate from the ideal sigmoid models (compare A and B) of qPCRs. For instance, some amplification curves are only flat or have a rise with positive or negative signs without sigmoid curvature. In the case of sigmoid amplification curves, there are turning points which can be characteristic for positive amplification curves. Such differences are interesting candidates to calculate features for machine learning.</p>
<p>On the basis of this observation, various concepts were developed and implemented in algorithms to describe amplification curves. The intent of <span class="citation">Gunay, Goceri, and Balasubramaniyan (2016)</span> was to improve the determination of the Cq values. They postulated that they can achieve an improved prediction of Cq values using a modified sigmoid function (three parameters). An assumption of their approach is, that this model can be applied to any dataset. There are several reasons why such an assumption is not valid. In the chapters , for example, the functions <code><a href="../reference/hookreg.html">hookreg()</a></code> and <code><a href="../reference/hookregNL.html">hookregNL()</a></code> are briefly displayed. These amplification curves deviate significantly from a three-parameter model.  shows the distribution of models fitted to amplification curves. In most case models with six and seven parameters were automatically selected. In addition, non-linear functions also tend to fit models to noise (). It becomes clear in  that for a considerable proportion of manually negatively classified amplification curves a Cq value could be calculated. A computer-assisted decision would be helpful.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the qpcR package for the model fit.</span>
<span class="kw">suppressMessages</span>(<span class="kw">library</span>(qpcR))
<span class="kw">library</span>(chipPCR)

<span class="co"># Select one positive and one negative amplification curve from the PCRedux </span>
<span class="co"># package.</span>

amp_data &lt;-<span class="st"> </span>PCRedux<span class="op">::</span>RAS002[, <span class="kw">c</span>(<span class="st">"cyc"</span>, <span class="st">"A01_gDNA.._unkn_B.Globin"</span>, 
                                <span class="st">"B07_gDNA.._unkn_HPRT1"</span>)]

<span class="kw">colnames</span>(amp_data) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">"cyc"</span>, <span class="st">"positive"</span>, <span class="st">"negative"</span>)

<span class="co"># Arrange graphs in an matrix and set the plot parameters. An plot the positive</span>
<span class="co"># and negative amplification curve.</span>
hight &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">3100</span>, <span class="dv">4100</span>)

<span class="kw">plot</span>(<span class="ot">NA</span>, <span class="ot">NA</span>, <span class="dt">xlim =</span> <span class="kw">range</span>(amp_data[, <span class="st">"cyc"</span>]), 
        <span class="dt">ylim =</span> <span class="kw">range</span>(amp_data[, <span class="kw">c</span>(<span class="st">"positive"</span>, <span class="st">"negative"</span>)]),
        <span class="dt">xlab =</span> <span class="st">"Cycle"</span>, <span class="dt">ylab =</span> <span class="st">"RFU"</span>, <span class="dt">main =</span> <span class="st">""</span>)

<span class="co"># Apply the the amptester function from the chipPCR package to the amplification </span>
<span class="co"># curve data and write the results to the main of the plots.</span>

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span><span class="dv">3</span>) {
    res.ampt &lt;-<span class="st">  </span><span class="kw">suppressMessages</span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/chipPCR/topics/amptester">amptester</a></span>(amp_data[, i]))
    
    <span class="co"># Make a logical connection by two tests (shap.noisy, lrt.test and</span>
    <span class="co"># tht.dec) of amptester to decide if an amplification reaction is</span>
    <span class="co"># positive or negative.</span>
    decision &lt;-<span class="st"> </span><span class="kw">ifelse</span>(<span class="op">!</span>res.ampt<span class="op">@</span>decisions[<span class="dv">1</span>] <span class="op">&amp;&amp;</span>
<span class="st">    </span>res.ampt<span class="op">@</span>decisions[<span class="dv">2</span>] <span class="op">&amp;&amp;</span>
<span class="st">    </span>res.ampt<span class="op">@</span>decisions[<span class="dv">4</span>],
    <span class="st">"positive"</span>, <span class="st">"negative"</span>
    )
    <span class="co"># The amplification curves were fitted (l7 model) with pcrfit() function. </span>
    <span class="co"># The Cq was determined with the efficiency() function.</span>
    
    fit &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/qpcR/topics/pcrfit">pcrfit</a></span>(<span class="dt">data =</span> amp_data, <span class="dt">cyc =</span> <span class="dv">1</span>, <span class="dt">fluo =</span> i, <span class="dt">model =</span> l7)
    res &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/qpcR/topics/efficiency">efficiency</a></span>(fit, <span class="dt">plot =</span> <span class="ot">FALSE</span>)
    <span class="kw">lines</span>(<span class="kw">predict</span>(fit), <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">xlab =</span> <span class="st">"Cycle"</span>, <span class="dt">ylab =</span> <span class="st">"RFU"</span>, 
          <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">col =</span> i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)
    <span class="kw">abline</span>(<span class="dt">h =</span> res[[<span class="st">"fluo"</span>]], <span class="dt">col =</span> <span class="st">"grey"</span>)
    <span class="kw">points</span>(res[[<span class="st">"cpD2"</span>]], res[[<span class="st">"fluo"</span>]], <span class="dt">pch =</span> <span class="dv">19</span>)

    <span class="kw">legend</span>(<span class="dv">1</span>, hight[i<span class="dv">-1</span>], <span class="kw">paste0</span>(<span class="kw">colnames</span>(amp_data)[i], 
                                 <span class="st">"  curve -&gt;  Decision: "</span>, 
                                 decision, <span class="st">"    Cq: "</span>, res[[<span class="st">"cpD2"</span>]]), <span class="dt">bty =</span> <span class="st">"n"</span>, 
           <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="st">"red"</span>
          )
}</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/curve_fit_fail-1.png" alt="Positive and negative Amplification curves from the `RAS002` dataset. A positive amplification curve (black) and a negative amplification curve (red) were selected from the `RAS002` dataset. The positive amplification curve has a baseline signal of approximately 2500 RFU and shows an unambiguous sigmoidal shape. The negative amplification curve has a baseline signal of approximately 4200 RFU, shows moderately positive slope and has no sigmoidal shape. A logistical function with seven parameters (`l7`) was fitted to both amplification curves. A Cq value of 25.95 was determined using the method of the maximum of the second derivative. The calculated Cq value appears to be correct. The negative amplification curve had a Cq value of 9.41 was calculated. It is clear that the model adaptation is not appropriate to calculate a trustworthy Cq value. If such a calculation would be done automatically, without human interaction, a false-positive result could be interpreted." width="576"><p class="caption">
Positive and negative Amplification curves from the <code>RAS002</code> dataset. A positive amplification curve (black) and a negative amplification curve (red) were selected from the <code>RAS002</code> dataset. The positive amplification curve has a baseline signal of approximately 2500 RFU and shows an unambiguous sigmoidal shape. The negative amplification curve has a baseline signal of approximately 4200 RFU, shows moderately positive slope and has no sigmoidal shape. A logistical function with seven parameters (<code>l7</code>) was fitted to both amplification curves. A Cq value of 25.95 was determined using the method of the maximum of the second derivative. The calculated Cq value appears to be correct. The negative amplification curve had a Cq value of 9.41 was calculated. It is clear that the model adaptation is not appropriate to calculate a trustworthy Cq value. If such a calculation would be done automatically, without human interaction, a false-positive result could be interpreted.
</p>
</div>
<p>Therefore, several characteristics of an amplification curve should be recorded first and then checked for their usefulness. There, it becomes clear that a three-parameter model adaptation can be adapted to noise and thus provides unreliable predictions.</p>
<p>As shown in  have positive amplification curves a typical sigmoid shape, while negative curves resemble random noise.</p>
<p>Many properties (e. g., experiment condition (hydrolysis probe, DNA binding dye)) can be converted to binary classifiers (no == 0, yes == 1). From the amplification curve one can calculate the signal range before and after the amplification process.</p>
<p>Next follows a brief introduction of the feature engineering process of this work. For doing this a set features which characterize amplification curves was needed. In total seven function were generated and integrated in  package. These functions features have not been described before in the literature for the classification of amplification curves.</p>
<p>The function described following are aimed for experimental studies. It is important to note that the features proposed herein emerged during a critical reasoning process. The aim of the package is to propose a set of features, functions and data for an independent research.</p>
<div id="pcrfit_single---a-function-to-calculate-features-from-an-amplification-curve" class="section level4">
<h4 class="hasAnchor">
<a href="#pcrfit_single---a-function-to-calculate-features-from-an-amplification-curve" class="anchor"></a><code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> - A Function to Calculate Features from an Amplification Curve </h4>
<p>The following chapter includes on <strong>exemplary applications</strong> of feature vectors from amplification curves, which can be used for automatic classification by machine learning. The focus is mainly on, the concise description of the algorithms of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function. The underlying hypotheses are formulated and supported by exemplary analysis.</p>
<p>Some algorithms have been implemented as standalone functions (e. g., <code><a href="../reference/earlyreg.html">earlyreg()</a></code>) to make them available for other applications. The goal is not to examine the limits of their applicability, but rather to prove their basic functionality. Based on considerations and experience the algorithms of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function are restricted to ROIs () in order to calculate specific features. In order to bring a systematic into the algorithms, the functions with similar approaches are summarized in groups. Due to the number of algorithms, it is not possible to provide a detailed description with examples in every place.</p>
<p>The following output shows all features and their data type (<code>num</code>, numeric; <code>int</code>, integer; <code>Factor</code>, factor; <code>logi</code>, boolean) which are determined from the second amplification curve of the <code>RAS002</code> dataset with the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PCRedux)
<span class="kw">str</span>(<span class="kw"><a href="../reference/pcrfit_single.html">pcrfit_single</a></span>(RAS002[, <span class="dv">2</span>]))</code></pre></div>
<pre><code>## N:36, idsize:36, idval1:1, idval22:22
## mm: 1, nn2: 36, N:36, cumksize.size: 36
## 'data.frame':    1 obs. of  48 variables:
##  $ cpD1                 : num 28.1
##  $ cpD2                 : num 25.9
##  $ eff                  : num 1.02
##  $ sliwin               : num 1.04
##  $ cpDdiff              : num 2.19
##  $ loglin_slope         : num 0.0343
##  $ cpD2_range           : num 4.48
##  $ top                  : num 25
##  $ f.top                : num 0.748
##  $ tdp                  : num 35
##  $ f.tdp                : num 1.65
##  $ bg.stop              : num 15
##  $ amp.stop             : num 40
##  $ b_slope              : num -13.6
##  $ f_intercept          : num 3.17
##  $ convInfo_iteratons   : int 14
##  $ qPCRmodel            : Factor w/ 1 level "l7": 1
##  $ qPCRmodelRF          : Factor w/ 1 level "l7": 1
##  $ minRFU               : num 0.682
##  $ maxRFU               : num 1
##  $ init2                : num 0.419
##  $ fluo                 : num 0.765
##  $ slope_bg             : num 0.00658
##  $ intercept_bg         : num 0.675
##  $ sd_bg                : num 0.0939
##  $ head2tail_ratio      : num 0.704
##  $ mblrr_slope_pt       : num 0.00586
##  $ mblrr_intercept_bg   : num 0.693
##  $ mblrr_slope_bg       : num 0.00202
##  $ mblrr_cor_bg         : num 0.91
##  $ mblrr_intercept_pt   : num 0.774
##  $ mblrr_cor_pt         : num 0.942
##  $ polyarea             : num 0.0409
##  $ peaks_ratio          : num 0.0117
##  $ autocorellation      : num 0.741
##  $ changepoint_e.agglo  : int 2
##  $ changepoint_bcp      : int 10
##  $ amptester_shapiro    : logi FALSE
##  $ amptester_lrt        : logi TRUE
##  $ amptester_rgt        : logi TRUE
##  $ amptester_tht        : logi TRUE
##  $ amptester_slt        : logi TRUE
##  $ amptester_polygon    : num 1.55
##  $ amptester_slope.ratio: num 0
##  $ hookreg_hook         : num 0
##  $ hookreg_hook_slope   : num 0
##  $ hookreg_hook_delta   : num 0
##  $ number_of_cycles     : int 40</code></pre>
<p>To underscore the usability of the algorithms and their features, 3302 observations (471 negative amplification curves, 2831 positive amplification curves) from the <code>batsch1</code>, <code>boggy</code>, <code>C126EG595</code>, <code>competimer</code>, <code>dil4reps94</code>, <code>guescini1</code>, <code>karlen1</code>, <code>lievens1</code>, <code>reps384</code>, <code>rutledge</code>, <code>testdat</code>, <code>vermeulen1</code>, <code>VIMCFX96_60</code>, <code>stepone_std</code>, <code>RAS002</code>, <code>RAS003</code>, <code>HCU32_aggR</code> and <code>lc96_bACTXY</code> were analyzed with the <code><a href="../reference/encu.html">encu()</a></code> function and the results (features) were combined in the file <code>data_sample.rda</code>. The algorithms are divided into the following broad categories:</p>
<ul>
<li>algorithms that determine increases, signal levels,</li>
<li>algorithms that determine turning points and</li>
<li>algorithms that determine areas.</li>
</ul>
<p>Users of this function should independently verify and validate the results of the methods for their applications. The <code><a href="../reference/encu.html">encu()</a></code> function is based on the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function. Contrary to the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function, the <code><a href="../reference/encu.html">encu()</a></code> function can be used to process large records of amplification curve data arranged in columns. The progress of processing is displayed in the form of a progress bar and the estimated run-time. The <code><a href="../reference/encu.html">encu()</a></code> function is not discussed in more detail. Additionally, the <code><a href="../reference/encu.html">encu()</a></code> allows to specify which monitoring chemistry (e. g., DNA binding dye, sequence specific probes) and which thermo-cycler was used. Such information may well be relevant for data analysis (). <span class="citation">Jan M. Ruijter et al. (2014)</span> have shown, among other things, that monitoring chemistry of the type of input DNA (single stranded, double stranded) can be important when analysing qPCR data.</p>

<p>The <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function and the <code><a href="../reference/encu.html">encu()</a></code> function perform two pre-processing steps before each calculation. That includes checking whether an amplification curve contains missing values. Missing values (NA) are measuring points in a dataset where no measured values are available or if they have been removed arbitrarily. Causes of this can be found, for example, in case that no measurement has been carried out (e. g., defective detector) or lengths of the vectors differ (number of cyles) between the observation. Missing values are automatically imputed by spline interpolation as described in <span class="citation">Rödiger, Burdukiewicz, and Schierack (2015)</span>. The <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function and the <code><a href="../reference/encu.html">encu()</a></code> function will only terminate with an error message in extreme cases. In the next step, all values of an amplification curve are normalized to the 99% quantile. The normalization is necessary, because the amplitudes of amplification curves depend on the used detection chemistry and thermo-cycler (sensor technology, software processing). As a result considerable differences between the maximum values of raw data are the norm. Users of the  package are advised to take a look at the datasets of amplification curves before starting complex analyses. In order to compare amplification curves from different thermo-cyclers, the values should always be scaled systematically using the same method. Although there are other normalization methods (e. g., <em>minimum-maximum normalization</em>, see <span class="citation">Rödiger, Burdukiewicz, and Schierack (2015)</span>), the normalization by means of the 99% quantile should ensure that the information about the height of the background signal is not lost. That would be the case with a <em>Min-Max-standardization</em>. A normalization to the maximum is not recommended, because outliers could have an unintentional influence on the normalization. Consequently, the 99% quantile is a pragmatic compromise to take the aforementioned aspects into account in the processing chain. For example, the data in D show that the <code>maxRFU</code> values after normalization are approximately 1. There is no statistical significant difference between <code>maxRFU</code> values of positive and negative amplification curves. Inspired by <code>maxRFU</code> value, the minimum of the amplification curve is determined by the 1% quantile to minimize the influence of outliers. It is referred to as <code>minRFU</code> (C). Selected algorithms of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function use the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/CPP">CPP()</a></code> function from the  package to pre-process (e. g., baselining, smoothing, imputation of missing values) the amplification curves. Further details are given in <span class="citation">Rödiger, Burdukiewicz, and Schierack (2015)</span>.</p>

<p>Missing values (NA) of features can occur in case that a calculation of a specified value is not possible. It can occur, for example, if a logistical function is to be adapted to a measurement series, but the raw data is too noisy to allow model adaptation. As a consequence, no parameters would be determined from this model. The apparent lack of information is nevertheless still useful in the context of data analysis. For the case described above, it could be deduced from the missing values that the data series does not show a sigmoid curve progression. In this regard, NAs nonetheless provide an informational basis.</p>
<p>However, NAs pose a difficulty in many analyses. Before an analysis is carried out, it must be clarified how to deal with the missing values. Under the term “imputation” there are a number of procedures based on statistical methods (e. g., neighboring median, spline interpolation) or on user-defined rules. Such a rule could, for example, consist of setting one of the slope parameters of a model to zero when it cannot be determined <span class="citation">(Williams 2009, <span class="citation">Cook and Swayne (2007)</span>, <span class="citation">Hothorn and Everitt (2014)</span>)</span>. The application of fixed rules brings the advantage that the user is relieved of the decision as to how to deal with missing values. The disadvantage is that certain rules do not necessarily have to reflect a natural process.</p>
<p>The NAs were left unchanged in the  package up to version 0.2.5-1. Since version 0.2.6, however, the NAs have been replaced by numerical values (e. g., total number of cycles) or factors (e. g., <em>lNA</em> for non-fitted model).</p>
</div>
<div id="model-selection" class="section level4">
<h4 class="hasAnchor">
<a href="#model-selection" class="anchor"></a>Model Selection </h4>
<p>In , it was postulated that a sigmoid curve can be fitted using logistic functions. There are four functions used in the  package, that were previously descried by <span class="citation">Spiess, Feig, and Ritz (2008)</span> and <span class="citation">Ritz and Spiess (2008)</span>. This model is used as the starting point for to fit a model with four (<em>l4</em>, ), five (<em>l5</em>, ) or six parameters (<em>l6</em>, ). The optimal model is selected on the basis of the Akaike information criterion. This model is used for all further calculations. The <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function returns <code>qPCRmodel</code> as a factor (<em>l4</em>, <em>l5</em>, <em>l6</em>, <em>l7</em>). The model found can also be interpreted as the quality of an amplification curve, since a model with many parameters differs more from an ideal sigmoid model. For instance, a four-parameter model, unlike the seven-parameter model, does not have a square component. The four-parameter model would be suitable for amplification curves with a very slight increase in the ground phase and plateau phase. This would correspond to a simple sigmoid amplification curve. In case no model could be fitted, an <em>lNA</em> is returned.</p>
<ul>
<li>
<strong>l4</strong>:</li>
</ul>
<span class="math display">\[\begin{equation}\label{l4}
f(x) = c + \frac{d - c}{1 + exp(b(log(x) - log(e)))}
\end{equation}\]</span>
<ul>
<li>
<strong>l5</strong>:</li>
</ul>
<span class="math display">\[\begin{equation}\label{l5}
f(x) = c + \frac{d - c}{(1 + exp(b(log(x) - log(e))))^f}
\end{equation}\]</span>
<ul>
<li>
<strong>l6</strong>:</li>
</ul>
<span class="math display">\[\begin{equation}\label{l6}
f(x) = c + k \cdot x + \frac{d - c}{(1 + exp(b(log(x) - log(e))))^f}
\end{equation}\]</span>
<ul>
<li>
<strong>l7</strong>:</li>
</ul>
<span class="math display">\[\begin{equation}\label{l7}
f(x) = c + k1 \cdot x + k2 \cdot x^2 + \frac{d - c}{(1 + exp(b(log(x) - log(e))))^f}
\end{equation}\]</span>
<p>The <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function starts by adjusting a seven-parameter model. As a matter of fact, models with many parameters adapt adapt <em>easier</em> to an dataset. From that model, the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function outputs the variables <code>b_slope</code> and <code>f_intercept</code>, which describe the increase and the intercept. The number of iterations required to adapt the model is also stored. That value is returned by the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function as <code>convInfo_iteratons</code>. The higher the <code>convInfo_iteratons</code> value, the more iterations were necessary to converge from the start parameters (D). Hence, a low <code>convInfo_iteratons</code> value implies a sigmoid curve and a high number of iterations implies a noisy or non-sigmoid curve.</p>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_models-1.png" alt="Distribution of models of amplification curves. The `competimer`, `dil4reps94`, `guescini1`, `HCU32\_aggR`, `karlen1`, `lc96\_bACTXY`, `lievens1`, `RAS002`, `RAS003`, `reps384`, `rutledge`, `stepone\_std`, `testdat`, `vermeulen1`, `VIMCFX96\_60` datasets were analyzed with the ``encu()`` function. For each amplification curve, the optimal model was selected on the basis of the Akaike information criterion. A) Model functions of the raw amplification curve. B) Model functions of the rotated and flipped amplification curves. lNA, no model fitted. l4 \ldots l7, model with four to seven parameters." width="700"><p class="caption">
Distribution of models of amplification curves. The <code>competimer</code>, <code>dil4reps94</code>, <code>guescini1</code>, <code>HCU32\_aggR</code>, <code>karlen1</code>, <code>lc96\_bACTXY</code>, <code>lievens1</code>, <code>RAS002</code>, <code>RAS003</code>, <code>reps384</code>, <code>rutledge</code>, <code>stepone\_std</code>, <code>testdat</code>, <code>vermeulen1</code>, <code>VIMCFX96\_60</code> datasets were analyzed with the <code><a href="../reference/encu.html">encu()</a></code> function. For each amplification curve, the optimal model was selected on the basis of the Akaike information criterion. A) Model functions of the raw amplification curve. B) Model functions of the rotated and flipped amplification curves. lNA, no model fitted. l4 l7, model with four to seven parameters.
</p>
</div>
</div>
<div id="quantification-points-ratios-and-slopes" class="section level4">
<h4 class="hasAnchor">
<a href="#quantification-points-ratios-and-slopes" class="anchor"></a>Quantification Points, Ratios and Slopes</h4>
<p>In the literature, statistical methods are described which can be used to describe quantitatively the product formation in a qPCR <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015, <span class="citation">Jan M. Ruijter et al. (2013)</span>)</span>. As illustrated in  are these the Ct value, the the first derivative maximum (<code>cpD1</code>) and the second derivative maximum (<code>cpD2</code>). The <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function calculates the <code>cpD1</code> and <code>cpD2</code> (). Both quantification points are not directly useful to distinguish between a positive and negative amplification curve. However, low <code>cpD1</code> and <code>cpD2</code> values (&lt; 5 cycles) indicate that the PCR reaction was negative or that the amount of input DNA was to high. The Ct value is not calculate for the reasons discussed in . No further information shall be provided about these typical procedures.</p>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_dat_Cq-1.png" alt="Distribution of Cq values of positive and negative amplification curves. All Cq values were calculated from 3302 amplification curves after fitting the optimal multi-parametric models. The Cqs of positive amplification curves heaped up in the range between 10 and 35 PCR cycles. This differs from the distribution of negative amplification curves. The Cqs of negative amplification curves were calculate over the entire range. Note: The Cqs of the negative amplification curves are false positive. A) The maximum of the first derivative cpD1. B) The maximum of the second derivative (cpD2)." width="700"><p class="caption">
Distribution of Cq values of positive and negative amplification curves. All Cq values were calculated from 3302 amplification curves after fitting the optimal multi-parametric models. The Cqs of positive amplification curves heaped up in the range between 10 and 35 PCR cycles. This differs from the distribution of negative amplification curves. The Cqs of negative amplification curves were calculate over the entire range. Note: The Cqs of the negative amplification curves are false positive. A) The maximum of the first derivative cpD1. B) The maximum of the second derivative (cpD2).
</p>
</div>
<p>Further features from the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function are:</p>
<ul>
<li>
<code>eff</code> is the optimized PCR efficiency found within a sliding window (C). A linear model of cycles versus log(Fluorescence) is fit within a sliding window (for details see <code><a href="http://www.rdocumentation.org/packages/qpcR/topics/sliwin">sliwin()</a></code> function from the  package). The comparison of positive and negative amplification curves in A demonstrates that the classes are significantly different from each other.</li>
<li>
<code>sliwin</code> is the PCR efficiency by the ‘window-of-linearity’ method <span class="citation">(Spiess, Feig, and Ritz 2008)</span>.</li>
<li>
<code>cpDdiff</code> is the the difference between the Cq values calculated from the first and the second derivative maximum (<span class="math inline">\(cpDdiff = |cpD1 - cpD2|\)</span>) from the fitted model (C). Provided that a model can be exactly fitted, the estimates of the difference are reliable. Higher <code>cpDdiff</code> values indicate a negative amplification reaction or a very low amplification efficiency. The comparison of positive and negative amplification curves in C demonstrates that the classes are significantly different from each other. In the event that the <code>cpDdiff</code> value cannot be determined (NA), it is replaced by zero.</li>
<li>
<code>cpD2_range</code> is the absolute value of the difference between the minimum and the maximum of the second derivative maximum (<span class="math inline">\(cpD2\_range = |\min cpD2 - \max cpD2|\)</span>) from the <code>diffQ2()</code> function (no model fitted) (). The <code>cpD2_range</code> value does not require an adjustment of a multiparametric model. The approximate first and second derivatives are determined using a five-point stencil <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015)</span>. The comparison of positive and negative amplification curves in E shows that the classes differ significantly from each other. In the event that the <code>cpD2_range</code> value cannot be determined (NA), it is replaced by zero.</li>
</ul>
<div class="figure">
<img src="PCRedux_files/figure-html/figure_cpD2_range-1.png" alt="Use of the second derivative maximum and minimum for the calculation of `cpD2\_range`. Both the minimum (cpD2m) and the maximum (cpD2) of the second derivative were determined numerically using the ``diffQ2()`` function. In addition, the function returns the maximum of the first derivative (cpD1). The difference of cpD2 and cpD2m results in the `cpD2\_range`. Large `cpD2\_range` values indicate a low amplification efficiency or negative amplification reaction. `bg.start` provides an estimate for the end of the ground phase. The following formula is used for the calculation: $bg.start = cpD1 - f * (cpD2m - cpD2)$. The distance between cpD1 and cpD2 is multiplied by a factor. `bg.stop` provides an estimate for the end of the exponential phase. The following formula is used for the calculation: $bg.start = cpD1 + f * (cpD2m - cpD2)$. $f$ is a factor (default 0.6) (see manual of ``bg.max()`` for details)." width="700"><p class="caption">
Use of the second derivative maximum and minimum for the calculation of <code>cpD2\_range</code>. Both the minimum (cpD2m) and the maximum (cpD2) of the second derivative were determined numerically using the <code>diffQ2()</code> function. In addition, the function returns the maximum of the first derivative (cpD1). The difference of cpD2 and cpD2m results in the <code>cpD2\_range</code>. Large <code>cpD2\_range</code> values indicate a low amplification efficiency or negative amplification reaction. <code>bg.start</code> provides an estimate for the end of the ground phase. The following formula is used for the calculation: <span class="math inline">\(bg.start = cpD1 - f * (cpD2m - cpD2)\)</span>. The distance between cpD1 and cpD2 is multiplied by a factor. <code>bg.stop</code> provides an estimate for the end of the exponential phase. The following formula is used for the calculation: <span class="math inline">\(bg.start = cpD1 + f * (cpD2m - cpD2)\)</span>. <span class="math inline">\(f\)</span> is a factor (default 0.6) (see manual of <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/bg.max">bg.max()</a></code> for details).
</p>
</div>
<ul>
<li>
<code>bg.stop</code> () is the end of the ground phase estimated by the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/bg.max">bg.max()</a></code> function <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015)</span>.</li>
<li>
<code>amp.stop</code> () is the end of the exponential phase estimated by the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/bg.max">bg.max()</a></code> function <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015)</span>.</li>
</ul>
<p>Another method is the <em>takeoff point</em> (<code>top</code>) according to <span class="citation">Tichopad et al. (2003)</span>. The <code>top</code> is calculated using externally studentized residuals, which tested to be an outlier in terms of the t-distribution. The <code>top</code> signifies to first PCR cycle entering the exponential phase. The <em>takedown point</em> (<code>tdp</code>) is an implementation in the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function, which uses the rotated <span class="math inline">\(f(x) \mapsto f_{1}(f(x))\)</span> and flipped <span class="math inline">\(g(x) = -(x)\)</span> amplification curve for calculation A describes the location of <code>top</code> and <code>tdp</code> exemplarily. The position (<code>f.top</code>, <code>f.tdp</code>) on the ordinate is also determined from these points. If an amplification curve is negative or neither <code>top</code> nor <code>tdp</code> can be calculated, then <code>top</code> &amp; <code>tdp</code> will be assigned the number of cycles and <code>f.top</code> &amp; <code>f.tdp</code> the value 1. The distribution of <code>top</code>, <code>tdp</code>, <code>f.top</code> and <code>f.tdp</code> is shown in I-L. This figure shows that a <code>top</code> value and a <code>tdp</code> value enable a qualitative classification of the amplification reaction. An interesting aspect is that the positive <code>f.top</code> values are markedly lower than the negative <code>f.top</code> values (J). The same applies inversely to the <code>tdp</code> values (L). In this way, amplification curves can be classified according to these values.</p>
<div class="figure">
<img src="PCRedux_files/figure-html/unnamed-chunk-17-1.png" alt="Analysis of location features. Amplification curves from the datasets `stepone\_std`, `RAS002`, `RAS003`, `lc96\_bACTXY`, `C126EG595` and `dil4reps94` were analyzed with the ``encu()`` function. These datasets contain positive and negative amplification curves.  Furthermore, the meta dataset contains amplification curves that exhibit a hook effect or non-sigmoid shapes, for instance. All amplification curves are manually classified. Altogether 626 positive and 317 negative amplification curves were included in the analysis. A) `eff`, optimized PCR efficiency found within a sliding window. B) `sliwin`, PCR efficiency by the ‘window-of-linearity’ method. C) `cpDdiff`, difference between the Cq values calculated from the first and the second derivative maximum. D) `loglin\_slope`, slope from the cycle at the second derivative maximum to the second derivative minimum. E) `cpD2\_range`, absolute value of the difference between the minimum and the maximum of the second derivative maximum. F) `top`, takeoff point. G) `f.top`, fluorescence intensity at takeoff point. H) `tdp`,  takedown point. I) `f.tdp`, fluorescence intensity at takedown point. J) `bg.stop`, estimated end of the ground phase. K) `amp.stop`, estimated end of the exponential phase. L) `convInfo\_iteratons`, number of iterations until convergence." width="1056"><p class="caption">
Analysis of location features. Amplification curves from the datasets <code>stepone\_std</code>, <code>RAS002</code>, <code>RAS003</code>, <code>lc96\_bACTXY</code>, <code>C126EG595</code> and <code>dil4reps94</code> were analyzed with the <code><a href="../reference/encu.html">encu()</a></code> function. These datasets contain positive and negative amplification curves. Furthermore, the meta dataset contains amplification curves that exhibit a hook effect or non-sigmoid shapes, for instance. All amplification curves are manually classified. Altogether 626 positive and 317 negative amplification curves were included in the analysis. A) <code>eff</code>, optimized PCR efficiency found within a sliding window. B) <code>sliwin</code>, PCR efficiency by the ‘window-of-linearity’ method. C) <code>cpDdiff</code>, difference between the Cq values calculated from the first and the second derivative maximum. D) <code>loglin\_slope</code>, slope from the cycle at the second derivative maximum to the second derivative minimum. E) <code>cpD2\_range</code>, absolute value of the difference between the minimum and the maximum of the second derivative maximum. F) <code>top</code>, takeoff point. G) <code>f.top</code>, fluorescence intensity at takeoff point. H) <code>tdp</code>, takedown point. I) <code>f.tdp</code>, fluorescence intensity at takedown point. J) <code>bg.stop</code>, estimated end of the ground phase. K) <code>amp.stop</code>, estimated end of the exponential phase. L) <code>convInfo\_iteratons</code>, number of iterations until convergence.
</p>
</div>
<p>In  it was postulated that an amplification curve can be divided into different regions. One assumption is that the slope and intercept of positive amplification curves are markedly different in head (ground phase) and tail (plateau phase). The intercept in the head should be lower than in the tail. In a negative amplification curve, the intercept should be nearly identical. The slope in the tail should also provide some indication to determine whether the amplification reaction is completed. In order to quantify these values, a linear regression model can be used in these ROIs.</p>
<p>An example is given for the internal parameter <code>loglin_slope</code> which is calculated from the slope determined by a linear model of the data points from the fluorescence at the minimum and maximum of the second derivative (). The coordinates of the minimum and the maximum were determined as described in <span class="citation">Rödiger, Böhm, and Schimke (2013)</span>. This feature uses the exponential phase as ROI. Provided that the locations of the minimum of the second derivative and the maximum of the second derivative yield a <em>suitable</em> interval. As a precaution, the algorithm checks, for example, whether the distance between the minimum of the second derivative and the maximum of the second derivative is not more than nine PCR cycles. Failing this, the <code>loglin_slope</code> value is set to zero (no slope). In the following example, the data .</p>
<div class="figure">
<img src="PCRedux_files/figure-html/loglin_slope-1.png" alt="Concept of the `loglin\_slope` feature. The algorithm determines the fluorescence values of the raw data at the approximate positions of the maximum of the first derivative, the minimum of the second derivative and the maximum of the second derivative, which are in the exponential phase of the amplification curve. A linear model is created from these parameter sets and the slope is determined. A) Positive amplification curves have a clearly positive slope. B) Negative amplification curves usually have a low, sometimes negative slope. The data were taken from the `RAS002` dataset." width="700"><p class="caption">
Concept of the <code>loglin\_slope</code> feature. The algorithm determines the fluorescence values of the raw data at the approximate positions of the maximum of the first derivative, the minimum of the second derivative and the maximum of the second derivative, which are in the exponential phase of the amplification curve. A linear model is created from these parameter sets and the slope is determined. A) Positive amplification curves have a clearly positive slope. B) Negative amplification curves usually have a low, sometimes negative slope. The data were taken from the <code>RAS002</code> dataset.
</p>
</div>
<p>All manufacturers of thermo-cyclers use different sensors and data processing algorithms in their systems. Hence it can be assumed that the signal variation in the ground phase (F) differs between the different systems. Moreover, users make use of different detection chemistries (e. g., hydrolysis probes, reporter dyes). However, the latter will not be discussed here. For the distinction between negative and positive amplification curves, it should be checked whether a difference can be determined on the basis of the standard deviation of the background fluorescence.</p>
<p>After analyzing all amplification curves with the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function, the <code>sd_bg</code> feature was analyzed. The feature <code>sd_bg</code> is the standard deviation from the first PCR cycle to the takeoff point (A). If no takeoff point can be determined from an amplification curve, the value for <code>sd_bg</code> is calculated from the first to the eighth PCR cycle. The feature <code>sd_bg</code> in  is broken down by the thermo-cycler and the output of the amplification reaction (negative, positive). It can be seen that the signal variation between the thermo-cyclers seems to be different. There is also a difference between negative and positive amplification curves. This is also in accordance with the observations from .</p>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_sd_bg-1.png" alt="Standard deviation in the ground phase of various qPCR devices. The `sd\_bg` feature was used to determine if the standard deviation between the thermo-cyclers and between positive and negative amplification curves was different. The standard deviation was determined from the fluorescence values from the first cycle to the takeoff point. If the takeoff point could not be determined, the standard deviation from the first cycle to the eighth cycle was calculated. The Mann-Whitney test was used to compare the medians of the two populations (y, positive; n, negative). The differences were significant for A) LC\_480 (Roche), B) ABI\_Prism\_7700 (ABI), C) LC1.0 (Roche), E) CFX96 (Bio-Rad) and F) LC96 (Roche). The difference was not significant for D) StepOne (Thermo Fisher)." width="700"><p class="caption">
Standard deviation in the ground phase of various qPCR devices. The <code>sd\_bg</code> feature was used to determine if the standard deviation between the thermo-cyclers and between positive and negative amplification curves was different. The standard deviation was determined from the fluorescence values from the first cycle to the takeoff point. If the takeoff point could not be determined, the standard deviation from the first cycle to the eighth cycle was calculated. The Mann-Whitney test was used to compare the medians of the two populations (y, positive; n, negative). The differences were significant for A) LC_480 (Roche), B) ABI_Prism_7700 (ABI), C) LC1.0 (Roche), E) CFX96 (Bio-Rad) and F) LC96 (Roche). The difference was not significant for D) StepOne (Thermo Fisher).
</p>
</div>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_bg_pt-1.png" alt="Analysis of slope and ratio features. Amplification curves from the datasets `stepone_std`, `RAS002`, `RAS003`, `lc96_bACTXY`, `C126EG595` and `dil4reps94` were analyzed with the ``encu()`` function. These datasets contain positive and negative amplification curves.  Furthermore, the meta dataset contains amplification curves that exhibit a hook effect or non-sigmoid shapes, for instance. All amplification curves are manually classified. Altogether 626 positive and 317 negative amplification curves were included in the analysis. A) `b_slope`, B) `f_intercept`, C) `minRFU` is the minimum (1% qantile) of the amplification curve, D) `maxRFU` is the maximum (99% qantile) of the amplification curve, E) `init2` is the initial template fluorescence from an exponential model, F) `fluo` is the raw fluorescence value at the second derivative maximum, G) `slope_bg` is the slope calculated be the ``earlyreg()`` function, H) `intercept_bg` is the intercept calculated be the ``earlyreg()`` function, I) `sd\_bg` is the standard deviation of the ground phase and J) `head2tail_ratio` is the between the RFU values of the head and the tail, normalized to the slope from the head to the tail." width="1056"><p class="caption">
Analysis of slope and ratio features. Amplification curves from the datasets <code>stepone_std</code>, <code>RAS002</code>, <code>RAS003</code>, <code>lc96_bACTXY</code>, <code>C126EG595</code> and <code>dil4reps94</code> were analyzed with the <code><a href="../reference/encu.html">encu()</a></code> function. These datasets contain positive and negative amplification curves. Furthermore, the meta dataset contains amplification curves that exhibit a hook effect or non-sigmoid shapes, for instance. All amplification curves are manually classified. Altogether 626 positive and 317 negative amplification curves were included in the analysis. A) <code>b_slope</code>, B) <code>f_intercept</code>, C) <code>minRFU</code> is the minimum (1% qantile) of the amplification curve, D) <code>maxRFU</code> is the maximum (99% qantile) of the amplification curve, E) <code>init2</code> is the initial template fluorescence from an exponential model, F) <code>fluo</code> is the raw fluorescence value at the second derivative maximum, G) <code>slope_bg</code> is the slope calculated be the <code><a href="../reference/earlyreg.html">earlyreg()</a></code> function, H) <code>intercept_bg</code> is the intercept calculated be the <code><a href="../reference/earlyreg.html">earlyreg()</a></code> function, I) <code>sd\_bg</code> is the standard deviation of the ground phase and J) <code>head2tail_ratio</code> is the between the RFU values of the head and the tail, normalized to the slope from the head to the tail.
</p>
</div>
<p>The aim was to predict, based on the <code>polyarea</code> feature, whether an amplification curve is positive or negative. The computation of <code>polyarea</code> is based on the Gauss polygon area formula. The feature <code>polyarea</code> has been selected to show that the area under an amplification curve can be used to distinguish positive and negative amplification curves. The hypothesis is that positive amplification curves have a larger area than negative amplification curves. As shown in C, there is a statistically significant difference between positive and negative amplification curves. Also shown are the values of another method to calculate the area under an amplification curve. This method is called <code>amptester_polygon</code>. <code>amptester_polygon</code> is part of the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/amptester">amptester()</a></code> function from the  package <span class="citation">(Rödiger, Burdukiewicz, and Schierack 2015)</span>. In contrast to the implementation in the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/amptester">amptester()</a></code> is the <code>amptester_polygon</code> value normalized to the total number of cycles. It is expected that this method allows comparable predictions (Ds). However, this question is not to be dealt with in the following example.</p>
<p>The <code>batsch1</code>, <code>HCU32_aggR</code>, <code>stepone_std</code>, <code>RAS002</code>, <code>RAS003</code>, <code>lc96_bACTXY</code> datasets were used for the calculation of the <code>polyarea</code> values for all amplification curves. A binomial logistic regression (aka logit regression or logit model) was used to analyze the relationship between the <code>polyarea</code> value and the decision (negative, positive). This dataset contains almost equal proportions of positive and negative amplification curves (A). Prior to this, the amplification curves were analyzed with the <code><a href="../reference/encu.html">encu()</a></code> function () and stored in the <code>data_sample.rda</code> file to save computing time. The file is part of the  package. The dataset was split into two chunks. This is an important step during such applications. One chunk is for adapting, i. e. training, the model and the other chunk for testing the model. Typically, 70% to 80% of the data is used for training <span class="citation">(Walsh, Pollastri, and Tosatto 2015, <span class="citation">Kuhn (2008)</span>)</span>. The binomial logistic regression model was adapted using the function <code>glm()</code> by using the parameter <code>family = binomial(link = 'logit')</code>. To objectify the splitting, the <code>sample()</code> function was used.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># options(warn = -1)</span>
<span class="kw">library</span>(PCRedux)

data &lt;-<span class="st"> </span>data_sample[data_sample<span class="op">$</span>dataset <span class="op">%in%</span><span class="st"> </span>
<span class="st">                </span><span class="kw">c</span>(<span class="st">"batsch1"</span>,
                  <span class="st">"HCU32_aggR"</span>,
                  <span class="st">"lc96_bACTXY"</span>,
                  <span class="st">"RAS002"</span>, 
                  <span class="st">"RAS003"</span>, 
                  <span class="st">"stepone_std"</span>), ]

n_positive &lt;-<span class="st"> </span><span class="kw">sum</span>(data[[<span class="st">"decision"</span>]] <span class="op">==</span><span class="st"> "y"</span>)
n_negative &lt;-<span class="st"> </span><span class="kw">sum</span>(data[[<span class="st">"decision"</span>]] <span class="op">==</span><span class="st"> "n"</span>)

dat &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">polyarea =</span> data[, <span class="st">"polyarea"</span>], 
                  <span class="dt">decision =</span> <span class="kw">as.numeric</span>(<span class="kw">factor</span>(data<span class="op">$</span>decision, 
                                         <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">"n"</span>, <span class="st">"y"</span>), 
                                         <span class="dt">label =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)

<span class="co"># Select randomly observations from 70% of the data for training.</span>
<span class="co"># n_train is the number of observations used for training.</span>

n_train &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">nrow</span>(data) <span class="op">*</span><span class="st"> </span><span class="fl">0.7</span>)

<span class="co"># index_test is the index of observations to be selected for the training</span>
index_test &lt;-<span class="st"> </span><span class="kw">sample</span>(1L<span class="op">:</span><span class="kw">nrow</span>(dat), <span class="dt">size =</span> n_train)

<span class="co"># index_test is the index of observations to be selected for the testing</span>
index_training &lt;-<span class="st"> </span><span class="kw">which</span>(<span class="op">!</span>(1L<span class="op">:</span><span class="kw">nrow</span>(dat) <span class="op">%in%</span><span class="st"> </span>index_test))

<span class="co"># train_data contains the data used for training</span>

train_data &lt;-<span class="st"> </span>dat[index_test, ]

<span class="co"># test_data contains the data used for training</span>

test_data &lt;-<span class="st"> </span>dat[index_training, ]

<span class="co"># Fit the binomial logistic regression model</span>

model_glm &lt;-<span class="st"> </span><span class="kw">glm</span>(decision <span class="op">~</span><span class="st"> </span>polyarea, <span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link=</span><span class="st">'logit'</span>), 
                 <span class="dt">data =</span> train_data)

predictions &lt;-<span class="st"> </span><span class="kw">ifelse</span>(<span class="kw">predict</span>(model_glm, 
                                 <span class="dt">newdata =</span> test_data, <span class="dt">type =</span> <span class="st">'response'</span>) <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>,
                         <span class="dv">1</span>, <span class="dv">0</span>)

res_performeR &lt;-<span class="st"> </span><span class="kw"><a href="../reference/performeR.html">performeR</a></span>(predictions, test_data[[<span class="st">"decision"</span>]])[, <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dv">12</span>)]</code></pre></div>
<p>The <code>summary()</code> function returns the results of the model fitting. This can be analysed and interpreted.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(model_glm)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = decision ~ polyarea, family = binomial(link = "logit"), 
##     data = train_data)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -5.2288  -0.3324  -0.1736   0.0273   1.7232  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -2.7706     0.3057  -9.063   &lt;2e-16 ***
## polyarea     89.2548     9.4865   9.409   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 484.08  on 362  degrees of freedom
## Residual deviance: 161.86  on 361  degrees of freedom
## AIC: 165.86
## 
## Number of Fisher Scoring iterations: 7</code></pre>
<p>Based on the results it can be concluded that the parameters <code>(Intercept)</code> and <code>polyarea</code> are statistically significant (<em>P</em> &lt; 2e-16). This indicates a strong association between <code>polyarea</code> and the probability that an amplification curve is positive.</p>
<p>In order to apply the model to a new dataset, further steps are necessary. <code>predict()</code> is a generic function for prediction from the results of a model fitting function. All previously split test data is passed to the function argument <code>newdata</code>. By setting the <code>type = 'response'</code> parameter, the <code>predict()</code> function returns probabilities in the form of <span class="math inline">\(P(y=1|X)\)</span>. In the case in hand, it was decided that a decision limit of 0.5 is to be applied. If <span class="math inline">\(P(y=1|X) &lt; 0.5\)</span> then <span class="math inline">\(y = 0\)</span> (amplification curve negative), otherwise <span class="math inline">\(y = 1\)</span> (amplification curves positive).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># options(warn = -1)</span>
<span class="kw">library</span>(PCRedux)

<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))

<span class="co"># Plot train_data (grey points) and the predicted model (blue)</span>

<span class="kw">plot</span>(train_data<span class="op">$</span>polyarea, train_data<span class="op">$</span>decision, <span class="dt">pch =</span> <span class="dv">19</span>, 
     <span class="dt">xlab =</span> <span class="st">"polyarea"</span>, <span class="dt">ylab =</span> <span class="st">"Probability"</span>, 
     <span class="dt">col =</span> <span class="kw">adjustcolor</span>(<span class="st">"grey"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.9</span>), <span class="dt">cex =</span> <span class="fl">1.5</span>)
<span class="kw">mtext</span>(<span class="st">"A"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, <span class="dt">las =</span> <span class="dv">0</span>)
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="fl">0.5</span>, <span class="dt">col =</span> <span class="st">"grey"</span>)

<span class="kw">curve</span>(<span class="kw">predict</span>(model_glm, <span class="kw">data.frame</span>(<span class="dt">polyarea =</span> x), <span class="dt">type =</span> <span class="st">"resp"</span>), 
      <span class="dt">add =</span> <span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">"blue"</span>)

<span class="co"># Plot test_data (red)</span>

<span class="kw">points</span>(test_data<span class="op">$</span>polyarea, test_data<span class="op">$</span>decision, <span class="dt">pch =</span> <span class="dv">19</span>,
       <span class="dt">col =</span> <span class="kw">adjustcolor</span>(<span class="st">"red"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.3</span>))
<span class="kw">legend</span>(<span class="st">"right"</span>, <span class="kw">paste</span>(<span class="st">"Positive: "</span>, n_positive, 
                      <span class="st">"</span><span class="ch">\n</span><span class="st">Negative: "</span>, n_negative), <span class="dt">bty =</span> <span class="st">"n"</span>)


<span class="co"># Plot the sensitivity, specificity and other measures to describe the prediction.</span>

position_bp &lt;-<span class="st"> </span><span class="kw">barplot</span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/as.matrix">as.matrix</a></span>(res_performeR), <span class="dt">yaxt =</span> <span class="st">"n"</span>, 
                       <span class="dt">ylab =</span> <span class="st">"Probability"</span>, <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">las =</span> <span class="dv">2</span>, 
                       <span class="dt">col =</span> <span class="kw">adjustcolor</span>(<span class="st">"grey"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.5</span>))

<span class="kw">par</span>(<span class="dt">srt =</span> <span class="dv">90</span>)
<span class="kw">text</span>(position_bp, <span class="kw">rep</span>(<span class="fl">0.8</span>, <span class="kw">length</span>(res_performeR)), 
     <span class="kw">paste</span>(<span class="kw">signif</span>(res_performeR, <span class="dv">2</span>)<span class="op">*</span><span class="dv">100</span>, <span class="st">"%"</span>), <span class="dt">cex =</span> <span class="fl">0.6</span>)
<span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">"0"</span>, <span class="st">"1"</span>), <span class="dt">las =</span> <span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="fl">0.85</span>, <span class="dt">col =</span> <span class="st">"grey"</span>)

<span class="kw">mtext</span>(<span class="st">"B"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, <span class="dt">las =</span> <span class="dv">0</span>)</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_Logistic_Regression-1.png" alt="Binomial logistic regression for the `polyarea` feature. A) binomial logistic regression model for the response variable $Y$ (decision) is categorical and must be converted into a numerical value. This regression calculation makes it possible to estimate the probability of a categorical response using predictor variables $X$. In this case, the predictor variable is `polyarea`. Gray dots are the value values used for training. Red dots are the values used for testing. The regression curve of the binomial logistic regression is shown in blue. At 0.5, the gray horizontal line marks the threshold value of probability used to determine whether an amplification curve is negative or positive. B) The measure were determined with the \textit{performance()} function from the \texttt{PCRedux} package. Sensitivity, TPR; Specificity, SPC; Precision, PPV; Negative predictive value, NPV; Fall-out, FPR; False negative rate, FNR; False discovery rate, FDR; Accuracy, ACC; F1 score, F1; Matthews correlation coefficient, MCC, Cohen's kappa (binary classification), kappa ($\kappa$)." width="700"><p class="caption">
Binomial logistic regression for the <code>polyarea</code> feature. A) binomial logistic regression model for the response variable <span class="math inline">\(Y\)</span> (decision) is categorical and must be converted into a numerical value. This regression calculation makes it possible to estimate the probability of a categorical response using predictor variables <span class="math inline">\(X\)</span>. In this case, the predictor variable is <code>polyarea</code>. Gray dots are the value values used for training. Red dots are the values used for testing. The regression curve of the binomial logistic regression is shown in blue. At 0.5, the gray horizontal line marks the threshold value of probability used to determine whether an amplification curve is negative or positive. B) The measure were determined with the  function from the  package. Sensitivity, TPR; Specificity, SPC; Precision, PPV; Negative predictive value, NPV; Fall-out, FPR; False negative rate, FNR; False discovery rate, FDR; Accuracy, ACC; F1 score, F1; Matthews correlation coefficient, MCC, Cohen’s kappa (binary classification), kappa (<span class="math inline">\(\kappa\)</span>).
</p>
</div>
<p>The sensitivity, specificity and further parameters for estimating the prediction were calculated using the <code><a href="../reference/performeR.html">performeR()</a></code> function (). The results indicate that the sensitivity and specificity for the test dataset provides a good result. However, the results in this case depend heavily on the computer-aided random sampling of the training data and the total size of the dataset. Over-fitting and under-fitting and other problems need to be addressed <span class="citation">(Walsh, Pollastri, and Tosatto 2015)</span>.</p>
<p>To proof the results, further methods such as Likelihood Ratio Test, McFadden’s <span class="math inline">\(R^{2}\)</span>, k-fold cross-validation, Receiver Operating Characteristic (ROC) analysis and model interpretation should be used <span class="citation">(Arlot and Celisse 2010, <span class="citation">McFadden (1974)</span>, <span class="citation">Sing et al. (2005)</span>)</span>.</p>
<div class="figure">
<img src="PCRedux_files/figure-html/statistical_methods_positive-1.png" alt="The positive amplification curve F1.1 (`testdat` dataset) was analyzed with algorithms of the ``amptester()`` function. A) The Threshold test (THt) is based on the Wilcoxon rank sum test. The test compares 20% of the head to 15% of the tail region. A significant difference ($p-value = 0.000512$) between the two regions was found for the amplfication curve F1.1. This is indicative of a positive amplification reaction. B) Quantile-Quantile plot (Q-Q plot) of the the amplification curve. A Q-Q plot is a probability plot for a graphical comparison of two probability distributions by plotting their quantiles against each other. In this study the probability distribution of the amplification curve is compared to a theoretical normal distribution. The orange line is the theoretical normal quantile-quantile plot which passes through the probabilities of the first and third quartiles. The Shapiro-Wilk test (SHt) of normality checks whether the underlying population of a sample (amplification curve) is significantly ($\alpha \leq 5e^{-4}$) normal distributed. Since the p-value is $7.09 e^{-9}$ the null hypothesis can be rejected. C) The Linear Regression test (LRt). This test determines the coefficient of determination ($R^{2}$) by an ordinary least squares linear (OLS) regression. Usually the non-linear part of an amplification curve has an $R^{2}$ smaller than 0.8." width="700"><p class="caption">
The positive amplification curve F1.1 (<code>testdat</code> dataset) was analyzed with algorithms of the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/amptester">amptester()</a></code> function. A) The Threshold test (THt) is based on the Wilcoxon rank sum test. The test compares 20% of the head to 15% of the tail region. A significant difference (<span class="math inline">\(p-value = 0.000512\)</span>) between the two regions was found for the amplfication curve F1.1. This is indicative of a positive amplification reaction. B) Quantile-Quantile plot (Q-Q plot) of the the amplification curve. A Q-Q plot is a probability plot for a graphical comparison of two probability distributions by plotting their quantiles against each other. In this study the probability distribution of the amplification curve is compared to a theoretical normal distribution. The orange line is the theoretical normal quantile-quantile plot which passes through the probabilities of the first and third quartiles. The Shapiro-Wilk test (SHt) of normality checks whether the underlying population of a sample (amplification curve) is significantly (<span class="math inline">\(\alpha \leq 5e^{-4}\)</span>) normal distributed. Since the p-value is <span class="math inline">\(7.09 e^{-9}\)</span> the null hypothesis can be rejected. C) The Linear Regression test (LRt). This test determines the coefficient of determination (<span class="math inline">\(R^{2}\)</span>) by an ordinary least squares linear (OLS) regression. Usually the non-linear part of an amplification curve has an <span class="math inline">\(R^{2}\)</span> smaller than 0.8.
</p>
</div>
<div class="figure">
<img src="PCRedux_files/figure-html/statistical_methods_negative-1.png" alt="The negative amplification curve F1.3 (`testdat` dataset) was analyzed with algorithms of the ``amptester()`` function. A) The Threshold test (THt) is based on the Wilcoxon rank sum test. The test compares 20% of the head to 15% of the tail region. No significant difference between the two regions was found for the amplfication curve F1.3. Since the p-value is $0.621$ the null hypothesis cannot be rejected. This is indicative of a negative amplification reaction. B) Quantile-Quantile plot (Q-Q plot) of the the amplification curve. A Q-Q plot is a probability plot for a graphical comparison of two probability distributions by plotting their quantiles against each other. In this study the probability distribution of the amplification curve is compared to a theoretical normal distribution. The orange line is the theoretical normal quantile-quantile plot which passes through the probabilities of the first and third quartiles. The Shapiro-Wilk test (SHt) of normality checks whether the underlying population of a sample (amplification curve) is significantly ($\alpha \leq 5e^{-4}$) normal distributed. Since the p-value is $0.895$ the null hypothesis cannot be rejected. C) The Linear Regression test (LRt). This test determines the coefficient of determination ($R^{2}$) by an ordinary least squares linear (OLS) regression. Usually the non-linear part of an amplification curve has an $R^{2}$ smaller than 0.8." width="700"><p class="caption">
The negative amplification curve F1.3 (<code>testdat</code> dataset) was analyzed with algorithms of the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/amptester">amptester()</a></code> function. A) The Threshold test (THt) is based on the Wilcoxon rank sum test. The test compares 20% of the head to 15% of the tail region. No significant difference between the two regions was found for the amplfication curve F1.3. Since the p-value is <span class="math inline">\(0.621\)</span> the null hypothesis cannot be rejected. This is indicative of a negative amplification reaction. B) Quantile-Quantile plot (Q-Q plot) of the the amplification curve. A Q-Q plot is a probability plot for a graphical comparison of two probability distributions by plotting their quantiles against each other. In this study the probability distribution of the amplification curve is compared to a theoretical normal distribution. The orange line is the theoretical normal quantile-quantile plot which passes through the probabilities of the first and third quartiles. The Shapiro-Wilk test (SHt) of normality checks whether the underlying population of a sample (amplification curve) is significantly (<span class="math inline">\(\alpha \leq 5e^{-4}\)</span>) normal distributed. Since the p-value is <span class="math inline">\(0.895\)</span> the null hypothesis cannot be rejected. C) The Linear Regression test (LRt). This test determines the coefficient of determination (<span class="math inline">\(R^{2}\)</span>) by an ordinary least squares linear (OLS) regression. Usually the non-linear part of an amplification curve has an <span class="math inline">\(R^{2}\)</span> smaller than 0.8.
</p>
</div>
</div>
<div id="autocorrelation_test---a-function-to-detect-positive-amplification-curves" class="section level4">
<h4 class="hasAnchor">
<a href="#autocorrelation_test---a-function-to-detect-positive-amplification-curves" class="anchor"></a><code><a href="../reference/autocorrelation_test.html">autocorrelation_test()</a></code> - A Function to Detect Positive Amplification Curves </h4>
<p>Autocorrelation analysis is a technique that is used in the field of time series analysis. It can be used to reveal regularly occurring patterns in one-dimensional data <span class="citation">(Spiess et al. 2016)</span>. The autocorrelation measures the correlation of a signal <span class="math inline">\(f(t)\)</span> with itself shifted by some time delay <span class="math inline">\(f(t - \tau)\)</span>.</p>
<p>The <code><a href="../reference/autocorrelation_test.html">autocorrelation_test()</a></code> function coercers the amplification curve data to an object of the class “zoo” ( package) as indexed totally ordered observations. Next follows the computation of a lagged version of the amplification curve data. The shifting the amplification curve data is based on the number of observations (number of cylces ‘c’) with the following <span class="math inline">\(\tau\)</span>.</p>
<table class="table">
<thead><tr class="header">
<th>Number of Cycles (c)</th>
<th><span class="math inline">\(\tau\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(c \leq 35\)</span></td>
<td>8</td>
</tr>
<tr class="even">
<td><span class="math inline">\(35 &gt; c \leq 40\)</span></td>
<td>10</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(40 &lt; c \leq 45\)</span></td>
<td>12</td>
</tr>
<tr class="even">
<td><span class="math inline">\(c &gt; 45\)</span></td>
<td>14</td>
</tr>
</tbody>
</table>
<p>Then follows a significance test for correlation between paired observations (amplification curve data &amp; lagged amplification curve data). The hypothesis is that the paired observation of positive amplification curves has a significant correlation (<code><a href="http://www.rdocumentation.org/packages/stats/topics/cor.test">stats::cor.test</a></code>, significance level is 0.01) in contrast to negative amplification curves (noise). The application of the <code><a href="../reference/autocorrelation_test.html">autocorrelation_test()</a></code> function is shown in the following example.</p>
<p>In addition, the the decisions file <code>decision_res_RAS002.csv</code> from the human expert was analyzed for the most frequent decision (modus) using the <code><a href="../reference/decision_modus.html">decision_modus()</a></code> function ().</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Test for autocorrelation in amplification curve data</span>
<span class="co"># Load the libraries magrittr for pipes and the amplification curve the data</span>
<span class="co"># The amplification curve data from the `RAS002` dataset was used.</span>
<span class="co"># The data.table package was used for fast import of the csv data</span>
<span class="kw">library</span>(magrittr)
<span class="kw">library</span>(PCRedux)
<span class="kw">suppressMessages</span>(<span class="kw">library</span>(data.table))

data &lt;-<span class="st"> </span>RAS002

<span class="co"># Test for autocorrelation in the RAS002 dataset</span>

res_ac &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">2</span><span class="op">:</span><span class="kw">ncol</span>(data), <span class="cf">function</span>(i) {
  <span class="kw"><a href="../reference/autocorrelation_test.html">autocorrelation_test</a></span>(data[, i], <span class="dt">ns_2_numeric =</span> <span class="ot">TRUE</span>)
})

<span class="co"># Curves classified by a human after analysis of the overview. 1 = positive,</span>
<span class="co"># 0 = negative</span>

human_classification &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/fread">fread</a></span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/devtools/topics/system.file">system.file</a></span>(
  <span class="st">"decision_res_RAS002.csv"</span>,
  <span class="dt">package =</span> <span class="st">"PCRedux"</span>
))

<span class="kw">head</span>(human_classification)</code></pre></div>
<pre><code>##                      RAS002 test.result.1 test.result.2 test.result.3
## 1: A01_gDNA.._unkn_B.Globin             y             y             y
## 2:    A01_gDNA.._unkn_HPRT1             n             n             n
## 3: A02_gDNA.._unkn_B.Globin             y             y             y
## 4:    A02_gDNA.._unkn_HPRT1             n             n             n
## 5: A03_gDNA.._unkn_B.Globin             y             y             y
## 6:    A03_gDNA.._unkn_HPRT1             n             n             n
##    conformity
## 1:       TRUE
## 2:       TRUE
## 3:       TRUE
## 4:       TRUE
## 5:       TRUE
## 6:       TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">decs &lt;-<span class="st"> </span><span class="kw">sapply</span>(1L<span class="op">:</span><span class="kw">nrow</span>(human_classification), <span class="cf">function</span>(i) {
  res &lt;-<span class="st"> </span><span class="kw"><a href="../reference/decision_modus.html">decision_modus</a></span>(human_classification[i, 2L<span class="op">:</span>(<span class="kw">ncol</span>(human_classification) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)])
  <span class="cf">if</span> (<span class="kw">length</span>(res) <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) res[[<span class="dv">1</span>]] &lt;-<span class="st"> "n"</span>
  res[[<span class="dv">1</span>]]
}) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()


<span class="co"># Plot curve data as overview</span>
<span class="co"># Names of the observations</span>

<span class="kw">layout</span>(<span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">4</span>), <span class="dv">2</span>, <span class="dv">3</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>))
<span class="kw">matplot</span>(
  data[, <span class="dv">1</span>], data[, <span class="dv">-1</span>], <span class="dt">xlab =</span> <span class="st">"Cycle"</span>, <span class="dt">ylab =</span> <span class="st">"RFU"</span>,
  <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">type =</span> <span class="st">"l"</span>, <span class="dt">lty =</span> <span class="dv">1</span>,
  <span class="dt">col =</span> decs, <span class="dt">lwd =</span> <span class="dv">2</span>
)
<span class="kw">legend</span>(<span class="st">"topleft"</span>, <span class="kw">c</span>(<span class="st">"positive"</span>, <span class="st">"negative"</span>), <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">col =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="dt">bty =</span> <span class="st">"n"</span>)
<span class="kw">mtext</span>(<span class="st">"A    RAS002 dataset"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)


<span class="co"># Convert the n.s. (not significant) in 0 and others to 1.</span>
<span class="co"># Combine the results of the aromatic autocorrelation_test as variable "ac",</span>
<span class="co"># the human classified values as variable "hc" in a new data frame (res_ac_hc).</span>

cutoff &lt;-<span class="st"> </span><span class="fl">0.8</span>

res_ac_hc &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">ac =</span> <span class="kw">ifelse</span>(res_ac <span class="op">&gt;</span><span class="st"> </span>cutoff, <span class="dv">1</span>, <span class="dv">0</span>),
  <span class="dt">hc =</span> <span class="kw">as.numeric</span>(<span class="kw">as.factor</span>(decs)) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>
) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/as.matrix">as.matrix</a></span>()
res_performeR &lt;-<span class="st"> </span><span class="kw"><a href="../reference/performeR.html">performeR</a></span>(res_ac_hc[, <span class="st">"ac"</span>], res_ac_hc[, <span class="st">"hc"</span>])


<span class="kw">plot</span>(<span class="kw">density</span>(res_ac), <span class="dt">ylab =</span> <span class="st">"Autocorrelation"</span>, <span class="dt">main =</span> <span class="st">""</span>)
<span class="kw">rug</span>(res_ac)

<span class="kw">abline</span>(<span class="dt">v =</span> cutoff)
<span class="kw">mtext</span>(<span class="st">"B"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, <span class="dt">las =</span> <span class="dv">0</span>)


<span class="kw">cdplot</span>(
  <span class="kw">as.factor</span>(decs) <span class="op">~</span><span class="st"> </span>res_ac, <span class="dt">xlab =</span> <span class="st">"Autocorrelation"</span>,
  <span class="dt">ylab =</span> <span class="st">"Decision"</span>
)
<span class="kw">mtext</span>(<span class="st">"C"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, <span class="dt">las =</span> <span class="dv">0</span>)

<span class="kw">barplot</span>(
  <span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/as.matrix">as.matrix</a></span>(res_performeR[, <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dv">12</span>)]), <span class="dt">yaxt =</span> <span class="st">"n"</span>, <span class="dt">ylab =</span> <span class="st">""</span>,
  <span class="dt">main =</span> <span class="st">"Performance of autocorrelation_test"</span>,
  <span class="dt">col =</span> <span class="kw">adjustcolor</span>(<span class="st">"grey"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.5</span>)
)

<span class="kw">axis</span>(<span class="dv">2</span>, <span class="dt">at =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">"0"</span>, <span class="st">"1"</span>), <span class="dt">las =</span> <span class="dv">2</span>)
<span class="kw">mtext</span>(<span class="st">"D"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, <span class="dt">las =</span> <span class="dv">0</span>)</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/autocorrelation-1.png" alt="Autocorrelation analysis for amplification curves of the `RAS002` dataset. A) Plot of all amplification curves of the `RAS002` dataset. B) Density plot of B) Positive curves and negative curves as determined by the `autocorrelation\_test()` and a human expert. C) Performance analysis by the ``performeR()`` function (see \autoref{section_performeR} for details)." width="1056"><p class="caption">
Autocorrelation analysis for amplification curves of the <code>RAS002</code> dataset. A) Plot of all amplification curves of the <code>RAS002</code> dataset. B) Density plot of B) Positive curves and negative curves as determined by the <code>autocorrelation\_test()</code> and a human expert. C) Performance analysis by the <code><a href="../reference/performeR.html">performeR()</a></code> function (see  for details).
</p>
</div>
<p>As shown in this example, the <code><a href="../reference/autocorrelation_test.html">autocorrelation_test()</a></code> function is able to distinguish between positive and negative amplification curves. Negative amplification curve were in all cases non-significant. In contrast, the coefficients of correlation for positive amplification curves ranged between 0.651 and 0.998 at a significance level of 0.01 and a lag of 3.</p>

</div>
<div id="earlyreg---a-function-to-calculate-the-slope-and-intercept-in-the-ground-phase-of-an-amplification-curve" class="section level4">
<h4 class="hasAnchor">
<a href="#earlyreg---a-function-to-calculate-the-slope-and-intercept-in-the-ground-phase-of-an-amplification-curve" class="anchor"></a><code><a href="../reference/earlyreg.html">earlyreg()</a></code> - A Function to Calculate the Slope and Intercept in the Ground Phase of an Amplification Curve </h4>
<p>The signal height and the slope in the first amplification curve cycles are helpful information for the analysis of amplification curves. Some qPCR systems calibrate themselves according to the measured values in the first cycles. This is noticeable in the form of strong signal changes which appear spontaneously between the first and second cycle. For another, the signal level can be used to determine which background signal is present and whether the ground phase already has a slope. From the slope it could be deduced whether amplification has already started (see ).</p>
<p>In addition, the function <code><a href="../reference/earlyreg.html">earlyreg()</a></code> was developed. This function uses an ordinary least squares linear regression within a limited number of cycles. As ROI, the first 10 cycles were defined. This restriction is based on empirical data suggesting that during the first ten cycles only a significant increase in signal strength can be measured within few qPCRs. However, <code><a href="../reference/earlyreg.html">earlyreg()</a></code> does not ignore the first cycle, as many thermo-cyclers use this cycle for sensor calibration. Extreme values are therefore included. As standard, the next nine amplitude values are used for the linear regression. The number of cycles can also be adjusted via the parameter <code>range</code>. Since all amplification curves are normalized to the 99%-percentile, there is also a comparability between the background signals and the slopes.</p>
<p>The following example illustrates a possible use of the function <code><a href="../reference/earlyreg.html">earlyreg()</a></code>. For that purpose amplification curves from the <code>RAS002</code> dataset were analysed. In figure A the amplification curves for all cycles are shown. Next, the <code><a href="../reference/earlyreg.html">earlyreg()</a></code> function was used to determine the slope and the intercept in the range of the first ten PCR cycles. The results were used in a cluster analysis using k-means clustering (B). Therefore, the increase seems to be an indicator of differences between the amplification curves. The C shows the first 15 cycles colored according to their cluster. After the cluster analysis this could also be observed (D-F). Hence, it can be postulated that the increase in the background phase is helpful for the classification of amplification curves.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># options(warn = -1)</span>
<span class="kw">library</span>(PCRedux)

data &lt;-<span class="st"> </span>RAS002

well &lt;-<span class="st"> </span><span class="kw">substr</span>(<span class="kw">colnames</span>(data)[<span class="op">-</span><span class="dv">1</span>], <span class="dv">1</span>, <span class="dv">10</span>)


<span class="co"># Normalize each amplification curve to their 0.99 percentile and use the</span>
<span class="co"># earlyreg function to determine the slope and intercept of the first</span>
<span class="co"># 5 cycles</span>

res_earlyreg &lt;-<span class="st"> </span><span class="kw">do.call</span>(rbind, <span class="kw">lapply</span>(2L<span class="op">:</span><span class="kw">ncol</span>(data), <span class="cf">function</span>(i) {
  <span class="kw"><a href="../reference/earlyreg.html">earlyreg</a></span>(<span class="dt">x =</span> data[, <span class="dv">1</span>], <span class="dt">y =</span> data[, i], <span class="dt">range =</span> <span class="dv">5</span>, <span class="dt">normalize =</span> <span class="ot">FALSE</span>)
}))

<span class="co"># Label the observation with their original names</span>
<span class="kw">rownames</span>(res_earlyreg) &lt;-<span class="st"> </span><span class="kw">colnames</span>(data)[<span class="dv">2</span><span class="op">:</span><span class="kw">ncol</span>(data)]


cl &lt;-<span class="st"> </span><span class="kw">kmeans</span>(res_earlyreg, <span class="dv">5</span>)

<span class="kw">rownames</span>(res_earlyreg) &lt;-<span class="st"> </span>well

<span class="kw">par</span>(<span class="dt">fig =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">las =</span> <span class="dv">0</span>, <span class="dt">bty =</span> <span class="st">"o"</span>, <span class="dt">oma =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>))
<span class="kw">matplot</span>(
  data[, <span class="dv">1</span>], data[, <span class="dv">-1</span>], <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">"l"</span>,
  <span class="dt">xlab =</span> <span class="st">"Cycle"</span>, <span class="dt">ylab =</span> <span class="st">"RFU"</span>, <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">col =</span> cl[[<span class="st">"cluster"</span>]]
)
<span class="kw">mtext</span>(<span class="st">"A"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">5</span>))
<span class="kw">rect</span>(<span class="fl">20.5</span>,<span class="dv">3500</span>,<span class="dv">45</span>,<span class="dv">4700</span>, <span class="dt">col =</span> <span class="st">"white"</span>, <span class="dt">border =</span> <span class="ot">NA</span>)
<span class="kw">text</span>(<span class="dv">3</span>, <span class="dv">3250</span>, <span class="st">"ROI"</span>)

<span class="kw">par</span>(<span class="dt">fig =</span> <span class="kw">c</span>(<span class="fl">0.525</span>, <span class="fl">0.99</span>, <span class="fl">0.5</span>, <span class="fl">0.95</span>), <span class="dt">new =</span> <span class="ot">TRUE</span>) 
<span class="kw">plot</span>(res_earlyreg, <span class="dt">col =</span> cl[[<span class="st">"cluster"</span>]], <span class="dt">pch =</span> <span class="dv">19</span>)
<span class="kw">mtext</span>(<span class="st">"B    k-means, k = 5"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/earlyreg_slopes-1.png" alt="Analysis of the ground phase with the ``earlyreg()`` function. A) The amplification curves show different slopes and intercepts in the early ground phase (ROI: cycle 1 to 5) of the qPCR. Amplification curves (n = 192) from the `RAS002` dataset were used. B) Both the slope and the intercept were used for a cluster analysis (k-means, Hartigan-Wong algorithm, number of centers \textit{k = 5}). The amplification curves were separated into three clusters dependent on their slope and intercept (colored in red, green, cyan, balck)." width="700"><p class="caption">
Analysis of the ground phase with the <code><a href="../reference/earlyreg.html">earlyreg()</a></code> function. A) The amplification curves show different slopes and intercepts in the early ground phase (ROI: cycle 1 to 5) of the qPCR. Amplification curves (n = 192) from the <code>RAS002</code> dataset were used. B) Both the slope and the intercept were used for a cluster analysis (k-means, Hartigan-Wong algorithm, number of centers ). The amplification curves were separated into three clusters dependent on their slope and intercept (colored in red, green, cyan, balck).
</p>
</div>
</div>
<div id="head2tailratio---a-function-to-calculate-the-ratio-of-the-head-and-the-tail-of-a-quantitative-pcr-amplification-curve" class="section level4">
<h4 class="hasAnchor">
<a href="#head2tailratio---a-function-to-calculate-the-ratio-of-the-head-and-the-tail-of-a-quantitative-pcr-amplification-curve" class="anchor"></a><code><a href="../reference/head2tailratio.html">head2tailratio()</a></code> - A Function to Calculate the Ratio of the Head and the Tail of a Quantitative PCR Amplification Curve</h4>
<p>The ratios from the ground and plateau phase can be used to search for patterns in amplification curves. Positive amplification curves have different slopes and intercepts at the start of the amplification curve (head, background region) and the end of the amplification curve (tail, plateau region). Therefore, these regions are potentially useful to extract a feature for an amplification curve classification. Negative amplification curves - without an increase - are assumed to have a ratio of about 1. In contrast, positive amplification curves should have a ratio of less than 1.</p>
<p>The <code><a href="../reference/head2tailratio.html">head2tailratio()</a></code> function calculates the ratio of the head and the tail of a quantitative PCR amplification curve. As ROI, the areas in the ground phase (head) and plateau phases (tail) are used (A). For the calculation, the median from the first six data points of the amplification curve and the median from the last six data points are used. The determination of six data points in both regions was made on the basis of . As a rule, no increase in amplification signals can be measured in the first six cycles and in the last six cycles, the amplification curve is usually about to transition into the plateau. This assumption is sometimes violated and might lead to false estimates. For example, the amplification curves in  show an increase within the first three cycles and the amplification curves in  have a negative slope in the tail. The median is used to minimize the influence of outliers.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PCRedux)

<span class="co"># Load the RAS002 dataset and assign it to the object data</span>

data &lt;-<span class="st"> </span>RAS002
data_decisions &lt;-<span class="st"> </span>RAS002_decisions

<span class="co"># Calculate the head2tailratio of all amplification curves</span>

res_head2tailratio &lt;-<span class="st"> </span><span class="kw">lapply</span>(2L<span class="op">:</span><span class="kw">ncol</span>(data), <span class="cf">function</span>(i) {
  <span class="kw"><a href="../reference/head2tailratio.html">head2tailratio</a></span>(
    <span class="dt">y =</span> data[, i], <span class="dt">normalize =</span> <span class="ot">TRUE</span>, <span class="dt">slope_normalizer =</span> <span class="ot">TRUE</span>,
    <span class="dt">verbose =</span> <span class="ot">TRUE</span>
  )
})

<span class="co"># Fetch all values of the head2tailratio analysis for a later comparison</span>
<span class="co"># by a boxplot.</span>

res &lt;-<span class="st"> </span><span class="kw">sapply</span>(1L<span class="op">:</span><span class="kw">length</span>(res_head2tailratio), <span class="cf">function</span>(i)
  res_head2tailratio[[i]]<span class="op">$</span>head_tail_ratio)

data_normalized &lt;-<span class="st"> </span><span class="kw">cbind</span>(
  data[, <span class="dv">1</span>],
  <span class="kw">sapply</span>(2L<span class="op">:</span><span class="kw">ncol</span>(data), <span class="cf">function</span>(i) {
    data[, i] <span class="op">/</span><span class="st"> </span><span class="kw">quantile</span>(data[, i], <span class="fl">0.99</span>)
  })
)

<span class="co"># Assign color to the positive and negative decisions</span>
colors &lt;-<span class="st"> </span><span class="kw">as.character</span>(<span class="kw">factor</span>(
  data_decisions, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">"y"</span>, <span class="st">"n"</span>),
  <span class="dt">labels =</span> <span class="kw">c</span>(
      <span class="kw">adjustcolor</span>(<span class="st">"black"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.25</span>), <span class="kw">adjustcolor</span>(<span class="st">"red"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.25</span>))
))

res_wilcox.test &lt;-<span class="st"> </span>stats<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/stats/topics/wilcox.test">wilcox.test</a></span>(res <span class="op">~</span><span class="st"> </span>data_decisions)

h &lt;-<span class="st"> </span><span class="kw">max</span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/na.omit.data.table">na.omit</a></span>(res))
h_text &lt;-<span class="st"> </span><span class="kw">rep</span>(h <span class="op">*</span><span class="st"> </span><span class="fl">0.976</span>, <span class="dv">2</span>)

<span class="co"># Plot the results of the analysis</span>

<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="dt">las =</span> <span class="dv">0</span>, <span class="dt">bty =</span> <span class="st">"o"</span>, <span class="dt">oma =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>))

<span class="kw">matplot</span>(
  data_normalized[, <span class="dv">1</span>], data_normalized[, <span class="dv">-1</span>],
  <span class="dt">xlab =</span> <span class="st">"Cycle"</span>, <span class="dt">ylab =</span> <span class="st">"normalized RFU"</span>, <span class="dt">main =</span> <span class="st">"RAS002 dataset"</span>,
  <span class="dt">type =</span> <span class="st">"l"</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> colors
)
<span class="cf">for</span> (i <span class="cf">in</span> 1L<span class="op">:</span>(<span class="kw">ncol</span>(data_normalized) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)) {
  <span class="kw">points</span>(
    res_head2tailratio[[i]]<span class="op">$</span>x_roi, res_head2tailratio[[i]]<span class="op">$</span>y_roi,
    <span class="dt">col =</span> colors[i], <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">cex =</span> <span class="fl">1.5</span>
  )
  <span class="kw">abline</span>(res_head2tailratio[[i]]<span class="op">$</span>fit, <span class="dt">col =</span> colors[i], <span class="dt">lwd =</span> <span class="dv">2</span>)
}
<span class="kw">mtext</span>(<span class="st">"A"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)

<span class="co"># Boxplot of the head2tail ratios of the positive and negative</span>
<span class="co"># amplification curves.</span>

<span class="kw">boxplot</span>(res <span class="op">~</span><span class="st"> </span>data_decisions, <span class="dt">col =</span> <span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/duplicated">unique</a></span>(colors), <span class="dt">ylab =</span> <span class="st">"Head to Tail Ratio"</span>)

<span class="kw">lines</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">rep</span>(h <span class="op">*</span><span class="st"> </span><span class="fl">0.945</span>, <span class="dv">2</span>))
<span class="kw">text</span>(<span class="fl">1.5</span>, h_text, <span class="kw">paste0</span>(<span class="st">"P = "</span>, <span class="kw">signif</span>(res_wilcox.test[[<span class="st">"p.value"</span>]])), 
     <span class="dt">cex =</span> <span class="dv">1</span>)

<span class="kw">mtext</span>(<span class="st">"B"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/figure_head2tailratio-1.png" alt="Calculation of the ratio between the head and the tail of a quantitative PCR amplification curve. A) Plot of quantile normalized amplification curves from the `RAS002` dataset. ROIs of the head and and tail are highlighted by circles. The ranges for performing Robust Linear Regression are automatically selected using the 25% and 75% quantiles. Therefore not all data points are used in the regression model. The straight line is the regression line from the robust linear model. The slopes of the positive and negative amplification curves differ. B) Boxplot for the comparison of the $head/tail$ ratio. Positive amplification curves have a lower ratio than negative curves. The difference between the classes is significant. " width="576"><p class="caption">
Calculation of the ratio between the head and the tail of a quantitative PCR amplification curve. A) Plot of quantile normalized amplification curves from the <code>RAS002</code> dataset. ROIs of the head and and tail are highlighted by circles. The ranges for performing Robust Linear Regression are automatically selected using the 25% and 75% quantiles. Therefore not all data points are used in the regression model. The straight line is the regression line from the robust linear model. The slopes of the positive and negative amplification curves differ. B) Boxplot for the comparison of the <span class="math inline">\(head/tail\)</span> ratio. Positive amplification curves have a lower ratio than negative curves. The difference between the classes is significant.
</p>
</div>
<p> shows that negative amplification curves can have a trend. The trend may be positive or negative. In  some reasons were mentioned. How to deal with this is the question. One possible solution could be to include this factor in the ratio calculation. The <code><a href="../reference/head2tailratio.html">head2tailratio()</a></code> function uses a linear model that calculates the slope between the ground and plateau phases. If the slope of the model is significant, then the ratio from the head and tail is normalized to this slope. This requires setting the <code>slope_normalizer</code> parameter in the <code><a href="../reference/head2tailratio.html">head2tailratio()</a></code> function. By default, this parameter is not set.</p>
</div>
<div id="hookreg-and-hookregnl---functions-to-detect-hook-effect-like-curvatures" class="section level4">
<h4 class="hasAnchor">
<a href="#hookreg-and-hookregnl---functions-to-detect-hook-effect-like-curvatures" class="anchor"></a><code><a href="../reference/hookreg.html">hookreg()</a></code> and <code><a href="../reference/hookregNL.html">hookregNL()</a></code> - Functions to Detect Hook Effect-like Curvatures</h4>
<p><code><a href="../reference/hookreg.html">hookreg()</a></code> and <code><a href="../reference/hookregNL.html">hookregNL()</a></code> are functions to detect amplification curves bearing a hook effect <span class="citation">(Barratt and Mackay 2002,)</span> or negative slope at the end of the amplification curve. Both functions calculate the slope and intercept of an amplification curve data. The idea is that a strong negative slope at the end of an amplification curve is indicative for a hook effect. <code><a href="../reference/hookreg.html">hookreg()</a></code> and <code><a href="../reference/hookregNL.html">hookregNL()</a></code> are currently undergoing a review process. For this reason, the functions will not be discussed in detail here. More information is given in the vignette and manual of both functions.</p>
<p>Amplification curves with a hook effect like curvature are characterized by a negative trend in the late phase of the amplification reaction ( A, curve F1.1, F1.2, F2.1, F2.2, F3.1 and F3.2).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Calculate slope and intercept on noise (negative) amplification curve data</span>
<span class="co"># for the last eight cycles.</span>
<span class="co"># options(warn = -1)</span>
<span class="kw">library</span>(qpcR)
<span class="kw">library</span>(magrittr)

res_hook &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">2</span><span class="op">:</span><span class="kw">ncol</span>(boggy), <span class="cf">function</span>(i) {
  <span class="kw"><a href="../reference/hookreg.html">hookreg</a></span>(<span class="dt">x =</span> boggy[, <span class="dv">1</span>], <span class="dt">y =</span> boggy[, i])
}) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">t</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">data.frame</span>(<span class="dt">obs =</span> <span class="kw">colnames</span>(boggy)[<span class="op">-</span><span class="dv">1</span>], .)</code></pre></div>
<p>The results of the <code><a href="../reference/hookreg.html">hookreg()</a></code> analysis were transferred to a tabular format.</p>

<p>In  is shown that the first amplification curves (F1.1, F1.2, F2.1, F2.2, F3.1 and F3.2) appear to have a hook effect-like curvature (“hook” column=1.00). The function estimate reliably the start of the hook effect-like region.</p>
<p>The clusters for amplification curve were determined by k-means clustering in this example. Next we plot the results of the analysis (). For the visualization the intercepts was plotted against the slope with the clusters as determined by k-means clustering.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">matplot</span>(
  <span class="dt">x =</span> boggy[, <span class="dv">1</span>], <span class="dt">y =</span> boggy[, <span class="dv">-1</span>], <span class="dt">xlab =</span> <span class="st">"Cycle"</span>, <span class="dt">ylab =</span> <span class="st">"RFU"</span>,
  <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">type =</span> <span class="st">"l"</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> res_hook<span class="op">$</span>hook <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
)

res_hook<span class="op">$</span>hook.start[res_hook<span class="op">$</span>hook.start <span class="op">==</span><span class="st"> </span><span class="dv">0</span>] &lt;-<span class="st"> "no hook"</span>

<span class="kw">legend</span>(
  <span class="st">"topleft"</span>, <span class="kw">paste</span>(<span class="kw">as.character</span>(res_hook<span class="op">$</span>obs), <span class="st">"Hook start cycle:"</span>, 
                   res_hook<span class="op">$</span>hook.start), <span class="dt">pch =</span> <span class="dv">19</span>,
  <span class="dt">col =</span> res_hook<span class="op">$</span>hook <span class="op">+</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">bty =</span> <span class="st">"n"</span>
)
<span class="kw">rect</span>(<span class="dv">26</span>,<span class="dv">2</span>,<span class="dv">40</span>,<span class="fl">2.3</span>, <span class="dt">border =</span><span class="st">"red"</span>)</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_hookreg-1.png" alt="Detection of the hook effect in amplification curves. Amplification curves of the `boggy` dataset were analyzed using the ``hookreg()`` function. The hook effect is characterized by a negative slope in the supposed plateau phase. Samples F1.1, F1.2, F2.1 and F2.2 (red) show a statistically significant negative slope. In the red rectangle the area of the hook effect is highlighted exemplary for the sample F1.1. No statistically significant negative slope (no hook effect) could be observed for the remaining amplification curves (black)." width="672"><p class="caption">
Detection of the hook effect in amplification curves. Amplification curves of the <code>boggy</code> dataset were analyzed using the <code><a href="../reference/hookreg.html">hookreg()</a></code> function. The hook effect is characterized by a negative slope in the supposed plateau phase. Samples F1.1, F1.2, F2.1 and F2.2 (red) show a statistically significant negative slope. In the red rectangle the area of the hook effect is highlighted exemplary for the sample F1.1. No statistically significant negative slope (no hook effect) could be observed for the remaining amplification curves (black).
</p>
</div>
</div>
<div id="mblrr---a-function-perform-the-quantile-filter-based-local-robust-regression" class="section level4">
<h4 class="hasAnchor">
<a href="#mblrr---a-function-perform-the-quantile-filter-based-local-robust-regression" class="anchor"></a><code><a href="../reference/mblrr.html">mblrr()</a></code> - A Function Perform the Quantile-filter Based Local Robust Regression </h4>
<p><code><a href="../reference/mblrr.html">mblrr()</a></code> is a function to perform the edian ased ocal obust egression (mblrr) from a quantitative PCR experiment. In detail, this function attempts to break the amplification curve in two ROIs (head (~background) and tail (~plateau)). As opposed to the <code><a href="../reference/earlyreg.html">earlyreg()</a></code> function, the <code><a href="../reference/mblrr.html">mblrr()</a></code> function does not use a fixed interval. Instead, the <code><a href="../reference/mblrr.html">mblrr()</a></code> function dynamically determines cut points for each amplification curve. For the <code><a href="../reference/mblrr.html">mblrr()</a></code> function was defined:</p>
<ul>
<li>The 25% quantile is the value for which 25% of all values are smaller than this value.</li>
<li>The 75% quantile is the value for which 75% of all values are greater than this value.</li>
</ul>
<p>Subsequent, a robust linear regression analysis (<code>lmrob()</code>) is preformed individually on both regions of the amplification curve. The rationale behind this analysis is that the slope and intercept of an amplification curve differ in the background and plateau region. This is also shown by the simulations in C-E. In the example shown below, the observations “P01.W19”, “P06.W35”, “P33.W66”, “P65.W90”, “P71.W23” and “P87.W01” were arbitrarily selected for demonstration purposes . Another example is shown in A. Those amplification curves have a slight negative trend in the baseline region and a positive trend in the plateau region.</p>
<p>The correlation coefficient is a measure to quantify the dependence on variables (e. g., number of cycles, signal height). The correlation coefficient is always between -1 and 1, with a value close to -1 describing a strong-negative dependency and close to 1 describing a strong-positive dependency; if the value is 0, there is no dependency between the variables. The most frequently used correlation coefficient to describe a linear dependency is the Pearson correlation coefficient <em>r</em>.</p>
<p>The correlation coefficient can also be used as a feature. Because similar data structures will have similar correlation coefficients. Correlation coefficients are between -1 and +1, with -1 being a strong negative correlation and 1 a strong positive correlation. The values of -1 and 1 have a perfect correlation. If the value is 0, there is no correlation between the two variables. However. variables that are not strongly correlated can also be important for modeling.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># options(warn = -1)</span>
<span class="kw">library</span>(PCRedux)

<span class="co"># Select four amplification curves from the RAS002 dataset</span>

data &lt;-<span class="st"> </span>RAS002[, <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>)]


<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))

<span class="cf">for</span> (i <span class="cf">in</span> 2L<span class="op">:</span><span class="kw">ncol</span>(data)) {
  x &lt;-<span class="st"> </span>data[, <span class="dv">1</span>]
  y_tmp &lt;-<span class="st"> </span>data[, i] <span class="op">/</span><span class="st"> </span><span class="kw">quantile</span>(data[, i], <span class="fl">0.99</span>)
  res_q25 &lt;-<span class="st"> </span>y_tmp <span class="op">&lt;</span><span class="st"> </span><span class="kw">quantile</span>(y_tmp, <span class="fl">0.25</span>)
  res_q75 &lt;-<span class="st"> </span>y_tmp <span class="op">&gt;</span><span class="st"> </span><span class="kw">quantile</span>(y_tmp, <span class="fl">0.75</span>)
  res_q25_lm &lt;-<span class="st"> </span><span class="kw">try</span>(
    <span class="kw">suppressWarnings</span>(<span class="kw">lmrob</span>(y_tmp[res_q25] <span class="op">~</span><span class="st"> </span>x[res_q25])),
    <span class="dt">silent =</span> <span class="ot">TRUE</span>
  )
  res_q75_lm &lt;-<span class="st"> </span><span class="kw">try</span>(
    <span class="kw">suppressWarnings</span>(<span class="kw">lmrob</span>(y_tmp[res_q75] <span class="op">~</span><span class="st"> </span>x[res_q75])),
    <span class="dt">silent =</span> <span class="ot">TRUE</span>
  )

  <span class="kw">plot</span>(x, y_tmp, <span class="dt">xlab =</span> <span class="st">"Cycle"</span>, <span class="dt">ylab =</span> <span class="st">"RFU (normalized)"</span>,
    <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">type =</span> <span class="st">"b"</span>, <span class="dt">pch =</span> <span class="dv">19</span>)
  
  <span class="kw">mtext</span>(<span class="kw">paste0</span>(LETTERS[i], <span class="st">"   "</span>, <span class="kw">colnames</span>(data)[i]), <span class="dt">cex =</span> <span class="dv">1</span>, <span class="dt">side =</span> <span class="dv">3</span>, 
        <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>)
  <span class="kw">abline</span>(res_q25_lm, <span class="dt">col =</span> <span class="st">"red"</span>)
  <span class="kw">points</span>(x[res_q25], y_tmp[res_q25], <span class="dt">cex =</span> <span class="fl">2.5</span>, <span class="dt">col =</span> <span class="st">"red"</span>)
  <span class="kw">abline</span>(res_q75_lm, <span class="dt">col =</span> <span class="st">"green"</span>)
  <span class="kw">points</span>(x[res_q75], y_tmp[res_q75], <span class="dt">cex =</span> <span class="fl">2.5</span>, <span class="dt">col =</span> <span class="st">"green"</span>)
}</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_mblrr-1.png" alt="Robust local regression to analyze amplification curves. The amplification curves were arbitrarily selected from the `RAS002` dataset. Not the differences in slopes and intercepts (red and green lines). The ``mblrr()`` function is presumably useful for datasets which are accompanied by noise and artifacts.m, slop; n, intercept." width="700"><p class="caption">
Robust local regression to analyze amplification curves. The amplification curves were arbitrarily selected from the <code>RAS002</code> dataset. Not the differences in slopes and intercepts (red and green lines). The <code><a href="../reference/mblrr.html">mblrr()</a></code> function is presumably useful for datasets which are accompanied by noise and artifacts.m, slop; n, intercept.
</p>
</div>
<p>Finally, the results of the analysis were printed in a tabular format.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the xtable library for an appealing table output</span>
<span class="kw">library</span>(xtable)

<span class="co"># Analyze the data via the mblrr() function</span>

res_mblrr &lt;-<span class="st"> </span><span class="kw">do.call</span>(cbind, <span class="kw">lapply</span>(2L<span class="op">:</span><span class="kw">ncol</span>(data), <span class="cf">function</span>(i) {
  <span class="kw">suppressMessages</span>(<span class="kw"><a href="../reference/mblrr.html">mblrr</a></span>(
    <span class="dt">x =</span> data[, <span class="dv">1</span>], <span class="dt">y =</span> data[, i],
    <span class="dt">normalize =</span> <span class="ot">TRUE</span>
  )) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">data.frame</span>()
}))
<span class="kw">colnames</span>(res_mblrr) &lt;-<span class="st"> </span><span class="kw">colnames</span>(data)[<span class="op">-</span><span class="dv">1</span>]

<span class="co"># Transform the data for a tabular output and assign the results to the object</span>
<span class="co"># output_res_mblrr.</span>

output_res_mblrr &lt;-<span class="st"> </span>res_mblrr <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">t</span>()

<span class="co"># The output variable names of the mblrr() function are rather long. For better</span>
<span class="co"># readability the variable names were changed to "nBG" (intercept of head region),</span>
<span class="co"># "mBG" (slope of head region), "rBG" (Pearson correlation of head region),</span>
<span class="co"># "nTP" (intercept of tail region), "mTP" (slope of tail region), "rBG" (Pearson</span>
<span class="co"># correlation of tail region)</span>

<span class="kw">colnames</span>(output_res_mblrr) &lt;-<span class="st"> </span><span class="kw">c</span>(
  <span class="st">"nBG"</span>, <span class="st">"mBG"</span>, <span class="st">"rBG"</span>,
  <span class="st">"nTP"</span>, <span class="st">"mTP"</span>, <span class="st">"rTP"</span>
)

<span class="kw">print</span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/xtable/topics/xtable">xtable</a></span>(
  output_res_mblrr, <span class="dt">caption =</span> <span class="st">"mblrr() text intro. nBG, intercept of </span>
<span class="st">             head region; mBG, slope of head region; rBG, Pearson </span>
<span class="st">             correlation of head region; nTP, intercept of tail region; mTP, </span>
<span class="st">             slope of tail region; rBG, Pearson correlation of tail region"</span>,
  <span class="dt">label =</span> <span class="st">"tablemblrrintroduction"</span>
), <span class="dt">comment =</span> <span class="ot">FALSE</span>, <span class="dt">caption.placement =</span> <span class="st">"top"</span>)</code></pre></div>

<p>In another example, the results from the <code><a href="../reference/mblrr.html">mblrr()</a></code> function were combined with the classifications (positive, negative) by a human to apply them in an analysis with Fast and Frugal Trees (FFTrees). A general introduction to decision trees is given in <span class="citation">(Quinlan 1986, <span class="citation">Luan, Schooler, and Gigerenzer (2011)</span>)</span>. FFTrees belong to class of simple decision rules. In many situations, FFTrees make fast decisions based on a few features (N = 1 - 5). In this example six features were used for the analysis.</p>
<p>The  package <span class="citation">(Phillips et al. 2017)</span> provides an implementation for the  statistical computing language. All that is needed for the present example are:</p>
<ul>
<li>the data assessed by the <code><a href="../reference/mblrr.html">mblrr()</a></code> function,</li>
<li>the classification of the amplification curve data by a human,</li>
<li>and a standard formula, which looks like <span class="math inline">\(outcome \leftarrow var1 + var2 + \ldots\)</span> along with the data arguments. The function <code><a href="http://www.rdocumentation.org/packages/FFTrees/topics/FFTrees">FFTrees()</a></code> returns a fast and frugal tree object. This rich object contains the underlying trees and many classification statistics (similar to ). In the following example, the <code>RAS002</code> dataset from the  package was used.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the xtable library for an appealing table output</span>
<span class="co"># options(warn = -1)</span>
<span class="kw">suppressMessages</span>(<span class="kw">library</span>(FFTrees))
<span class="kw">library</span>(PCRedux)

<span class="co"># The RAS002 amplification curves were analyzed with the mblrr() function </span>
<span class="co"># to save computing time and the.results of this analysis are stored in the </span>
<span class="co"># `data_sample` dataset.</span>

data &lt;-<span class="st"> </span>data_sample[data_sample<span class="op">$</span>dataset <span class="op">==</span><span class="st"> "RAS002"</span>, <span class="kw">c</span>(<span class="st">"mblrr_intercept_bg"</span>, 
                                                       <span class="st">"mblrr_slope_bg"</span>, 
                                                       <span class="st">"mblrr_cor_bg"</span>, 
                                                       <span class="st">"mblrr_intercept_pt"</span>, 
                                                       <span class="st">"mblrr_slope_pt"</span>, 
                                                       <span class="st">"mblrr_cor_pt"</span>)]

<span class="co"># The output variable names of the mblrr() function are rather long. For better</span>
<span class="co"># readability the variable names were changed to "nBG" (intercept of head</span>
<span class="co"># region), "mBG" (slope of head region), "rBG" (Pearson correlation of head</span>
<span class="co"># region), "nTP" (intercept of tail region), "mTP" (slope of tail region),</span>
<span class="co"># "rBG" (Pearson correlation of tail region).</span>


res_mblrr &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
    <span class="dt">class =</span> <span class="kw">as.numeric</span>(<span class="kw">as.character</span>(<span class="kw">factor</span>(RAS002_decisions, 
                                           <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">"y"</span>, <span class="st">"n"</span>), 
                                           <span class="dt">label =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>)))),
  data
)

<span class="kw">colnames</span>(res_mblrr) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">"class"</span>, <span class="st">"nBG"</span>, <span class="st">"mBG"</span>, <span class="st">"rBG"</span>, <span class="st">"nTP"</span>, <span class="st">"mTP"</span>, <span class="st">"rTP"</span>)

res_mblrr.fft &lt;-<span class="st"> </span><span class="kw">suppressMessages</span>(
            <span class="kw"><a href="http://www.rdocumentation.org/packages/FFTrees/topics/FFTrees">FFTrees</a></span>(<span class="dt">formula =</span> class <span class="op">~</span>., <span class="dt">data =</span> res_mblrr)
            )</code></pre></div>
<p> shows the Fast and Frugal Trees by using the features nBG (intercept of head region), mBG (slope of head region), rBG (Pearson correlation of head region), nTP (intercept of tail region), mTP (slope of tail region), and rBG (Pearson correlation of tail region).</p>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_FFTrees-1.png" alt="Visualization of decisions in  Fast and Frugal Trees after data analysis of amplification curves via the ``mblrr()`` function. \textbf{Top row} `Data`) Overview of the dataset, with displaying the total number of observations (N = 192) and percentage of positive (22\%) and negative (78\%) amplification curves. \textbf{Middle row} `FFT \#1 (of 6)`) Decision Tree with the number of observations classified at each level of the tree. For the analysis, six features (nBG, intercept of head region; mBG, slope of head region; rBG, Pearson correlation of head region; nTP, intercept of tail region; mTP, slope of tail region; rBG, Pearson correlation of tail region) have been used for the analysis. After two tree levels (nBG, nTP) already the decision tree is created. All positive amplification curves (N = 40) are correctly classified. Two observations are classified as false-negative in the negative amplification curves. \textbf{Lower row} `Performance`)  The ``FFTrees()`` function determines several performance statistics. For the training data, there is a classification table on the left side showing the relationship between tree `decision` and the `truth`. The correct rejection (`Cor Rej`) and `Hit` are the right decisions. `Miss` and false alarm (`False Al`) are wrong decisions. The centre shows the cumulative tree performance in terms of mean of used cues (`mcu`), Percent of ignored cues (`pci`), sensitivity (`sens`), specificity (`spec`), accuracy (`acc`) and weighted Accuracy (`wacc`). The receiver operating characteristic (ROC) curve on the right-hand side compares the performance of all trees in the FFTrees object. The system also displays the performance of the fast frugal trees (`\#`, green), CART (`C`, red), logistical regression (`L`, blue), random forest (`R`, violet) and the support vector machine (`S`, yellow)." width="1056"><p class="caption">
Visualization of decisions in Fast and Frugal Trees after data analysis of amplification curves via the <code><a href="../reference/mblrr.html">mblrr()</a></code> function.  <code>Data</code>) Overview of the dataset, with displaying the total number of observations (N = 192) and percentage of positive (22%) and negative (78%) amplification curves.  <code>FFT \#1 (of 6)</code>) Decision Tree with the number of observations classified at each level of the tree. For the analysis, six features (nBG, intercept of head region; mBG, slope of head region; rBG, Pearson correlation of head region; nTP, intercept of tail region; mTP, slope of tail region; rBG, Pearson correlation of tail region) have been used for the analysis. After two tree levels (nBG, nTP) already the decision tree is created. All positive amplification curves (N = 40) are correctly classified. Two observations are classified as false-negative in the negative amplification curves.  <code>Performance</code>) The <code><a href="http://www.rdocumentation.org/packages/FFTrees/topics/FFTrees">FFTrees()</a></code> function determines several performance statistics. For the training data, there is a classification table on the left side showing the relationship between tree <code>decision</code> and the <code>truth</code>. The correct rejection (<code>Cor Rej</code>) and <code>Hit</code> are the right decisions. <code>Miss</code> and false alarm (<code>False Al</code>) are wrong decisions. The centre shows the cumulative tree performance in terms of mean of used cues (<code>mcu</code>), Percent of ignored cues (<code>pci</code>), sensitivity (<code>sens</code>), specificity (<code>spec</code>), accuracy (<code>acc</code>) and weighted Accuracy (<code>wacc</code>). The receiver operating characteristic (ROC) curve on the right-hand side compares the performance of all trees in the FFTrees object. The system also displays the performance of the fast frugal trees (<code>\#</code>, green), CART (<code>C</code>, red), logistical regression (<code>L</code>, blue), random forest (<code>R</code>, violet) and the support vector machine (<code>S</code>, yellow).
</p>
</div>

<div class="figure">
<img src="PCRedux_files/figure-html/plot_peaks_ratio-1.png" alt="Working principle of the `peaks\_ratio` feature. The computation is based on a sequential linking of functions. The ``diffQ()`` function (\texttt{MBmca}) determines numerically the first derivative of an amplification curve. This derivative is passed to the ``mcaPeaks()`` function (\texttt{MBmca}). In the output all minima and all maxima are contained. The ranges are calculated from the minima and maxima. The Lagged Difference is determined from the ranges of the minima and maxima. Finally, the ratio of the differences (maximum/minimum) is calculated." width="700"><p class="caption">
Working principle of the <code>peaks\_ratio</code> feature. The computation is based on a sequential linking of functions. The <code>diffQ()</code> function () determines numerically the first derivative of an amplification curve. This derivative is passed to the <code>mcaPeaks()</code> function (). In the output all minima and all maxima are contained. The ranges are calculated from the minima and maxima. The Lagged Difference is determined from the ranges of the minima and maxima. Finally, the ratio of the differences (maximum/minimum) is calculated.
</p>
</div>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_cp_area-1.png" alt="Analysis of area and changepoint features. Amplification curves from the datasets `stepone\_std`, `RAS002`, `RAS003`, `lc96\_bACTXY`, `C126EG595` and `dil4reps94` were analyzed with the ``encu()`` function. These datasets contain positive and negative amplification curves. Furthermore, the meta dataset contains amplification curves that exhibit a hook effect or non-sigmoid shapes, for instance. All amplification curves are manually classified. Altogether 626 positive and 317 negative amplification curves were included in the analysis. A) `polyarea`, is the area under the amplification curve determined by the Gauss polygon area formula. B) `peaks\_ratio`, is the ratio of the local minima and the local maxima. C) `changepoint\_e.agglo`, makes use of energy agglomerative clustering. Positive amplification curves have fewer change points than negative amplification curves. These two change point analyses generally separate positive and negative amplification curves. D) `changepoint\_bcp`, analyses change points by a Bayesian approach. Positive amplification curves appear to contain more change points than negative amplification curves. Nevertheless, there is an overlap between the positive and negative amplification curves in both methods. This can lead to false-positive or false-negative classifications. E) `amptester\_polygon`, is the cycle normalized order of a polygon.  F) `amptester\_slope.ratio`, is the slope (linear model) of the raw fluorescence values at the approximate first derivate maximum, second derivative minimum and second derivative maximum." width="1056"><p class="caption">
Analysis of area and changepoint features. Amplification curves from the datasets <code>stepone\_std</code>, <code>RAS002</code>, <code>RAS003</code>, <code>lc96\_bACTXY</code>, <code>C126EG595</code> and <code>dil4reps94</code> were analyzed with the <code><a href="../reference/encu.html">encu()</a></code> function. These datasets contain positive and negative amplification curves. Furthermore, the meta dataset contains amplification curves that exhibit a hook effect or non-sigmoid shapes, for instance. All amplification curves are manually classified. Altogether 626 positive and 317 negative amplification curves were included in the analysis. A) <code>polyarea</code>, is the area under the amplification curve determined by the Gauss polygon area formula. B) <code>peaks\_ratio</code>, is the ratio of the local minima and the local maxima. C) <code>changepoint\_e.agglo</code>, makes use of energy agglomerative clustering. Positive amplification curves have fewer change points than negative amplification curves. These two change point analyses generally separate positive and negative amplification curves. D) <code>changepoint\_bcp</code>, analyses change points by a Bayesian approach. Positive amplification curves appear to contain more change points than negative amplification curves. Nevertheless, there is an overlap between the positive and negative amplification curves in both methods. This can lead to false-positive or false-negative classifications. E) <code>amptester\_polygon</code>, is the cycle normalized order of a polygon. F) <code>amptester\_slope.ratio</code>, is the slope (linear model) of the raw fluorescence values at the approximate first derivate maximum, second derivative minimum and second derivative maximum.
</p>
</div>
</div>
<div id="change-point-analysis" class="section level4">
<h4 class="hasAnchor">
<a href="#change-point-analysis" class="anchor"></a>Change point analysis</h4>
<p>Change point analysis (CPA) encompasses methods to identify or estimate single or multiple locations of distributional changes in a series of data points indexed in time order. A change herein refers to a statistical property. There exist several change point algorithms such as the binary segmentation algorithm <span class="citation">(A. J. Scott and Knott 1974)</span>. In the change point analysis one assumes independent ordered observations <span class="math inline">\(X_{1}, X_{2}, \ldots, X_{n} \in \mathbb{R}^{\textit{d}}\)</span> <span class="citation">(N. A. James and Matteson 2013)</span>. The case of qPCR this is simply the cycle-dependent fluorescence. This is be used to create <span class="math inline">\(k\)</span> homogeneous subsets of unknown size <span class="citation">(Erdman, Emerson, and others 2007)</span>. While frequentist methods make an estimation of the parameter at the location (e. g., mean, variance) of the change points at specific points, change point analysis using the Bayesian method produces a probability for the occurrence of a change point at certain points. CPA is used for example in econometrics and bioinformatics <span class="citation">(Killick and Eckley 2014, <span class="citation">Erdman, Emerson, and others (2007)</span>)</span>. For the analysis of the amplification curves it was hypothesized that the number of change points differs between positive (sigmoidal) and negative (noise) amplification curves.</p>
<p>The <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function uses two independent approaches for change point analysis. These are the <code>bcp()</code> function from the  package <span class="citation">(Erdman, Emerson, and others 2007)</span> and the <code>e.agglo()</code> function from the  package <span class="citation">(N. A. James and Matteson 2013)</span>. The <code>e.agglo()</code> function performs a non-parametric change point analysis based on agglomerative hierarchical estimation and is useful to “detect changes within the marginal distributions” <span class="citation">(N. A. James and Matteson 2013)</span>. Measurement from the qPCR systems typically shows noise that typically has rapidly changing components. Differentiators amplify these rapidly changing noise components <span class="citation">(Rödiger, Böhm, and Schimke 2013)</span>. Therefore, the first derivation of the amplification curve was used for both change point analyses. It was assumed for the change point analysis of amplification curves that this leads to larger differences between positive and negative amplification curves. An example is shown on . In contrast the <code>bcp()</code> [] function performs a change point analysis based on a Bayesian approach. This method can detect changes in the mean of independent Gaussian observations. As result the analysis returns the posterior probability of a change point at each <span class="math inline">\(X_{i}\)</span>. An example is shown on . Both the change point analysis methods provide additional information to distinguish positive and negative amplification curves E &amp; F).</p>
<pre><code>## N:36, idsize:36, idval1:1, idval22:22
## mm: 1, nn2: 36, N:36, cumksize.size: 36</code></pre>
<pre><code>## N:36, idsize:36, idval1:1, idval22:22
## mm: 1, nn2: 36, N:36, cumksize.size: 36</code></pre>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_cpa-1.png" alt="Application of Bayesian change point analysis and energy agglomerative change point analysis methods to the `RAS002` dataset. An analysis of a negative and a positive amplification curve from the `RAS002` dataset was performed using the ``pcrfit\_single()`` function. In this process, the amplification curves were analysed for change points using Bayesian change point analysis and energy agglomerative clustering. A) The negative amplification curve has a base signal of cica 2450 RFU and only a small signal increase to 2650 RFU. There is a clear indication of the signal variation (noise). B) The first negative derivative amplifies the noise so that some peaks are visible. C) The change point analysis shows changes in energy agglomerative clustering at several positions (green vertical line). The Bayesian change point analysis rarely exceeds a probability of 0.6 (grey vert line). D) The positive amplification curve has a lower base signal (~ 2450 RFU) and increases up to the 40th cycle (~3400 RFU). A sigmoid shape of the curve is clearly visible. E) The first negative derivation of the positive amplification curve shows a distinctive peak with a minimum at cycle 25. F) The change point analysis in energy agglomerative clustering shows changes (green vertical line) only at two positions. The Bayesian change point analysis shows a probability higher then 0.6 (grey horizontal line) at several positions." width="700"><p class="caption">
Application of Bayesian change point analysis and energy agglomerative change point analysis methods to the <code>RAS002</code> dataset. An analysis of a negative and a positive amplification curve from the <code>RAS002</code> dataset was performed using the <code>pcrfit\_single()</code> function. In this process, the amplification curves were analysed for change points using Bayesian change point analysis and energy agglomerative clustering. A) The negative amplification curve has a base signal of cica 2450 RFU and only a small signal increase to 2650 RFU. There is a clear indication of the signal variation (noise). B) The first negative derivative amplifies the noise so that some peaks are visible. C) The change point analysis shows changes in energy agglomerative clustering at several positions (green vertical line). The Bayesian change point analysis rarely exceeds a probability of 0.6 (grey vert line). D) The positive amplification curve has a lower base signal (~ 2450 RFU) and increases up to the 40th cycle (~3400 RFU). A sigmoid shape of the curve is clearly visible. E) The first negative derivation of the positive amplification curve shows a distinctive peak with a minimum at cycle 25. F) The change point analysis in energy agglomerative clustering shows changes (green vertical line) only at two positions. The Bayesian change point analysis shows a probability higher then 0.6 (grey horizontal line) at several positions.
</p>
</div>
</div>
<div id="test-of-an-amplification-reaction" class="section level4">
<h4 class="hasAnchor">
<a href="#test-of-an-amplification-reaction" class="anchor"></a>Test of an amplification reaction</h4>
<p>A part of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/amptester">amptester()</a></code> function from the  package. This function contains tests to determine whether an amplification curve is positive or negative. The input values for the function differ due to the different pre-processing steps in the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function. Therefore, the concepts of the tests are briefly described below.</p>
<ul>
<li>The first test, designated as SHt, is based on this Shapiro-Wilk test of normality. This relatively simple procedure can be used to check whether the underlying population of a sample (amplification curve) is significantly (<span class="math inline">\(\alpha \leq 5e-04\)</span>) normal distributed. In  it can be seen that negative amplification curves resemble a normal distribution, but positive amplification curves are deviating from the normal distribution. The output is binary coded (negative = 0, positive = 1). The name of the output of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is <code>amptester_shapiro</code>.</li>
<li>The second test is the <em>Resids growth test</em> (RGt), which tests if the fluorescence values in linear phase are stable. Whenever no amplification occurs, fluorescence values quickly deviate from linear model. Their standardized residuals will be strongly correlated with their value. For real amplification curves, situation is much more stable. Noise (that means deviations from linear model) in background do not correlate strongly with the changes in fluorescence. The decision is based on the threshold value (here 0.5). The output is binary coded (negative = 0, positive = 1). The output name of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is <code>amptester_rgt</code>.</li>
<li>The third test is the <em>Linear Regression test</em> (LRt). This test determines the coefficient of determination (<span class="math inline">\(R^{2}\)</span>) by an ordinary least squares linear (OLS) regression. The <span class="math inline">\(R^{2}\)</span> are determined from a run of circa 15% range of the data. If a sequence of more than six <span class="math inline">\(R^{2}\)</span>s is larger than 0.8 is found that is likely a nonlinear signal. This is a bit counter intuitive because <span class="math inline">\(R^{2}\)</span> of nonlinear data should be low. The output is binary coded (negative = 0, positive = 1). The output name of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is <code>amptester_lrt</code>.</li>
<li>The fourth test is called <em>Threshold test</em> (THt), which is based on the Wilcoxon rank sum test. As a simple rule the first 20% (head) and the last 15% (tail) of an amplification curve are used as input data. From that a one-sided Wilcoxon rank sum tests of the head versus the tail is performed (<span class="math inline">\(\alpha \leq 1e-02\)</span>). The output is binary coded (negative = 0, positive = 1). The output name of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is <code>amptester_tht</code>.</li>
<li>The fifth test is called <em>Signal level test</em> (SLt). he test compares the signals of the head and the tail by a robust “sigma” rule (median + 2 * median absolute deviation) and the the comparison of the head/tail ratio. If the returned value is less than 1.25 (25 percent), then the amplification curve is likely negative.The output is binary coded (negative = 0, positive = 1). The output name of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is <code>amptester_slt</code>.</li>
<li>The sixth test is called <em>Polygon test</em> (pco). The pco test determines if the points in an amplification curve (like a polygon) are in a “clockwise” order. The sum over the edges result in a positive value if the amplification curve is “clockwise” and is negative if the curve is counter-clockwise. From experience is noise positive and “true” amplification curves “highly” negative. In contrast to the implementation in the <code><a href="http://www.rdocumentation.org/packages/chipPCR/topics/amptester">amptester()</a></code> function, the result is normalized by a division to the number of PCR cycles. The output is numeric. The output name of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is <code>amptester_polygon</code>.</li>
<li>The seventh test is the <em>Slope Ratio test</em> (SlR).This test uses the approximated first derivative maximum, the second derivative minimum and the second derivative maximum of the amplification curve. Next the raw fluorescence at the approximated second derivative minimum and the second derivative maximum are taken from the original dataset. The fluorescence intensities are normalized to the maximum fluorescence of this data. This data is used for a linear regression. Where the slope is used. The output is numeric. The output name of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is <code>amptester_slope.ratio</code>.</li>
</ul>
<p>Random Forest is an enhancement of decision tree algorithms. Random Forest uses <em>n</em> random data subsets. The subset is to be used to capture trends precisely without taking into account the whole data. In order to do this, an ensemble consisting of <em>n</em> small decision trees is generated. Each decision tree contains a biased classifier. The majority of the previous classes are then selected for classification. Compared to a single tree classifier, the Random Forest has a high robustness against noise, outliers and over-fitting <span class="citation">(Williams 2009, <span class="citation">Breiman (2001)</span>)</span>.</p>
<p>In the following example, the <code><a href="http://www.rdocumentation.org/packages/randomForest/topics/randomForest">randomForest()</a></code> function from the  package <span class="citation">(Liaw and Wiener 2002)</span> was used for the classification. The aim was to classify positive and negative amplification curves. As response vector (<span class="math inline">\(y\)</span>) served <code>decision</code> with its possible states “positive” and “negative” (factor). The features <code>amptester_shapiro</code>, <code>amptester_lrt</code>, <code>amptester_rgt</code>, <code>amptester_tht</code>, <code>amptester_slt</code>, <code>amptester_polygon</code> and <code>amptester_slope.ratio</code> served as a matrix of predictors describing the model to be adapted. The <code>batsch1</code>, <code>HCU32_aggR</code>, <code>stepone_std</code>, <code>RAS002</code>, <code>RAS003</code>, <code>lc96_bACTXY</code> datasets were used for the analysis. This dataset contains almost equal proportions of positive and negative amplification curves (A). Prior to this, the amplification curves were analyzed with the <code><a href="../reference/encu.html">encu()</a></code> function () and stored in the <code>data_sample.rda</code> file to save computing time. The file is part of the  package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># options(warn = -1)</span>
<span class="kw">suppressMessages</span>(<span class="kw">library</span>(randomForest))
<span class="kw">library</span>(PCRedux)

data &lt;-<span class="st"> </span>data_sample[data_sample<span class="op">$</span>dataset <span class="op">%in%</span><span class="st"> </span>
<span class="st">                </span><span class="kw">c</span>(<span class="st">"batsch1"</span>,
                  <span class="st">"HCU32_aggR"</span>,
                  <span class="st">"lc96_bACTXY"</span>,
                  <span class="st">"RAS002"</span>, 
                  <span class="st">"RAS003"</span>, 
                  <span class="st">"stepone_std"</span>), ]

n_positive &lt;-<span class="st"> </span><span class="kw">sum</span>(data[[<span class="st">"decision"</span>]] <span class="op">==</span><span class="st"> "y"</span>)
n_negative &lt;-<span class="st"> </span><span class="kw">sum</span>(data[[<span class="st">"decision"</span>]] <span class="op">==</span><span class="st"> "n"</span>)

dat &lt;-<span class="st"> </span><span class="kw">data.frame</span>(data[, <span class="kw">c</span>(<span class="st">"amptester_shapiro"</span>, 
                           <span class="st">"amptester_lrt"</span>, 
                           <span class="st">"amptester_rgt"</span>, 
                           <span class="st">"amptester_tht"</span>, 
                           <span class="st">"amptester_slt"</span>,
                           <span class="st">"amptester_polygon"</span>, 
                           <span class="st">"amptester_slope.ratio"</span>)],
                  <span class="dt">decision =</span> <span class="kw">as.numeric</span>(<span class="kw">factor</span>(data<span class="op">$</span>decision, 
                                         <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">"n"</span>, <span class="st">"y"</span>), 
                                         <span class="dt">label =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)

<span class="co"># Select randomly observations from 70% of the data for training.</span>
<span class="co"># n_train is the number of observations used for training.</span>

n_train &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">nrow</span>(data) <span class="op">*</span><span class="st"> </span><span class="fl">0.7</span>)

<span class="co"># index_test is the index of observations to be selected for the training</span>
index_test &lt;-<span class="st"> </span><span class="kw">sample</span>(1L<span class="op">:</span><span class="kw">nrow</span>(dat), <span class="dt">size =</span> n_train)

<span class="co"># index_test is the index of observations to be selected for the testing</span>
index_training &lt;-<span class="st"> </span><span class="kw">which</span>(<span class="op">!</span>(1L<span class="op">:</span><span class="kw">nrow</span>(dat) <span class="op">%in%</span><span class="st"> </span>index_test))

<span class="co"># train_data contains the data used for training</span>

train_data &lt;-<span class="st"> </span>dat[index_test, ]

<span class="co"># test_data contains the data used for training</span>

test_data &lt;-<span class="st"> </span>dat[index_training, ]


model_rf =<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/randomForest/topics/randomForest">randomForest</a></span>(decision <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> train_data, <span class="dt">ntree =</span> <span class="dv">4000</span>, 
                        <span class="dt">importance =</span> <span class="ot">TRUE</span>)


<span class="co"># Determine variable importance</span>
res_importance &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/randomForest/topics/importance">importance</a></span>(model_rf)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))

<span class="kw">plot</span>(model_rf, <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">las =</span> <span class="dv">2</span>)
<span class="kw">mtext</span>(<span class="st">"A"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, <span class="dt">las =</span> <span class="dv">0</span>)

<span class="kw">rownames</span>(res_importance) &lt;-<span class="st"> </span><span class="kw">substr</span>(<span class="kw">rownames</span>(res_importance), <span class="dv">11</span>, <span class="dv">22</span>)


<span class="kw">barplot</span>(<span class="kw">t</span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/as.matrix">as.matrix</a></span>(<span class="kw">sort</span>(res_importance[, <span class="dv">1</span>]))), 
        <span class="dt">ylab =</span> <span class="st">"%IncMSE"</span>, <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">las =</span> <span class="dv">2</span>,
        <span class="dt">col =</span> <span class="kw">adjustcolor</span>(<span class="st">"grey"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.5</span>))
<span class="kw">mtext</span>(<span class="st">"B"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, <span class="dt">las =</span> <span class="dv">0</span>)

<span class="kw">barplot</span>(<span class="kw">t</span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/data.table/topics/as.matrix">as.matrix</a></span>(<span class="kw">sort</span>(res_importance[, <span class="dv">2</span>]))), 
        <span class="dt">ylab =</span> <span class="st">"IncNodePurity"</span>, <span class="dt">main =</span> <span class="st">""</span>, <span class="dt">las =</span> <span class="dv">2</span>,
        <span class="dt">col =</span> <span class="kw">adjustcolor</span>(<span class="st">"grey"</span>, <span class="dt">alpha.f =</span> <span class="fl">0.5</span>))
<span class="kw">mtext</span>(<span class="st">"C"</span>, <span class="dt">cex =</span> <span class="fl">1.2</span>, <span class="dt">side =</span> <span class="dv">3</span>, <span class="dt">adj =</span> <span class="dv">0</span>, <span class="dt">font =</span> <span class="dv">2</span>, <span class="dt">las =</span> <span class="dv">0</span>)</code></pre></div>
<div class="figure">
<img src="PCRedux_files/figure-html/plot_random_forest-1.png" alt="Random Forest." width="700"><p class="caption">
Random Forest.
</p>
</div>

</div>
<div id="parallel-programming" class="section level4">
<h4 class="hasAnchor">
<a href="#parallel-programming" class="anchor"></a>Parallel Programming </h4>
<p><code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> is a function, which calculates 48 potential features from an amplification curve. This comes at a cost, since several internal functions are computational very intensive <span class="citation">(Porzelius, Knaus, and Schwarzer 2009, <span class="citation">Schmidberger et al. (2009)</span>)</span>. For example, <code><a href="http://www.rdocumentation.org/packages/qpcR/topics/pcrfit">pcrfit()</a></code> function ( package) in <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> fits and optimizes eight non-linear (sigmoid) models to the amplification curve data. <code><a href="../reference/encu.html">encu()</a></code> (ENcode CUrves) is a relative of the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function. Similarly, this function calculates numerous but with an emphasis on features extraction of large amplification curve datasets.</p>
<p>The <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is performing the analysis for a single process and the <code>pblapply()</code> function from the  package is used internally to is delivers a progress bar and leverages parallel processing. Examples are given in the documentation of the <code><a href="../reference/encu.html">encu()</a></code> function. Parallel computing technologies saves scientists time in their routine tasks of analyzing experimental data. Information about parallel computing technologies in  are available from <span class="citation">Eddelbuettel (2017)</span>.</p>
<p>To process high data volumes and to deal with speed issues several  packages for parallelization were evaluated <span class="citation">(Vera, Jansen, and Suppi 2008, <span class="citation">Porzelius, Knaus, and Schwarzer (2009)</span>, <span class="citation">Boehringer (2013)</span>)</span>. For the calculation of the curve parameters the custom-made function <code>pcrfit_parallel()</code> was developed. In particular, to benchmark and evaluate the performance of multiple learners on multiple tasks studies quickly become resource-demanding. Therefore, packages such as <strong>mlr</strong> support natively parallelization <span class="citation">(Bischl et al. 2010)</span>.</p>
<p>The code block below shows an example for a parallelized version of <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code>. This function is called <code>pcrfit_parallel()</code>, which is intended for users who wish to calculate the features of a large amplification curve dataset. This function appears to be works on Linux systems. On Windows systems error messages were reported. <code>pcrfit_parallel()</code> makes use of parallelized code to make use of multi-core architectures. In this function we import from the  package the <code><a href="http://www.rdocumentation.org/packages/parallel/topics/detectCores">detectCores()</a></code> function. This function determines the number of available cores. Function from the  package (e. g., <code>%dopar%</code>, <code>foreach()</code>) are used for the further organization of the CPU usage. The <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> performs the analysis for a single process.</p>
<ul>
<li>The parameter <code>data</code> is the dataset containing the cycles and fluorescence amplitudes.</li>
<li>The parameter <code>n_cores</code> defines the numbers of cores that should be left unused by this function.</li>
</ul>
<p>By default, <code>pcrfit_parallel()</code> is using only one core (<code>n_cores=1</code>). <code>n_cores="all"</code> uses all available cores. The output of the <code>pcrfit_parallel()</code> function is similar to the <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Copy and paste the code to an R console to evaluate it</span>

<span class="kw">library</span>(parallel)
<span class="kw">library</span>(doParallel)

pcrfit_parallel &lt;-<span class="st"> </span><span class="cf">function</span>(data, <span class="dt">n_cores=</span><span class="dv">1</span>) {
    <span class="co"># Determine the number of available cores and register them</span>
    <span class="cf">if</span> (n_cores <span class="op">==</span><span class="st"> "all"</span>) {
        n_cores &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/parallel/topics/detectCores">detectCores</a></span>()
    }
    
    <span class="kw"><a href="http://www.rdocumentation.org/packages/doParallel/topics/registerDoParallel">registerDoParallel</a></span>(n_cores)
    
    <span class="co"># Prepare the data for further processing</span>
    <span class="co"># Normalize RFU values to the alpha percentile (0.99)</span>
    cycles &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">cycles =</span> data[, <span class="dv">1</span>])
    data_RFU &lt;-<span class="st"> </span><span class="kw">data.frame</span>(data[, <span class="dv">-1</span>])
    data_RFU_colnames &lt;-<span class="st"> </span><span class="kw">colnames</span>(data_RFU)
    data_RFU &lt;-<span class="st"> </span><span class="kw">sapply</span>(1L<span class="op">:</span><span class="kw">ncol</span>(data_RFU), <span class="cf">function</span>(i) {
        data_RFU[, i] <span class="op">/</span><span class="st"> </span><span class="kw">quantile</span>(data_RFU[, i], <span class="fl">0.99</span>, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)
    })
    <span class="kw">colnames</span>(data_RFU) &lt;-<span class="st"> </span>data_RFU_colnames
    
    <span class="co"># just to shut RCHeck for NSE we define ith_cycle</span>
    ith_cycle &lt;-<span class="st"> </span><span class="dv">1</span>
    
    run_res &lt;-<span class="st"> </span>foreach<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/foreach/topics/foreach">foreach</a></span>(
        <span class="dt">ith_cycle =</span> 1L<span class="op">:</span><span class="kw">ncol</span>(data_RFU),
                                <span class="dt">.packages =</span> <span class="kw">c</span>(
                                    <span class="st">"bcp"</span>, <span class="st">"changepoint"</span>, <span class="st">"chipPCR"</span>, <span class="st">"ecp"</span>, <span class="st">"MBmca"</span>,
                                    <span class="st">"PCRedux"</span>, <span class="st">"pracma"</span>, <span class="st">"qpcR"</span>, <span class="st">"robustbase"</span>,
                                    <span class="st">"zoo"</span>
                                ),
                                <span class="dt">.combine =</span> rbind
    ) <span class="op">%dopar%</span><span class="st"> </span>{
        <span class="kw">suppressMessages</span>(<span class="kw"><a href="../reference/pcrfit_single.html">pcrfit_single</a></span>(data_RFU[, ith_cycle]))
    }
    
    
    res &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">runs =</span> <span class="kw">colnames</span>(data_RFU), run_res)
    
    <span class="kw">rownames</span>(res) &lt;-<span class="st"> </span><span class="ot">NULL</span>
    
    res
}

<span class="co"># Calculate curve features of an amplification curve data. Note: Not all</span>
<span class="co"># CPU cores are used. If need set "all" to use all available cores.</span>
<span class="co"># In this example the testdat dataset from the qpcR package is used.</span>
<span class="co"># The observations F1.1 and F1.2 are positive amplification curves. The observations</span>
<span class="co"># F1.3 and F1.4 are negative.</span>
<span class="co"># options(warn = -1)</span>
<span class="kw">library</span>(qpcR)
res_pcrfit_parallel &lt;-<span class="st"> </span><span class="kw">pcrfit_parallel</span>(testdat[, <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>])
res_pcrfit_parallel</code></pre></div>

</div>
</div>
</div>
<div id="summary-and-conclusions" class="section level1">
<h1 class="hasAnchor">
<a href="#summary-and-conclusions" class="anchor"></a>Summary and Conclusions </h1>
<p>The  enables the user to extract features from amplification curve data. Numerous features can be extracted from the amplification curve. Some of them have not been described in the literature. We consider  as enabling technology for further research. For example, the proposed features are useable for machine learning applications or quality assessment of data.</p>
<p>Such software can be used in high-throughput applications in combination with other technologies, such as next generation sequencing. Next generation sequencing depends on pre-tests of the input DNA, prior to sequencing and is also used for confirmatory experiments after RNA-Seq quantification. To this end automatized quality control and decision support are conceivable applications.</p>
<p>The <code><a href="../reference/pcrfit_single.html">pcrfit_single()</a></code> function is an extendable wrapper function for several algorithm. Currently, 48 features can be calculated from an amplification curve.</p>
<p>Of note, we would like to emphasis that the functionality of this package is not limited to amplification curve data from qPCR experiments. As stated before, amplification curves have a sigmoid curve shape. Presumably, this can also be used for melting curve analysis.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<div id="refs" class="references">
<div id="ref-arlot_survey_2010">
<p>Arlot, Sylvain, and Alain Celisse. 2010. “A survey of cross-validation procedures for model selection.” <em>Statistics Surveys</em> 4: 40–79. doi:<a href="https://doi.org/10.1214/09-SS054">10.1214/09-SS054</a>.</p>
</div>
<div id="ref-Baaaath_2012">
<p>Bååth, Rasmus. 2012. “The State of Naming Conventions in R.” <em>The R Journal</em> 4 (2): 74–75. <a href="http://journal.r-project.org/archive/2012-2/RJournal_2012-2_Baaaath.pdf" class="uri">http://journal.r-project.org/archive/2012-2/RJournal_2012-2_Baaaath.pdf</a>.</p>
</div>
<div id="ref-barratt_improving_2002">
<p>Barratt, Kevin, and John F. Mackay. 2002. “Improving Real-Time PCR Genotyping Assays by Asymmetric Amplification.” <em>Journal of Clinical Microbiology</em> 40 (4): 1571–2. doi:<a href="https://doi.org/10.1128/JCM.40.4.1571-1572.2002">10.1128/JCM.40.4.1571-1572.2002</a>.</p>
</div>
<div id="ref-bischl_mlr:_2010">
<p>Bischl, Bernd, Michel Lang, Lars Kotthoff, Julia Schiffner, Jakob Richter, Erich Studerus, Giuseppe Casalicchio, and Zachary M. Jones. 2010. <em>mlr: Machine learning in R</em>. <a href="http://www.jmlr.org/papers/volume17/15-066/source/15-066.pdf" class="uri">http://www.jmlr.org/papers/volume17/15-066/source/15-066.pdf</a>.</p>
</div>
<div id="ref-boehringer_dynamic_2013">
<p>Boehringer, Stefan. 2013. “Dynamic Parallelization of R Functions.” <em>The R Journal</em> 5 (2): 88–97. <a href="http://journal.r-project.org/archive/2013-2/RJournal_2013-2_boehringer.pdf" class="uri">http://journal.r-project.org/archive/2013-2/RJournal_2013-2_boehringer.pdf</a>.</p>
</div>
<div id="ref-breiman_random_2001">
<p>Breiman, Leo. 2001. “Random forests.” <em>Machine Learning</em> 45 (1): 5–32.</p>
</div>
<div id="ref-noauthor_compstat_2008">
<p>Brito, Paula, ed. 2008. <em>COMPSTAT 2008: Proceedings in Computational Statistics</em>. Physica-Verlag Heidelberg.</p>
</div>
<div id="ref-bustin_continuing_2017">
<p>Bustin, Stephen. 2017. “The continuing problem of poor transparency of reporting and use of inappropriate methods for RT-qPCR.” <em>Biomolecular Detection and Quantification</em> 12 (June): 7–9. doi:<a href="https://doi.org/10.1016/j.bdq.2017.05.001">10.1016/j.bdq.2017.05.001</a>.</p>
</div>
<div id="ref-bustin_reproducibility_2014">
<p>Bustin, Stephen A. 2014. “The reproducibility of biomedical research: Sleepers awake!” <em>Biomolecular Detection and Quantification</em> 2 (December): 35–42. doi:<a href="https://doi.org/10.1016/j.bdq.2015.01.002">10.1016/j.bdq.2015.01.002</a>.</p>
</div>
<div id="ref-charpiat_shape_2003">
<p>Charpiat, Guillaume, Olivier Faugeras, and Renaud Keriven. 2003. “Shape metrics, warping and statistics.” In <em>Image Processing, 2003. ICIP 2003. Proceedings. 2003 International Conference on</em>, 2:II–627. IEEE. <a href="http://ieeexplore.ieee.org/abstract/document/1246758/" class="uri">http://ieeexplore.ieee.org/abstract/document/1246758/</a>.</p>
</div>
<div id="ref-cook_interactive_2007">
<p>Cook, Dianne, and Deborah F. Swayne. 2007. <em>Interactive and Dynamic Graphics for Data Analysis: With R and GGobi</em>. 2007 edition. 1st Ser. New York: Springer. <a href="http://www.springer.com/us/book/9780387717616" class="uri">http://www.springer.com/us/book/9780387717616</a>.</p>
</div>
<div id="ref-de_vries_r_2012">
<p>De Vries, Andrie, and Joris Meys. 2012. <em>R for Dummies</em>. 2nd ed. John Wiley &amp; Sons.</p>
</div>
<div id="ref-dvinge_htqpcr:_2009">
<p>Dvinge, Heidi, and Paul Bertone. 2009. “HTqPCR: high-throughput analysis and visualization of quantitative real-time PCR data in R.” <em>Bioinformatics</em> 25 (24): 3325–6. doi:<a href="https://doi.org/10.1093/bioinformatics/btp578">10.1093/bioinformatics/btp578</a>.</p>
</div>
<div id="ref-eddelbuettel_cran_2017">
<p>Eddelbuettel, Dirk. 2017. “CRAN Task View: High-Performance and Parallel Computing with R,” September. <a href="https://CRAN.R-project.org/view=HighPerformanceComputing" class="uri">https://CRAN.R-project.org/view=HighPerformanceComputing</a>.</p>
</div>
<div id="ref-erdman_bcp:_2007">
<p>Erdman, Chandra, John W. Emerson, and others. 2007. “bcp: an R package for performing a Bayesian analysis of change point problems.” <em>Journal of Statistical Software</em> 23 (3): 1–13. <a href="https://www.researchgate.net/profile/Chandra_Erdman/publication/26538600_bcp_An_R_Package_for_Performing_a_Bayesian_Analysis_of_Change_Point_Problems/links/56dee56608aec8c022cf2fd2.pdf" class="uri">https://www.researchgate.net/profile/Chandra_Erdman/publication/26538600_bcp_An_R_Package_for_Performing_a_Bayesian_Analysis_of_Change_Point_Problems/links/56dee56608aec8c022cf2fd2.pdf</a>.</p>
</div>
<div id="ref-Febrero_Bande_2012">
<p>Febrero-Bande, Manuel, and Manuel Oviedo de la Fuente. 2012. “Statistical Computing in Functional Data Analysis: The R Package fda.usc.” <em>Journal of Statistical Software</em> 51 (4): 1–28. <a href="http://www.jstatsoft.org/v51/i04/" class="uri">http://www.jstatsoft.org/v51/i04/</a>.</p>
</div>
<div id="ref-feuer_lemming:_2015">
<p>Feuer, Ronny, Sebastian Vlaic, Janine Arlt, Oliver Sawodny, Uta Dahmen, Ulrich M. Zanger, and Maria Thomas. 2015. “LEMming: A Linear Error Model to Normalize Parallel Quantitative Real-Time PCR (qPCR) Data as an Alternative to Reference Gene Based Methods.” <em>PLOS ONE</em> 10 (9): e0135852. doi:<a href="https://doi.org/10.1371/journal.pone.0135852">10.1371/journal.pone.0135852</a>.</p>
</div>
<div id="ref-greene_big_2014">
<p>Greene, Casey S., Jie Tan, Matthew Ung, Jason H. Moore, and Chao Cheng. 2014. “Big Data Bioinformatics.” <em>Journal of Cellular Physiology</em> 229 (12): 1896–1900. doi:<a href="https://doi.org/10.1002/jcp.24662">10.1002/jcp.24662</a>.</p>
</div>
<div id="ref-gunay_machine_2016">
<p>Gunay, Melih, Evgin Goceri, and Rajarajeswari Balasubramaniyan. 2016. “Machine Learning for Optimum CT-Prediction for qPCR.” In <em>Machine Learning and Applications (ICMLA), 2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)</em>, 588–92. IEEE. doi:<a href="https://doi.org/10.1109/ICMLA.2016.0103">10.1109/ICMLA.2016.0103</a>.</p>
</div>
<div id="ref-herrera_multiple_2016">
<p>Herrera, Francisco, Sebastián Ventura, Rafael Bello, Chris Cornelis, Amelia Zafra, Dánel Sánchez-Tarragó, and Sarah Vluymans. 2016. <em>Multiple Instance Learning</em>. Cham: Springer International Publishing. <a href="http://link.springer.com/10.1007/978-3-319-47759-6" class="uri">http://link.springer.com/10.1007/978-3-319-47759-6</a>.</p>
</div>
<div id="ref-hothorn_handbook_2014">
<p>Hothorn, Torsten, and Brian S. Everitt. 2014. <em>A Handbook of Statistical Analyses using R, Third Edition</em>. 3rd ed. Oakville: Chapman; Hall/CRC.</p>
</div>
<div id="ref-hothorn_unbiased_2006">
<p>Hothorn, Torsten, Kurt Hornik, and Achim Zeileis. 2006. “Unbiased Recursive Partitioning: A Conditional Inference Framework.” <em>Journal of Computational and Graphical Statistics</em> 15 (3): 651–74. doi:<a href="https://doi.org/10.1198/106186006X133933">10.1198/106186006X133933</a>.</p>
</div>
<div id="ref-igual_introduction_2017">
<p>Igual, Laura, and Santi Seguí. 2017. <em>Introduction to Data Science</em>. Undergraduate Topics in Computer Science. Cham: Springer International Publishing. <a href="http://link.springer.com/10.1007/978-3-319-50017-1" class="uri">http://link.springer.com/10.1007/978-3-319-50017-1</a>.</p>
</div>
<div id="ref-isaac_essentials_2009">
<p>Isaac, Peter G. 2009. “Essentials of nucleic acid analysis: a robust approach.” <em>Annals of Botany</em> 104 (2): vi–vi. doi:<a href="https://doi.org/10.1093/aob/mcp135">10.1093/aob/mcp135</a>.</p>
</div>
<div id="ref-james_introduction_2013">
<p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. Vol. 103. Springer Texts in Statistics. New York, NY: Springer New York. <a href="http://link.springer.com/10.1007/978-1-4614-7138-7" class="uri">http://link.springer.com/10.1007/978-1-4614-7138-7</a>.</p>
</div>
<div id="ref-james_ecp:_2013">
<p>James, Nicholas A., and David S. Matteson. 2013. “ecp: An R package for nonparametric multiple change point analysis of multivariate data.” <em>arXiv Preprint arXiv:1309.3295</em>. <a href="https://arxiv.org/abs/1309.3295" class="uri">https://arxiv.org/abs/1309.3295</a>.</p>
</div>
<div id="ref-Killick_2014">
<p>Killick, Rebecca, and Idris A. Eckley. 2014. “changepoint: An R Package for Changepoint Analysis.” <em>Journal of Statistical Software</em> 58 (3): 1–19. <a href="http://www.jstatsoft.org/v58/i03/" class="uri">http://www.jstatsoft.org/v58/i03/</a>.</p>
</div>
<div id="ref-kitchin2014">
<p>Kitchin, Rob. 2014. <em>The data revolution : big data, open data, data infrastructures &amp; their consequences</em>. Los Angeles, California London: SAGE Publications.</p>
</div>
<div id="ref-knuth_literate_1984">
<p>Knuth, D. E. 1984. “Literate Programming.” <em>The Computer Journal</em> 27 (2): 97–111. doi:<a href="https://doi.org/10.1093/comjnl/27.2.97">10.1093/comjnl/27.2.97</a>.</p>
</div>
<div id="ref-kuhn_building_2008">
<p>Kuhn, Max. 2008. “Building Predictive Models in R Using the caret Package.” <em>Journal of Statistical Software</em> 28 (5). <a href="http://www.jstatsoft.org/v28/i05/" class="uri">http://www.jstatsoft.org/v28/i05/</a>.</p>
</div>
<div id="ref-lanubile_collaboration_2010">
<p>Lanubile, F., C. Ebert, R. Prikladnicki, and A. Vizcaíno. 2010. “Collaboration Tools for Global Software Engineering.” <em>IEEE Software</em> 27 (2): 52–55. doi:<a href="https://doi.org/10.1109/MS.2010.39">10.1109/MS.2010.39</a>.</p>
</div>
<div id="ref-lee_statistical_2010">
<p>Lee, J. K. 2010. <em>Statistical Bioinformatics: For Biomedical and Life Science Researchers</em>. Wiley. <a href="https://books.google.de/books?id=aT1MBGtxSNsC" class="uri">https://books.google.de/books?id=aT1MBGtxSNsC</a>.</p>
</div>
<div id="ref-lefever_rdml_2009">
<p>Lefever, Steve, Jan Hellemans, Filip Pattyn, Daniel R. Przybylski, Chris Taylor, René Geurts, Andreas Untergasser, Jo Vandesompele, and RDML on behalf of the Consortium. 2009. “RDML: structured language and reporting guidelines for real-time quantitative PCR data.” <em>Nucleic Acids Research</em> 37 (7): 2065–9. doi:<a href="https://doi.org/10.1093/nar/gkp056">10.1093/nar/gkp056</a>.</p>
</div>
<div id="ref-liaw_classification_2002">
<p>Liaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” <em>R News</em> 2 (3): 18–22. <a href="http://CRAN.R-project.org/doc/Rnews/" class="uri">http://CRAN.R-project.org/doc/Rnews/</a>.</p>
</div>
<div id="ref-luan_signal-detection_2011">
<p>Luan, Shenghua, Lael J. Schooler, and Gerd Gigerenzer. 2011. “A signal-detection analysis of fast-and-frugal trees.” <em>Psychological Review</em> 118 (2): 316–38. doi:<a href="https://doi.org/10.1037/a0022684">10.1037/a0022684</a>.</p>
</div>
<div id="ref-luo_learning_2010">
<p>Luo, Ping, Liang Lin, and Hongyang Chao. 2010. “Learning shape detector by quantizing curve segments with multiple distance metrics.” In <em>European Conference on Computer Vision</em>, 342–55. Springer.</p>
</div>
<div id="ref-mallona_chainy:_nodate">
<p>Mallona, Izaskun, Anna Díez-Villanueva, Berta Martín, and Miguel A. Peinado. 2017. “Chainy: an universal tool for standardized relative quantification in real-time PCR.” <em>Bioinformatics</em>. doi:<a href="https://doi.org/10.1093/bioinformatics/btw839">10.1093/bioinformatics/btw839</a>.</p>
</div>
<div id="ref-mallona_pcrefficiency:_2011">
<p>Mallona, Izaskun, Julia Weiss, and Marcos Egea-Cortines. 2011. “pcrEfficiency: a Web tool for PCR amplification efficiency prediction.” <em>BMC Bioinformatics</em> 12: 404. doi:<a href="https://doi.org/10.1186/1471-2105-12-404">10.1186/1471-2105-12-404</a>.</p>
</div>
<div id="ref-martins_dna_2015">
<p>Martins, C., G. Lima, Mr. Carvalho, L. Cainé, and Mj. Porto. 2015. “DNA quantification by real-time PCR in different forensic samples.” <em>Forensic Science International: Genetics Supplement Series</em> 5 (December): e545–e546. doi:<a href="https://doi.org/10.1016/j.fsigss.2015.09.215">10.1016/j.fsigss.2015.09.215</a>.</p>
</div>
<div id="ref-matz_no_2013">
<p>Matz, Mikhail V., Rachel M. Wright, and James G. Scott. 2013. “No Control Genes Required: Bayesian Analysis of qRT-PCR Data.” <em>PLoS ONE</em> 8 (8): e71448. doi:<a href="https://doi.org/10.1371/journal.pone.0071448">10.1371/journal.pone.0071448</a>.</p>
</div>
<div id="ref-mccall_non-detects_2014">
<p>McCall, Matthew N., Helene R. McMurray, Hartmut Land, and Anthony Almudevar. 2014. “On non-detects in qPCR data.” <em>Bioinformatics</em> 30 (16): 2310–6. doi:<a href="https://doi.org/10.1093/bioinformatics/btu239">10.1093/bioinformatics/btu239</a>.</p>
</div>
<div id="ref-mcfadden_conditional_1974">
<p>McFadden, Daniel L. 1974. “Conditional Logit Analysis of Qualitative Choice Behavior.” In <em>Frontiers in Economics</em>, Frontiers in Economics:105–42. P. Zarembka (ed.). New York: Academic Press. <a href="https://eml.berkeley.edu/reprints/mcfadden/zarembka.pdf" class="uri">https://eml.berkeley.edu/reprints/mcfadden/zarembka.pdf</a>.</p>
</div>
<div id="ref-myers_art_2004">
<p>Myers, Glenford J., Tom Badgett, Todd M. Thomas, and Corey Sandler. 2004. <em>The art of software testing</em>. 2nd ed. Hoboken, N.J: John Wiley &amp; Sons.</p>
</div>
<div id="ref-neve_unifiedwmwqpcr:_2014">
<p>Neve, Jan De, Joris Meys, Jean-Pierre Ottoy, Lieven Clement, and Olivier Thas. 2014. “unifiedWMWqPCR: the unified Wilcoxon–Mann–Whitney test for analyzing RT-qPCR data in R.” <em>Bioinformatics</em> 30 (17): 2494–5. doi:<a href="https://doi.org/10.1093/bioinformatics/btu313">10.1093/bioinformatics/btu313</a>.</p>
</div>
<div id="ref-nolan_2006">
<p>Nolan, Tania, Rebecca E Hands, and Stephen A Bustin. 2006. “Quantification of mRNA using real-time RT-PCR.” <em>Nature Protocols</em> 1 (November): 1559. <a href="http://dx.doi.org/10.1038/nprot.2006.236" class="uri">http://dx.doi.org/10.1038/nprot.2006.236</a>.</p>
</div>
<div id="ref-pabinger_2014">
<p>Pabinger, Stephan, Stefan Rödiger, Albert Kriegner, Klemens Vierlinger, and Andreas Weinhäusel. 2014. “A survey of tools for the analysis of quantitative PCR (qPCR) data.” <em>Biomolecular Detection and Quantification</em> 1 (1): 23–33. doi:<a href="https://doi.org/10.1016/j.bdq.2014.08.002">10.1016/j.bdq.2014.08.002</a>.</p>
</div>
<div id="ref-pabinger_qpcr:_2009">
<p>Pabinger, Stephan, Gerhard G. Thallinger, René Snajder, Heiko Eichhorn, Robert Rader, and Zlatko Trajanoski. 2009. “QPCR: Application for real-time PCR data management and analysis.” <em>BMC Bioinformatics</em> 10 (1): 268. doi:<a href="https://doi.org/10.1186/1471-2105-10-268">10.1186/1471-2105-10-268</a>.</p>
</div>
<div id="ref-perkins_readqpcr_2012">
<p>Perkins, James R., John M. Dawes, Steve B. McMahon, David LH Bennett, Christine Orengo, and Matthias Kohl. 2012. “ReadqPCR and NormqPCR: R packages for the reading, quality checking and normalisation of RT-qPCR quantification cycle (Cq) data.” <em>BMC Genomics</em> 13 (1): 296. doi:<a href="https://doi.org/10.1186/1471-2164-13-296">10.1186/1471-2164-13-296</a>.</p>
</div>
<div id="ref-FFTrees_package">
<p>Phillips, Nathaniel, Hansjoerg Neth, Jan Woike, and Wolfgang Gaissmaer. 2017. <em>FFTrees: Generate, Visualise, and Evaluate Fast-and-Frugal Decision Trees</em>. <a href="https://CRAN.R-project.org/package=FFTrees" class="uri">https://CRAN.R-project.org/package=FFTrees</a>.</p>
</div>
<div id="ref-porzelius_easier_2009">
<p>Porzelius, Christine, Harald Binder Jochen Knaus, and Guido Schwarzer. 2009. “Easier Parallel Computing in R with snowfall and sfCluster.” <em>The R Journal</em> 1 (1): 54–59. <a href="http://journal.r-project.org/archive/2009-1/RJournal_2009-1_Knaus+et+al.pdf" class="uri">http://journal.r-project.org/archive/2009-1/RJournal_2009-1_Knaus+et+al.pdf</a>.</p>
</div>
<div id="ref-quinlan_induction_1986">
<p>Quinlan, J. Ross. 1986. “Induction of decision trees.” <em>Machine Learning</em> 1 (1): 81–106. <a href="http://link.springer.com/article/10.1007/BF00116251" class="uri">http://link.springer.com/article/10.1007/BF00116251</a>.</p>
</div>
<div id="ref-richards_flexible_1959">
<p>Richards, F. J. 1959. “A Flexible Growth Function for Empirical Use.” <em>Journal of Experimental Botany</em> 10 (2): 290–301. doi:<a href="https://doi.org/10.1093/jxb/10.2.290">10.1093/jxb/10.2.290</a>.</p>
</div>
<div id="ref-Ritz2008">
<p>Ritz, Christian, and Andrej-Nikolai Spiess. 2008. “qpcR: an R package for sigmoidal model selection in quantitative real-time polymerase chain reaction analysis.” <em>Bioinformatics</em> 24 (13): 1549–51. doi:<a href="https://doi.org/10.1093/bioinformatics/btn227">10.1093/bioinformatics/btn227</a>.</p>
</div>
<div id="ref-roediger_RJ_2013">
<p>Rödiger, Stefan, Alexander Böhm, and Ingolf Schimke. 2013. “Surface Melting Curve Analysis with R.” <em>The R Journal</em> 5 (2): 37–53. <a href="http://journal.r-project.org/archive/2013-2/roediger-bohm-schimke.pdf" class="uri">http://journal.r-project.org/archive/2013-2/roediger-bohm-schimke.pdf</a>.</p>
</div>
<div id="ref-roediger2015chippcr">
<p>Rödiger, Stefan, Michał Burdukiewicz, and Peter Schierack. 2015. “chipPCR: an R package to pre-process raw data of amplification curves.” <em>Bioinformatics</em> 31 (17): 2900–2902. doi:<a href="https://doi.org/10.1093/bioinformatics/btv205">10.1093/bioinformatics/btv205</a>.</p>
</div>
<div id="ref-roediger2015r">
<p>Rödiger, Stefan, Michał Burdukiewicz, Konstantin A. Blagodatskikh, and Peter Schierack. 2015. “R as an Environment for the Reproducible Analysis of DNA Amplification Experiments.” <em>The R Journal</em> 7 (2): 127–50. <a href="http://journal.r-project.org/archive/2015-1/RJ-2015-1.pdf" class="uri">http://journal.r-project.org/archive/2015-1/RJ-2015-1.pdf</a>.</p>
</div>
<div id="ref-roediger_enabling_2017">
<p>Rödiger, Stefan, Michał Burdukiewicz, Andrej-Nikolai Spiess, and Konstantin Blagodatskikh. 2017. “Enabling reproducible real-time quantitative PCR research: the RDML package.” <em>Bioinformatics</em>, August. doi:<a href="https://doi.org/10.1093/bioinformatics/btx528">10.1093/bioinformatics/btx528</a>.</p>
</div>
<div id="ref-roediger_highly_2013">
<p>Rödiger, Stefan, Peter Schierack, Alexander Böhm, Jörg Nitschke, Ingo Berger, Ulrike Frömmel, Carsten Schmidt, et al. 2013. “A highly versatile microscope imaging technology platform for the multiplex real-time detection of biomolecules and autoimmune antibodies.” <em>Advances in Biochemical Engineering/Biotechnology</em> 133: 35–74. doi:<a href="https://doi.org/10.1007/10_2011_132">10.1007/10_2011_132</a>.</p>
</div>
<div id="ref-ronde_practical_2017">
<p>Ronde, Maurice W. J. de, Jan M. Ruijter, David Lanfear, Antoni Bayes-Genis, Maayke G. M. Kok, Esther E. Creemers, Yigal M. Pinto, and Sara-Joan Pinto-Sietsma. 2017. “Practical data handling pipeline improves performance of qPCR-based circulating miRNA measurements.” <em>RNA</em> 23 (5): 811–21. doi:<a href="https://doi.org/10.1261/rna.059063.116">10.1261/rna.059063.116</a>.</p>
</div>
<div id="ref-rote_computing_1991">
<p>Rote, Günter. 1991. “Computing the minimum Hausdorff distance between two point sets on a line under translation.” <em>Information Processing Letters</em> 38 (3): 123–27. doi:<a href="https://doi.org/10.1016/0020-0190(91)90233-8">10.1016/0020-0190(91)90233-8</a>.</p>
</div>
<div id="ref-ruijter_amplification_2009">
<p>Ruijter, J M, C Ramakers, W M H Hoogaars, Y Karlen, O Bakker, M J B van den Hoff, and A F M Moorman. 2009. “Amplification efficiency: linking baseline and bias in the analysis of quantitative PCR data.” <em>Nucleic Acids Research</em> 37 (6): e45. doi:<a href="https://doi.org/10.1093/nar/gkp045">10.1093/nar/gkp045</a>.</p>
</div>
<div id="ref-ruijter_2014">
<p>Ruijter, Jan M., Peter Lorenz, Jari M. Tuomi, Michael Hecker, and Maurice J. B. van den Hoff. 2014. “Fluorescent-increase kinetics of different fluorescent reporters used for qPCR depend on monitoring chemistry, targeted sequence, type of DNA input and PCR efficiency.” <em>Microchimica Acta</em>, 1–8. doi:<a href="https://doi.org/10.1007/s00604-013-1155-8">10.1007/s00604-013-1155-8</a>.</p>
</div>
<div id="ref-ruijter_evaluation_2013">
<p>Ruijter, Jan M., Michael W. Pfaffl, Sheng Zhao, Andrej N. Spiess, Gregory Boggy, Jochen Blom, Robert G. Rutledge, et al. 2013. “Evaluation of qPCR curve analysis methods for reliable biomarker discovery: Bias, resolution, precision, and implications.” <em>Methods</em> 59 (1): 32–46. doi:<a href="https://doi.org/10.1016/j.ymeth.2012.08.011">10.1016/j.ymeth.2012.08.011</a>.</p>
</div>
<div id="ref-ruijter_removal_2015">
<p>Ruijter, Jan M., Adrián Ruiz Villalba, Jan Hellemans, Andreas Untergasser, and Maurice J. B. van den Hoff. 2015. “Removal of between-run variation in a multi-plate qPCR experiment.” <em>Biomolecular Detection and Quantification</em>, Special Issue: Advanced Molecular Diagnostics for Biomarker Discovery – Part I, 5 (September): 10–14. doi:<a href="https://doi.org/10.1016/j.bdq.2015.07.001">10.1016/j.bdq.2015.07.001</a>.</p>
</div>
<div id="ref-saeys_review_2007">
<p>Saeys, Y., I. Inza, and P. Larranaga. 2007. “A review of feature selection techniques in bioinformatics.” <em>Bioinformatics</em> 23 (19): 2507–17. doi:<a href="https://doi.org/10.1093/bioinformatics/btm344">10.1093/bioinformatics/btm344</a>.</p>
</div>
<div id="ref-sauer_differentiation_2016">
<p>Sauer, Eva, Ann-Kathrin Reinke, and Cornelius Courts. 2016. “Differentiation of five body fluids from forensic samples by expression analysis of four microRNAs using quantitative PCR.” <em>Forensic Science International: Genetics</em> 22 (May): 89–99. doi:<a href="https://doi.org/10.1016/j.fsigen.2016.01.018">10.1016/j.fsigen.2016.01.018</a>.</p>
</div>
<div id="ref-schmidberger_2009">
<p>Schmidberger, Markus, Martin Morgan, Dirk Eddelbuettel, Hao Yu, Luke Tierney, and Ulrich Mansmann. 2009. “State-of-the-art in Parallel Computing with R.” <em>Journal of Statistical Software</em> 47 (1).</p>
</div>
<div id="ref-scott_cluster_1974">
<p>Scott, A. J., and M. Knott. 1974. “A Cluster Analysis Method for Grouping Means in the Analysis of Variance.” <em>Biometrics</em> 30 (3): 507. doi:<a href="https://doi.org/10.2307/2529204">10.2307/2529204</a>.</p>
</div>
<div id="ref-Seibelt_xray">
<p>Seibelt, Pablo. 2017. <em>xray: X Ray Vision on your Datasets</em>. <a href="https://CRAN.R-project.org/package=xray" class="uri">https://CRAN.R-project.org/package=xray</a>.</p>
</div>
<div id="ref-sing_rocr:_2005">
<p>Sing, Tobias, Oliver Sander, Niko Beerenwinkel, and Thomas Lengauer. 2005. “ROCR: visualizing classifier performance in R.” <em>Bioinformatics</em> 21 (20): 3940–1. doi:<a href="https://doi.org/10.1093/bioinformatics/bti623">10.1093/bioinformatics/bti623</a>.</p>
</div>
<div id="ref-spiess_impact_2015">
<p>Spiess, Andrej-Nikolai, Claudia Deutschmann, Michał Burdukiewicz, Ralf Himmelreich, Katharina Klat, Peter Schierack, and Stefan Rödiger. 2015. “Impact of Smoothing on Parameter Estimation in Quantitative DNA Amplification Experiments.” <em>Clinical Chemistry</em> 61 (2): 379–88. doi:<a href="https://doi.org/10.1373/clinchem.2014.230656">10.1373/clinchem.2014.230656</a>.</p>
</div>
<div id="ref-spiess_highly_2008">
<p>Spiess, Andrej-Nikolai, Caroline Feig, and Christian Ritz. 2008. “Highly accurate sigmoidal fitting of real-time PCR data by introducing a parameter for asymmetry.” <em>BMC Bioinformatics</em> 9 (1): 221. doi:<a href="https://doi.org/10.1186/1471-2105-9-221">10.1186/1471-2105-9-221</a>.</p>
</div>
<div id="ref-spiess_system-specific_2016">
<p>Spiess, Andrej-Nikolai, Stefan Rödiger, Michał Burdukiewicz, Thomas Volksdorf, and Joel Tellinghuisen. 2016. “System-specific periodicity in quantitative real-time polymerase chain reaction data questions threshold-based quantitation.” <em>Scientific Reports</em> 6 (December): 38951. doi:<a href="https://doi.org/10.1038/srep38951">10.1038/srep38951</a>.</p>
</div>
<div id="ref-rpart_2017">
<p>Therneau, Terry, Beth Atkinson, and Brian Ripley. 2017. <em>rpart: Recursive Partitioning and Regression Trees</em>. <a href="https://CRAN.R-project.org/package=rpart" class="uri">https://CRAN.R-project.org/package=rpart</a>.</p>
</div>
<div id="ref-tichopad_standardized_2003">
<p>Tichopad, Ales, Michael Dilger, Gerhard Schwarz, and Michael W Pfaffl. 2003. “Standardized determination of real-time PCR efficiency from a single reaction set-up.” <em>Nucleic Acids Research</em> 31 (20): e122.</p>
</div>
<div id="ref-Tierney2017">
<p>Tierney, Nicholas. 2017. “Visdat: Visualising Whole Data Frames.” <em>The Journal of Open Source Software</em> 2 (16). The Open Journal.</p>
</div>
<div id="ref-vera_r_parallel_2008">
<p>Vera, Gonzalo, Ritsert C. Jansen, and Remo L. Suppi. 2008. “R/parallel – speeding up bioinformatics analysis with R.” <em>BMC Bioinformatics</em> 9 (September): 390. doi:<a href="https://doi.org/10.1186/1471-2105-9-390">10.1186/1471-2105-9-390</a>.</p>
</div>
<div id="ref-walsh_correct_2015">
<p>Walsh, Ian, Gianluca Pollastri, and Silvio C. E. Tosatto. 2015. “Correct machine learning on protein sequences: a peer-reviewing perspective.” <em>Briefings in Bioinformatics</em>, September, bbv082. doi:<a href="https://doi.org/10.1093/bib/bbv082">10.1093/bib/bbv082</a>.</p>
</div>
<div id="ref-wickham_testthat_2011">
<p>Wickham, Hadley. 2011. “testthat: Get Started with Testing.” <em>The R Journal</em> 3 (1): 5–10. <a href="http://journal.r-project.org/archive/2011/RJ-2011-002/index.html" class="uri">http://journal.r-project.org/archive/2011/RJ-2011-002/index.html</a>.</p>
</div>
<div id="ref-williams_rattle:_2009">
<p>Williams, Graham J. 2009. “Rattle: A Data Mining GUI for R.” <em>The R Journal</em> 1 (2): 45–55. <a href="http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Williams.pdf" class="uri">http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Williams.pdf</a>.</p>
</div>
<div id="ref-wilson_good_2016">
<p>Wilson, Greg, Jennifer Bryan, Karen Cranston, Justin Kitzes, Lex Nederbragt, and Tracy K. Teal. 2017. “Good enough practices in scientific computing.” <em>PLOS Computational Biology</em> 13 (6): e1005510. doi:<a href="https://doi.org/10.1371/journal.pcbi.1005510">10.1371/journal.pcbi.1005510</a>.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#analysis-of-sigmoid-shaped-curves-for-data-mining-and-machine-learning-applications">Analysis of Sigmoid Shaped Curves for Data Mining and Machine Learning Applications</a></li>
      <li><a href="#development-implementation-and-installation">Development, Implementation and Installation </a></li>
      <li><a href="#technologies-for-amplification-curve-classification-and-classified-amplification-curves">Technologies for Amplification Curve Classification and Classified Amplification Curves</a></li>
      <li><a href="#functions-of-the-package">Functions of the  Package </a></li>
      <li><a href="#summary-and-conclusions">Summary and Conclusions </a></li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Stefan Roediger, Michal Burdukiewicz, Andrej-Nikolai Spiess, Konstantin A. Blagodatskikh.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
